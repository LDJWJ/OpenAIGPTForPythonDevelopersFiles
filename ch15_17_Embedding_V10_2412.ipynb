{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuTKV33UHXPz"
      },
      "source": [
        "# PART 05 임베딩: 복잡한 데이터를 쉽게 이해하는 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CHAPTER 15. 임베딩 소개"
      ],
      "metadata": {
        "id": "XX9eDi9T6iIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 목차\n",
        "- 15.1 임베딩의 의미\n",
        "- 15.2 임베딩 사용 사례\n"
      ],
      "metadata": {
        "id": "b_9bjF0A6nCe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd2M90lJHXI6"
      },
      "source": [
        "### chatgpt.env 환경파일 준비\n",
        " * 일반적으로 환경 변수는 .env 파일에 저장되지만, 구글 코랩 사용자의 편의를 위해 이 책에서는 chatgpt.env를 사용합니다.\n",
        " * 실제 개발 환경에서는 보통 .env를 사용하니, 이 점을 기억해 두세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s6aRqQlHWtu"
      },
      "source": [
        "### 기본 환경 설정\n",
        "### chatgpt.env 환경파일 준비\n",
        " * 일반적으로 환경 변수는 .env 파일에 저장되지만, 구글 코랩 사용자의 편의를 위해 이 책에서는 chatgpt.env를 사용합니다.\n",
        " * 실제 개발 환경에서는 보통 .env를 사용하니, 이 점을 기억해 두세요.\n",
        "\n",
        "\n",
        " ### 사전 준비\n",
        " * 구글 코랩 환경은 일정 시간이후에 초기화가 되기 때문에 두가지 작업을 매번 수행해야 함.\n",
        "   * chatgpt.env 파일 생성이 필요.\n",
        "     * 준비된 chatgpt.env를 내용을 변경하여 업로드 하거나 또는 API_KEY와 ORG_ID를 확인하여 생성한다.\n",
        "   * pip install openai 설치\n",
        "    * 라이브러리 불일치로 인한 에러 발생시, 추가 라이브러리 설치 필요.\n",
        "    * 에러 : TypeError: Client.__init__() got an unexpected keyword argument 'proxies'\n",
        "    * 해결 방법 : 안정된 버전 설치\n",
        "    ```\n",
        "    !pip install httpx==0.27.2\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60-b4puJwCia",
        "outputId": "2de2efc2-2c7f-4abb-8606-12a1bddd1724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Collecting httpx==0.27.2\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx==0.27.2) (1.2.2)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpx\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "Successfully installed httpx-0.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install httpx==0.27.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_AygDzPME5T"
      },
      "source": [
        "## CHAPTER 16. 텍스트 임베딩 활용 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 목차\n",
        "- 16.1 텍스트 임베딩의 핵심 이해하기\n",
        "- 16.2 다중 입력 사용 예제\n",
        "- 16.3 사용자의 의도를 읽어내는 시맨틱 검색\n",
        "- 16.4 코사인 유사도 쉽게 이해하기\n",
        "- 16.5 오픈AI 텍스트 임베딩 사용 예제\n",
        "- 16.6 임베딩의 내부 작동 원리"
      ],
      "metadata": {
        "id": "Sgl8GZjW6vSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 16.1 텍스트 임베딩의 핵심 이해하기"
      ],
      "metadata": {
        "id": "Kaz-HkUR7Zjc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuD6FMzVwARE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "with open(\"chatgpt.env\") as env:\n",
        "  for line in env:\n",
        "    key, value = line.strip().split(\"=\")\n",
        "    os.environ[key] = value\n",
        "\n",
        "client = OpenAI(api_key  = os.environ['API_KEY'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRyI_B2owAKH",
        "outputId": "6afe218d-5939-4873-9bf3-59ef31983c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CreateEmbeddingResponse(data=[Embedding(embedding=[-0.033891718834638596, -0.01960858516395092, -0.030314108356833458, -0.022476136684417725, 0.03544839099049568, -0.025330033153295517, 0.02755579724907875, 0.02703690715134144, -0.04317712411284447, -0.024305908009409904, 0.03435599058866501, -0.04519806429743767, -0.025261757895350456, -0.02333640120923519, 0.011081036180257797, 0.029795218259096146, -0.01708240993320942, -0.01734185591340065, -0.012822048738598824, 0.0034854398109018803, 0.03146113082766533, -0.008363690227270126, 0.006991362199187279, 0.024442456662654877, 0.041838932782411575, -0.00359467975795269, -0.010316355153918266, 0.03482025861740112, 0.02767869271337986, -0.00508990278467536, 0.0008184468024410307, -0.013975896872580051, -0.03315434977412224, 0.006813846994191408, 0.03809745982289314, -0.02528906799852848, 0.04148390144109726, 0.013982724398374557, 0.02780158817768097, 0.008554860018193722, -0.03733278065919876, -0.05284486711025238, 0.009223954752087593, -0.015334569849073887, 0.011524823494255543, 0.016563519835472107, -0.032553531229496, 0.01355259120464325, -0.002613226417452097, 0.04874836280941963, -0.04295864328742027, -0.010268563404679298, 0.03503873944282532, 0.100118488073349, 0.02401915192604065, -0.0021199393086135387, -0.012132471427321434, -0.0003072375839110464, -0.0024954520631581545, -0.009599467739462852, 0.05093316361308098, 0.0038199874106794596, -0.0059023755602538586, 0.009073750115931034, -0.050605446100234985, 0.018707355484366417, -0.007066464517265558, -0.034465231001377106, 0.013095148839056492, -0.02377336099743843, 0.03025948815047741, 0.019635895267128944, -0.019840721040964127, 0.010186633095145226, 0.00392581382766366, -0.010330010205507278, 0.008261277340352535, 0.03929910063743591, 0.032007329165935516, 0.04563502222299576, -0.007496597245335579, 0.03656810149550438, 0.010104702785611153, -0.017109720036387444, -0.05729639530181885, -0.0143104437738657, -0.06477934122085571, -0.04178431257605553, -0.00033070711651816964, -0.009974980726838112, -0.040637291967868805, 0.05762411653995514, -0.02774696797132492, 0.03989992290735245, 0.043095193803310394, -8.054318459471688e-05, -0.03935372084379196, 0.04552578181028366, 0.02138373628258705, -0.00974284578114748, 0.014556234702467918, 0.008595825172960758, 0.010145667940378189, -0.01289715152233839, 0.048830293118953705, 0.00889623537659645, 0.050605446100234985, -0.04211203381419182, -0.011490685865283012, 0.021848006173968315, -0.11197103559970856, -0.010582627728581429, 0.012815221212804317, -0.03214387968182564, -0.012152954004704952, 0.024565352126955986, 0.04937649518251419, -0.017642265185713768, 0.0033744927495718002, -0.041838932782411575, 0.02274923585355282, -0.014679129235446453, -0.005175246391445398, -0.047819823026657104, 0.008534377440810204, -0.029221707955002785, -0.00526741798967123, -0.02837509848177433, -0.02489307150244713, -0.012193918228149414, 0.017232615500688553, -0.015252639539539814, 0.04639970511198044, -0.02982252836227417, -0.036349620670080185, 0.006731917150318623, -0.03979068249464035, -0.02138373628258705, -0.04134735092520714, 0.012569431215524673, 0.011354135349392891, 0.03733278065919876, -0.009312712587416172, 0.0012989322422072291, 0.024865761399269104, -0.05631323531270027, 0.00562927545979619, 0.022612687200307846, -0.02680477313697338, -0.010835245251655579, -0.015785183757543564, 0.002845361363142729, -0.023500261828303337, 0.0021694388706237078, 0.043286360800266266, -0.011538478545844555, -0.0010761850280687213, -0.038561731576919556, -0.017833435907959938, 0.01936279609799385, -0.02982252836227417, 0.0004175444191787392, -0.006803605705499649, 0.01024808082729578, -0.0035434735473245382, -0.021042361855506897, -0.011381445452570915, -0.0034769054036587477, -0.0276104174554348, -0.030341418460011482, -0.0014406029367819428, 0.0347929485142231, -0.047574032098054886, 0.0012673550518229604, 0.007305426988750696, -0.01822943054139614, 0.04623584449291229, -0.009039612486958504, -0.007476114667952061, -0.015990009531378746, 0.006919673178344965, 0.014037343673408031, -0.01563498005270958, -0.017300890758633614, -0.03501142933964729, -0.05063275620341301, 0.019594930112361908, 0.04787444323301315, -0.05112433433532715, 0.008657272905111313, 0.02722807787358761, 0.07248076051473618, 0.05150667577981949, 0.014460649341344833, 0.017109720036387444, -0.04219396412372589, 0.022544411942362785, -0.032744698226451874, -0.01370962429791689, -0.042904023081064224, 0.013975896872580051, 0.021219875663518906, -0.007401012349873781, -0.0029682565946131945, 0.007510252296924591, -0.042521681636571884, 0.03146113082766533, -0.0022718512918800116, 0.01104007102549076, 0.012733290903270245, 0.017000479623675346, -0.012207573279738426, -0.015908079221844673, 0.0007817489677108824, -0.030996859073638916, 0.020400576293468475, 0.034465231001377106, 0.013812036253511906, 0.04784713312983513, 0.00992718804627657, -0.01979975588619709, 0.016727380454540253, 0.05604013800621033, 0.014924919232726097, 0.030423348769545555, 0.01551208458840847, 0.052681006491184235, 0.012712808325886726, 0.008233967237174511, 0.01050069835036993, 0.039626821875572205, 0.019895341247320175, 0.03380978852510452, -0.014324098825454712, 0.03129727020859718, 0.04121080040931702, -0.00974284578114748, 0.006834329571574926, -0.036977749317884445, -0.003082617186009884, -0.008022314868867397, 0.020414231345057487, 0.03834325075149536, 0.02004554495215416, -0.004953352734446526, 0.0068445708602666855, -0.0012263900134712458, -0.011647718027234077, -0.024797488003969193, -0.005253762938082218, 0.028265858069062233, 0.00875968486070633, 0.019772445783019066, -0.007988177239894867, -0.04710976406931877, 0.0068513983860611916, 0.00870506465435028, 0.021233530715107918, 0.05216211453080177, -0.03189808875322342, -0.02232593111693859, -0.02786986343562603, -0.05341837555170059, 0.012111988849937916, -0.016440624371170998, 0.04568964242935181, 0.03656810149550438, 0.07269924134016037, -0.02452438697218895, -0.020223060622811317, 0.03271738812327385, -0.002205283148214221, 0.057132538408041, -0.01428313460201025, -0.022175725549459457, -0.018707355484366417, -0.005830686539411545, 0.010657730512320995, -0.04872105270624161, -0.02647705189883709, -0.07428321987390518, 0.010514353401958942, 0.007203014567494392, 0.016563519835472107, -0.0119822658598423, 0.03198001906275749, -0.010459733195602894, 0.006923086941242218, 0.004786078818142414, -0.005960409063845873, 0.009326367639005184, -0.0062608192674815655, -0.009722363203763962, -0.05707791820168495, 0.025889888405799866, 0.00316113349981606, 0.02647705189883709, 0.0022650237660855055, -0.023158887401223183, 0.03869828209280968, 0.009954498149454594, -0.003932641353458166, -0.020892156288027763, -0.004233051091432571, -0.04929456487298012, -0.005868237931281328, 0.030669139698147774, 0.01816115528345108, -0.05464732646942139, -0.03233505040407181, -0.04836602509021759, -0.023227162659168243, 0.03593996912240982, -0.04812023416161537, -0.07155222445726395, -0.05931733548641205, -0.020482506603002548, 0.031870778650045395, 0.00015159188478719443, -0.054947737604379654, 0.0066056083887815475, -0.06838425993919373, -0.004345704801380634, -0.011688683182001114, 0.010104702785611153, 0.018338670954108238, 0.015334569849073887, 0.027528487145900726, 0.02061905525624752, -0.008664100430905819, 0.015867114067077637, -0.028921298682689667, -0.024196667596697807, 0.027760623022913933, 0.06570787727832794, -0.028784748166799545, -0.06450624018907547, 0.04664549231529236, 0.004963594023138285, 0.0032891491428017616, -0.025739682838320732, -0.005158177576959133, -0.02703690715134144, -0.02919439785182476, 0.03790629282593727, 0.027951793745160103, 0.004441290162503719, 0.031679607927799225, 0.006779709365218878, -0.011572616174817085, -0.01943107135593891, 0.007394184824079275, 0.01478836964815855, 0.008664100430905819, -0.05074199661612511, -0.08864828944206238, 0.051479365676641464, 0.0008171666413545609, -0.01614021509885788, 0.02199821174144745, -0.06264916062355042, 0.014965884387493134, -0.013381903991103172, 0.021766075864434242, 0.013477489352226257, 0.04743748530745506, -0.015238984487950802, -0.039435651153326035, 0.0259854719042778, 0.022039176896214485, -0.012774256058037281, 0.006492954213172197, 0.05756949633359909, -0.018502529710531235, -0.018202120438218117, -0.01650889962911606, 0.0014320685295388103, 0.0346837118268013, 0.03233505040407181, 0.03285393863916397, 0.019198935478925705, 0.05131550505757332, 0.049704212695360184, -0.023090612143278122, 0.011360962875187397, 0.011702338233590126, 0.018707355484366417, 0.009606295265257359, -0.02358219213783741, 0.020277680829167366, 0.06423313915729523, -0.018447909504175186, 0.03318165987730026, 0.03949027135968208, 0.015853459015488625, -0.04140197113156319, 0.046618182212114334, -0.013791553676128387, -0.015539394691586494, -0.04844795539975166, 0.0244697667658329, 0.007906246930360794, 0.052626386284828186, 0.008056452497839928, -0.012849358841776848, -0.02433321624994278, 0.012835703790187836, 0.0265999473631382, 0.002695156494155526, -0.013812036253511906, -0.009681398048996925, -0.051479365676641464, 0.06652718037366867, 0.022148417308926582, -0.04426952451467514, -0.05240790545940399, -0.007626319769769907, -0.027951793745160103, 0.02149297669529915, 0.041074253618717194, -0.0026012782473117113, -0.02157490700483322, -0.002814637729898095, -0.020127475261688232, 0.03148844093084335, 0.0037278160452842712, -0.0054415189661085606, 0.0038234011735767126, 0.0033369415905326605, -0.03501142933964729, 0.019567620009183884, 0.03776974231004715, -0.026326848194003105, -0.027596762403845787, -0.031379200518131256, -0.040883082896471024, 0.007523907348513603, 0.01709606498479843, 0.02281751111149788, 0.057351015508174896, -0.0050660064443945885, 0.026258572936058044, -0.010528008453547955, -0.01739647425711155, -0.07586719840765, -0.011681855656206608, -0.021738765761256218, -0.04538923501968384, -0.020851191133260727, -0.008930373005568981, 0.00501138623803854, -0.07007747888565063, -0.013661831617355347, 0.012180263176560402, -0.015867114067077637, -0.007387357298284769, 0.03487487882375717, 0.021848006173968315, -0.0007727878983132541, 0.025575822219252586, 0.010780625976622105, 0.05131550505757332, -0.08329552412033081, -0.037933599203825, -0.004523220006376505, -0.018680045381188393, -0.04686397314071655, 0.04394180327653885, -0.014911264181137085, 0.030041009187698364, -0.006694365758448839, -0.004659770056605339, 0.020086510106921196, 0.013101976364850998, -0.025930851697921753, -0.011989093385636806, -0.027569452300667763, -0.024920381605625153, -0.027064217254519463, -0.03968144208192825, -0.011251723393797874, -0.006772881839424372, 0.016235800459980965, -0.0022855063434690237, -0.028538959100842476, 0.06669104099273682, -0.045361924916505814, -0.01910335011780262, -0.006318853236734867, 0.007319082040339708, -0.007612664718180895, 0.02218938060104847, 0.018761975690722466, -0.016481589525938034, 0.018447909504175186, -0.0038165736477822065, -0.04585350304841995, 0.001716263359412551, -0.023063302040100098, -0.03757857158780098, -0.004045295063406229, -0.01822943054139614, -0.018270395696163177, 0.019130660220980644, 0.04426952451467514, 0.0016991945449262857, 0.04973152279853821, -0.0011120294220745564, 0.003509335918352008, 0.019144315272569656, 0.02445611171424389, 0.019895341247320175, 0.03711429983377457, -0.034274060279130936, -0.006933328229933977, -0.01904872991144657, 0.003963364753872156, -0.0019458380993455648, 0.003987261094152927, 0.014665474183857441, -0.026217607781291008, -0.020086510106921196, -0.050277724862098694, -0.01741012930870056, 0.013238525949418545, -0.05508428439497948, -0.0009276868076995015, -0.02963135950267315, 0.02403280697762966, 0.007319082040339708, 0.05478387698531151, 0.014406029134988785, -0.006103786639869213, 0.026640912517905235, -0.03001369908452034, 0.04986807331442833, -0.0127947386354208, -0.00562927545979619, -0.016167525202035904, -0.03853442147374153, 0.0041169836185872555, 0.027378283441066742, 0.019267210736870766, 0.04418759420514107, -0.03593996912240982, 0.02384163625538349, -0.012262193486094475, -0.037988219410181046, 0.0007104869000613689, 0.023363711312413216, 0.018010949715971947, -0.022435171529650688, 0.022558066993951797, 0.022244000807404518, 0.009142025373876095, 0.01790170930325985, -0.002147249411791563, 0.009633605368435383, -0.03435599058866501, 0.003328407183289528, -0.019690515473484993, -0.03195270895957947, 0.02995907887816429, -0.0027190526016056538, 0.009305885061621666, 0.0612836591899395, -0.022913096472620964, -0.045170754194259644, 0.01459719892591238, -0.011845716275274754, 0.006236922927200794, -0.007824317552149296, -0.03279931843280792, -0.014351408928632736, 0.009340022690594196, -0.03689581900835037, 0.00559513783082366, -0.005625861696898937, 0.02157490700483322, -0.026954978704452515, 0.010951313190162182, -0.021219875663518906, 0.0075853546150028706, -0.03353669121861458, -0.025015966966748238, 0.01538918912410736, -0.006998189724981785, 0.023227162659168243, 0.006158406846225262, -0.00744197703897953, 0.009340022690594196, 0.002208696911111474, -0.0447884127497673, 0.016809310764074326, 0.017628610134124756, 0.0031628403812646866, -0.008063280023634434, -0.01226902101188898, -0.023418331518769264, 0.02685939334332943, 0.024046462029218674, -0.017369164153933525, 0.01620849035680294, -0.030532589182257652, 0.0016266523161903024, -0.040391501039266586, -0.023431986570358276, 0.005410795100033283, -0.027897173538804054, -0.038944073021411896, -0.025903543457388878, 0.04260361194610596, 0.017737850546836853, -0.03189808875322342, 0.01009104773402214, -0.02281751111149788, 0.00715522188693285, -0.0075785270892083645, 0.032061949372291565, 0.008821132592856884, -0.013361421413719654, -0.0015669116983190179, 0.014446994289755821, 0.03121533989906311, 0.040828462690114975, -0.011558961123228073, 0.02081022597849369, 0.02117891050875187, 0.0040009161457419395, 0.0069674658589065075, 0.047765202820301056, 0.045798882842063904, 0.028538959100842476, 0.026709187775850296, 0.02804737724363804, 0.0002910222683567554, -0.008466102182865143, 0.005827272776514292, 0.00769459456205368, -0.052052874118089676, 0.006441748235374689, -0.005878479219973087, 0.0012417519465088844, 0.011968610808253288, 0.018884871155023575, -0.004294498823583126, -0.013252181001007557, 0.026149332523345947, 0.005018213763833046, -0.029112469404935837, -0.017573989927768707, -0.027146147564053535, -0.017382819205522537, 0.005325451493263245, 0.0022394205443561077, -0.022353241220116615, 0.006789950653910637, -0.027842553332448006, 0.02137008123099804, -0.0060218567959964275, -0.03247160091996193, -0.01657717488706112, -0.016809310764074326, 0.03323628008365631, -0.005752170458436012, 0.013791553676128387, -0.0007424908690154552, 0.04604467377066612, -0.002515934407711029, -0.009947670623660088, -0.050660066306591034, -0.0012366313021630049, 0.039572201669216156, -0.06417851895093918, 0.012842531315982342, 0.018447909504175186, 0.01796998456120491, -0.0397360622882843, -0.01075331587344408, 0.01078745350241661, -0.014556234702467918, 0.01119027566164732, -0.023541226983070374, -0.00698112091049552, 0.029167087748646736, 0.022558066993951797, 0.019622240215539932, -0.006885535549372435, 0.027910828590393066, -0.04484303295612335, -0.00901230238378048, -0.015853459015488625, -0.011907163076102734, -0.025111552327871323, 0.017614955082535744, -0.031051479279994965, -0.02963135950267315, -0.00015329875168390572, 0.0016010492108762264, -0.09482035040855408, -0.006233509164303541, 0.03411019966006279, -0.008425137028098106, 0.0013066132087260485, -0.04235782101750374, -0.019308175891637802, -0.009531192481517792, 0.008739202283322811, -0.017683230340480804, -0.012439708225429058, -0.003983847331255674, 0.015553049743175507, -0.01645427942276001, 0.028866678476333618, -0.017232615500688553, -0.02208014205098152, -0.018202120438218117, -0.02117891050875187, -0.006045753136277199, -0.05969967693090439, -0.04683666303753853, 0.044105663895606995, -0.02452438697218895, -0.0036731960717588663, 0.026026437059044838, -0.01765592023730278, -0.055712416768074036, -0.005612206645309925, -0.0028709645848721266, 0.02711883746087551, 0.003649299731478095, 0.022025521844625473, 0.0077901799231767654, -0.0038063323590904474, 0.039763372391462326, 0.019526654854416847, -0.05502966418862343, -0.012494328431785107, 0.001117150066420436, -0.04091039299964905, 0.0003921546449419111, -0.050960473716259, -0.0018775630742311478, 0.03979068249464035, -0.01676834560930729, -0.007373702246695757, 0.015785183757543564, 0.02636781334877014, -0.012330468744039536, 0.008240794762969017, 0.0259854719042778, 0.01104007102549076, -0.01308149378746748, -0.010227598249912262, -0.011033243499696255, -0.004772423766553402, 0.003529818495735526, -0.04148390144109726, 0.013395559042692184, 0.0250842422246933, 0.005642930511385202, 0.024852106347680092, 0.008227139711380005, 0.013422869145870209, -0.0017341854982078075, -0.0022513687144964933, 0.0038268149364739656, -0.01588076911866665, 0.029522119089961052, 0.02162952721118927, 0.0552208349108696, -0.014296788722276688, -0.01270598080009222, -0.015088779851794243, 0.043286360800266266, -0.0209331214427948, -0.03826132044196129, -0.03473832830786705, -0.005031868815422058, -0.00687188096344471, -0.004089673515409231, 0.009558502584695816, -0.008404655382037163, -0.005796549376100302, -0.0429859533905983, -0.021479321643710136, 0.015170709230005741, 0.03531184047460556, 0.004509564954787493, -0.03932641074061394, -0.010992278344929218, -0.010439250618219376, -0.03544839099049568, 0.004710976500064135, 0.05541200563311577, -0.025575822219252586, 0.009066922590136528, -0.032690078020095825, -0.015211674384772778, -0.0022684375289827585, 0.031816158443689346, 0.005410795100033283, 0.002934118965640664, 0.024551697075366974, -0.006172061897814274, 0.02680477313697338, -0.0042364648543298244, 0.01753302477300167, -0.04350484162569046, 0.004881663713604212, -0.003348889760673046, -0.01650889962911606, 0.01311563141644001, 0.03790629282593727, 0.011463375762104988, -0.02401915192604065, 0.04047343134880066, -0.01689123921096325, -0.052298665046691895, 0.02149297669529915, 0.03462909162044525, -0.013231698423624039, 0.006762640550732613, 0.0014303616480901837, 0.02635415829718113, -0.0346837118268013, 0.004898732528090477, 0.0119822658598423, -0.008971337229013443, 0.024947691708803177, 0.022599032148718834, 0.017437439411878586, 0.014324098825454712, -0.008384172804653645, -0.008752857334911823, 0.05404650419950485, -0.026217607781291008, -0.0244697667658329, -0.018188465386629105, -0.014173894189298153, -0.03998185321688652, -0.039189860224723816, 0.0074556320905685425, 0.03380978852510452, -0.005472242832183838, -0.03290855884552002, -0.050851233303546906, -0.0077970074489712715, 0.026149332523345947, -0.014296788722276688, -0.01999092660844326, -0.0022974545136094093, -0.0004975541960448027, -0.03132458031177521, 0.00675922678783536, 0.0015011969953775406, 0.0036731960717588663, 0.015198019333183765, 0.012009575963020325, -0.03531184047460556, -0.04609929397702217, 0.01144289318472147, 0.021083327010273933, -0.002910222625359893, -0.010985450819134712, -0.03107878938317299, 0.008602652698755264, -0.027883518487215042, 0.013525281101465225, 0.029740598052740097, 0.030860308557748795, 0.021916281431913376, -0.03430137038230896, -0.009865740314126015, 0.007223497144877911, 0.009462918154895306, -0.014064653776586056, 0.023486606776714325, 0.027378283441066742, -0.02408742718398571, 0.0189121812582016, -0.03015024960041046, -0.00537665793672204, 0.022926751524209976, -0.011859371326863766, -0.04451531171798706, 0.027665037661790848, 0.023909911513328552, 0.03083299845457077, 0.026135677471756935, 0.007025499362498522, 0.025807958096265793, -0.01144289318472147, 0.0033335278276354074, -0.002684915205463767, 0.004840699024498463, 0.005291313864290714, 0.02232593111693859, -0.010207115672528744, -0.010350492782890797, -0.002089215675368905, -0.020100165158510208, 0.028457028791308403, 0.0249750018119812, -0.027159802615642548, -0.026053747162222862, 0.01267867162823677, -0.017929019406437874, 0.009142025373876095, -0.003939468879252672, 0.02239420637488365, -0.03337283059954643, 0.00461539113894105, -0.0005299848271533847, -0.0714976042509079, -0.037742432206869125, 0.01601731963455677, 0.0020192337688058615, 0.023309091106057167, -0.004465186502784491, -0.029740598052740097, -0.020414231345057487, -0.005489311646670103, -0.000790283374954015, 0.03318165987730026, 0.039817992597818375, -0.005851169116795063, 0.01362086646258831, 0.02421032264828682, 0.0035605423618108034, 0.01910335011780262, 0.04205741360783577, -0.021588562056422234, 0.007312254514545202, 0.028921298682689667, -0.02157490700483322, -0.03334552049636841, 0.021151600405573845, 0.0076672849245369434, 0.008527549915015697, -0.038998689502477646, 0.016003664582967758, -0.009271747432649136, -0.03820670023560524, 0.0837324857711792, 0.003983847331255674, -0.018802940845489502, 0.007564872037619352, -0.02528906799852848, 0.010507525876164436, 0.016822965815663338, -0.010732833296060562, 0.03544839099049568, -0.03689581900835037, 0.004926042631268501, 0.03501142933964729, 0.016877584159374237, -0.0189121812582016, 0.024824798107147217, -0.003519577207043767, -0.01159992627799511, -0.04009108990430832, 0.010855727829039097, 0.02750117890536785, -0.0427674725651741, -0.01670007035136223, -0.03045065887272358, 0.023937221616506577, -0.02307695709168911, 0.008616307750344276, -0.010528008453547955, -0.005137695465236902, -0.020755605772137642, 0.029412878677248955, -0.0037551261484622955, 0.012473845854401588, -0.008063280023634434, -0.005810203962028027, -0.002753190230578184, 0.007148394361138344, 0.057733356952667236, 0.042712852358818054, 0.01084890030324459, -0.011046898551285267, -0.022353241220116615, 0.00038191338535398245, 0.03853442147374153, 0.015867114067077637, -0.010623592883348465, 0.0009695052867755294, -0.031160719692707062, 0.009107887744903564, -0.02987714856863022, 0.009654087945818901, 0.06161137670278549, 0.0132999736815691, -0.030559899285435677, -0.022558066993951797, 0.024483421817421913, -0.005694136489182711, -0.00948339980095625, 0.006154993083328009, 0.019526654854416847, 0.02578064799308777, 0.00810424517840147, -0.0500592440366745, 0.024360526353120804, 0.013054183684289455, -0.009462918154895306, 0.02773331291973591, 0.0124875009059906, -0.021342771127820015, -0.006813846994191408, 0.026081057265400887, -0.0158261489123106, 0.0398453027009964, -0.009019129909574986, 0.031870778650045395, -0.0037960910703986883, 0.007353219669312239, 0.007052809465676546, 0.022244000807404518, -0.021219875663518906, -0.02755579724907875, -0.016822965815663338, -0.04123811051249504, 0.02011382021009922, -0.016235800459980965, -0.0018673217855393887, 0.03263545781373978, 0.0008466102299280465, 0.03039603866636753, -0.023677777498960495, -0.001456818194128573, -0.036595411598682404, 0.04336829110980034, -0.01842060126364231, -0.014460649341344833, 0.03088761866092682, 0.016058284789323807, 0.025261757895350456, -0.012350951321423054, 0.008220312185585499, 0.015184364281594753, -0.00479290634393692, 0.024619972333312035, -0.010118357837200165, -0.04254899173974991, -0.014774714596569538, 0.026272227987647057, 0.03320896998047829, 0.01796998456120491, -0.06324997544288635, 0.009189818054437637, 0.014870299026370049, -0.015047814697027206, -0.006274474319070578, -0.004079432226717472, -0.024073772132396698, -0.010186633095145226, -0.014010034501552582, 0.02698228694498539, -0.03539377078413963, -0.05844341591000557, 0.011483858339488506, -0.0043661873787641525, 0.02150663174688816, 0.005823859013617039, 0.02527541294693947, -0.0042398786172270775, 0.024852106347680092, -0.01201640348881483, 0.021411046385765076, 0.013177079148590565, -0.020851191133260727, -0.019062384963035583, -0.025179827585816383, -0.043477531522512436, 0.005571241490542889, -0.010220770724117756, 0.03260814771056175, 0.022844821214675903, -0.005793135613203049, -0.032881248742341995, -0.04011840000748634, -0.018898526206612587, 0.03096954897046089, 0.020264025777578354, 0.027460213750600815, -0.01626311056315899, 0.00176149548497051, -0.009701880626380444, 0.012692325748503208, -0.02213476225733757, -0.010323182679712772, 0.03662272170186043, 0.015525739639997482, 0.03738740086555481, 0.02535734325647354, 0.02168414555490017, 0.02325447089970112, 0.014829333871603012, 0.0073327370919287205, 0.024060117080807686, -0.020441541448235512, -0.019390106201171875, -0.002089215675368905, -0.015198019333183765, 0.0016437211306765676, 0.011927645653486252, 0.0336732380092144, 0.00803596992045641, -0.005885306745767593, -0.016495244577527046, -0.013730106875300407, -0.0038131598848849535, 0.020851191133260727, -0.012118816375732422, 0.0017922192346304655, 0.008950854651629925, 0.02055078186094761, -0.008766512386500835, 0.006998189724981785, 0.014965884387493134, -0.020291335880756378, -0.009974980726838112, 0.0011461669346317649, 0.004939697682857513, -0.013463834300637245, 0.03045065887272358, 0.008650445379316807, -0.03645886108279228, 0.017546679824590683, 0.014815679751336575, -0.0006823234725743532, -0.0027787932194769382, 0.002198455622419715, -0.00515476381406188, -0.01639965921640396, 0.023240815848112106, 0.02220303565263748, 0.003063841490074992, 0.04055536165833473, 0.002749776467680931, 0.03613113984465599, -0.025179827585816383, -0.019062384963035583, 0.10050082951784134, -0.03869828209280968, -0.0003251597809139639, -0.01009104773402214, 0.0033010973129421473, 0.031679607927799225, -0.004314981400966644, -0.011197103187441826, -0.015320914797484875, 0.009189818054437637, 0.021452011540532112, -0.0335640013217926, -0.0023640226572752, 0.0065100230276584625, -0.008657272905111313, 0.005997960455715656, -0.011463375762104988, -0.01144289318472147, -0.026586292311549187, -0.006025270558893681, -0.01758764497935772, 0.010691868141293526, -0.02623126283288002, -0.010166150517761707, -0.027706002816557884, 0.013272663578391075, -0.028975918889045715, 0.01162723544985056, 0.041511211544275284, -0.012938116677105427, -0.02049616165459156, -0.002587623195722699, 0.020823881030082703, 0.009032784961163998, 0.02370508760213852, 0.00027331343153491616, -0.032498911023139954, -0.0010855727596208453, 0.007981349714100361, -0.015921734273433685, -0.0014576716348528862, -0.025521202012896538, 0.013921276666224003, -0.014365063980221748, -0.0022923338692635298, -0.011750130914151669, 0.028156617656350136, 0.030177559703588486, 0.0021557838190346956, -0.016631795093417168, -0.01727358065545559, 0.011654545553028584, 0.032444290816783905, 0.003290856024250388, 0.021397391334176064, -0.002872671466320753, -0.005994546692818403, 0.02201186679303646, 0.022530756890773773, 0.009101060219109058, -0.021848006173968315, -0.02421032264828682, 0.0001270555512746796, -0.022407861426472664, -0.014829333871603012, -0.011463375762104988, -0.05423767492175102, -0.028921298682689667, 0.01488395407795906, 0.03503873944282532, -0.00047195106162689626, 0.00021015905076637864, -0.019690515473484993, 0.0031628403812646866, 0.03733278065919876, 0.009428780525922775, 0.0022206450812518597, -0.020250370725989342, 0.0023879187647253275, 0.01835232600569725, 0.017314545810222626, -0.01488395407795906, 0.041265420615673065, 0.02005920000374317, 0.004024812486022711, 0.012350951321423054, -0.005762411747127771, 0.020755605772137642, 0.009633605368435383, -0.006704607047140598, 0.0060184430330991745, 0.0023640226572752, -0.008056452497839928, -0.005711205303668976, 0.0044515314511954784, -0.02124718576669693, -0.006544160656630993, -0.009640432894229889, 0.012344123795628548, 0.001279303221963346, 0.010589455254375935, 0.008780167438089848, -0.019895341247320175, -0.0012912512756884098, -0.04339560121297836, -0.017259925603866577, 0.026777463033795357, -0.0018246498657390475, 0.016304073855280876, -0.03454716131091118, 0.010425595566630363, -0.013614038936793804, -0.015129744075238705, -0.013893966563045979, 0.025821613147854805, 0.0007407839875668287, -0.022025521844625473, -0.006175475660711527, 0.004171603824943304, -0.013750589452683926, 0.02169780060648918, 0.022913096472620964, 0.012671844102442265, -0.02206648699939251, 0.010842072777450085, 0.025889888405799866, 0.0070869470946490765, 0.013893966563045979, 0.029330948367714882, -0.00908057764172554, 0.00023426866391673684, -0.00012257500202395022, 0.024005496874451637, 0.0029648428317159414, 0.02679111808538437, -0.011272205971181393, -0.0009985221549868584, -0.0028470682445913553, -0.01374376192688942, -0.0064758858643472195, -0.019472036510705948, 0.004492496140301228, 0.020591745153069496, -0.01507512480020523, 0.005690722726285458, 0.02471555769443512, -0.00781749002635479, -0.009592640213668346, -0.022025521844625473, 0.008834787644445896, -0.007250807248055935, 0.03473832830786705, -0.02837509848177433, 0.005984305404126644, -0.005120626650750637, -0.0129927359521389, 0.011094690300524235, 0.012030058540403843, -0.032061949372291565, -0.014296788722276688, -0.016563519835472107, 0.01390762161463499, -0.0011837182100862265, -0.05360954627394676, 0.0061379242688417435, 0.02604009211063385, 0.0018690286669880152, 0.005578069016337395, -0.01370962429791689, -0.03512066975235939, 0.00176149548497051, -0.03088761866092682, -0.01416023913770914, 0.018243085592985153, 0.0712791234254837, -0.04577157273888588, -0.002188214333727956, 0.013600383885204792, -0.028648197650909424, -0.002551778918132186, -0.0010949606075882912, -0.018051914870738983, 0.008500239811837673, 0.018488874658942223, -0.0003072375839110464, 0.017164340242743492, -0.02313157729804516, -0.0316522978246212, -0.008554860018193722, -0.050468895584344864, 0.04402373358607292, 0.011804751120507717, 0.011709165759384632, -0.002509106881916523, -0.005246935412287712, 0.01210516132414341, -0.018488874658942223, -0.005970650352537632, -0.011804751120507717, -0.0017469871090725064, 0.013736934401094913, 0.0009114714921452105, -0.012262193486094475, 0.03561225160956383, 0.00860948022454977, -0.007564872037619352, 0.054893117398023605, 0.014515269547700882, -6.848837801953778e-05, -0.0044822548516094685, 0.02832047827541828, 0.03599458932876587, -0.04112887382507324, 0.023568537086248398, 0.022872131317853928, 0.014474304392933846, -0.019021419808268547, 0.009490227326750755, -0.025616787374019623, -0.016973169520497322, 0.003652713494375348, -0.007052809465676546, 0.0017922192346304655, -0.018488874658942223, -0.00839100033044815, 0.011668200604617596, -0.007394184824079275, -0.02924901805818081, -0.012296331115067005, 0.02629953809082508, 0.014146584086120129, -0.024920381605625153, -0.02680477313697338, 0.0016036095330491662, -0.01999092660844326, 0.023759707808494568, -0.014610853977501392, 0.0009311005705967546, -0.03484756872057915, -0.010568972676992416, -0.024729212746024132, -0.02274923585355282, -0.010828417725861073, 0.03563956171274185, -0.0234592966735363, 0.028402408584952354, 0.030232178047299385, -0.020004581660032272, 0.03831594064831734, -0.0037721949629485607, 0.03315434977412224, 0.017055099830031395, -0.0010002290364354849, 0.029549429193139076, 0.018761975690722466, -0.03853442147374153, -0.00016951406723819673, 0.0029426533728837967, 0.035721492022275925, -0.017546679824590683, 0.036295000463724136, 0.01078745350241661, 0.02812930755317211, -0.014132929034531116, 0.00305018643848598, -0.005332279019057751, -0.0032959766685962677, 0.028402408584952354, 0.006861639674752951, -0.016918549314141273, -0.004031640011817217, -0.007059636991471052, -0.014119273982942104, -0.020946776494383812, 0.008582170121371746, 0.025575822219252586, -0.0021779730450361967, 0.014692784287035465, -0.0056463442742824554, -0.0199226513504982, -0.012371433898806572, 0.007639974821358919, -0.053117964416742325, -0.004881663713604212, -0.015785183757543564, -0.014201204292476177, 0.004915801342576742, 0.035284530371427536, -0.0013296559918671846, 0.004058950114995241, 0.014624509029090405, -0.010084220208227634, -0.0027770863380283117, 0.03787898272275925, 0.007558044511824846, 0.0036766098346561193, -0.004990904126316309, 0.0009379280963912606, 0.016194835305213928, 0.020660020411014557, 0.002256489358842373, -0.0015148520469665527, 0.0265999473631382, 0.003164547262713313, 0.005499552935361862, 0.01594904437661171, 0.0076672849245369434, -0.021902626380324364, -0.0042091547511518, 0.014515269547700882, -0.007203014567494392, 0.013142941519618034, 0.0008146063191816211, 0.03462909162044525, -0.01396224182099104, 0.010227598249912262, 0.04798368364572525, 0.03064182959496975, -0.013327283784747124, 0.009121542796492577, 0.0019731479696929455, 0.030232178047299385, 0.009237609803676605, 0.010575800202786922, 0.058989617973566055, -0.020031891763210297, 0.006612435448914766, -0.021042361855506897, 0.028593577444553375, -0.020072855055332184, 0.013265836052596569, -0.003840469755232334, 0.008397827856242657, -0.030914928764104843, 0.06559863686561584, -0.004874836187809706, 0.0005513207870535553, 0.019444726407527924, 0.017642265185713768, -0.03992723301053047, -0.033946339040994644, 0.012562603689730167, 0.015198019333183765, 0.0070937746204435825, 0.0398453027009964, 0.025452926754951477, -0.008445619605481625, 0.010637247934937477, 0.002746362704783678, 0.00755121698603034, -0.01892583630979061, 0.002049957402050495, 0.02968597784638405, 0.028702817857265472, -0.02982252836227417, 0.003536646021530032, 0.007141567301005125, -0.020264025777578354, -0.030368728563189507, 0.0061447517946362495, 0.033509381115436554, -0.010924003086984158, -0.002732707653194666, 0.011333653703331947, -0.002894860925152898, 0.04416028410196304, -0.032007329165935516, 0.03820670023560524, 0.02352757193148136, 0.006062821950763464, -0.02528906799852848, 0.002403280697762966, 0.01216660812497139, -0.04375063255429268, -0.008534377440810204, -0.005270831752568483, -0.005209384020417929, 0.06527091562747955, 0.0099613256752491, -0.02786986343562603, 0.038807522505521774, -0.017259925603866577, 0.008725547231733799, 0.04798368364572525, -0.013074666261672974, 0.005786308087408543, -0.03768781200051308, -0.01028221845626831, -0.0033232865389436483], index=0, object='embedding')], model='text-embedding-3-small', object='list', usage=Usage(prompt_tokens=4, total_tokens=4))\n"
          ]
        }
      ],
      "source": [
        "response = client.embeddings.create(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    input=\"I am a programmer\",\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhIruipDv75P",
        "outputId": "cd1bf542-7e60-42a7-954e-75a085d5c6aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.033891718834638596, -0.01960858516395092, -0.030314108356833458, -0.022476136684417725, 0.03544839099049568, -0.025330033153295517, 0.02755579724907875, 0.02703690715134144, -0.04317712411284447, -0.024305908009409904, 0.03435599058866501, -0.04519806429743767, -0.025261757895350456, -0.02333640120923519, 0.011081036180257797, 0.029795218259096146, -0.01708240993320942, -0.01734185591340065, -0.012822048738598824, 0.0034854398109018803, 0.03146113082766533, -0.008363690227270126, 0.006991362199187279, 0.024442456662654877, 0.041838932782411575, -0.00359467975795269, -0.010316355153918266, 0.03482025861740112, 0.02767869271337986, -0.00508990278467536, 0.0008184468024410307, -0.013975896872580051, -0.03315434977412224, 0.006813846994191408, 0.03809745982289314, -0.02528906799852848, 0.04148390144109726, 0.013982724398374557, 0.02780158817768097, 0.008554860018193722, -0.03733278065919876, -0.05284486711025238, 0.009223954752087593, -0.015334569849073887, 0.011524823494255543, 0.016563519835472107, -0.032553531229496, 0.01355259120464325, -0.002613226417452097, 0.04874836280941963, -0.04295864328742027, -0.010268563404679298, 0.03503873944282532, 0.100118488073349, 0.02401915192604065, -0.0021199393086135387, -0.012132471427321434, -0.0003072375839110464, -0.0024954520631581545, -0.009599467739462852, 0.05093316361308098, 0.0038199874106794596, -0.0059023755602538586, 0.009073750115931034, -0.050605446100234985, 0.018707355484366417, -0.007066464517265558, -0.034465231001377106, 0.013095148839056492, -0.02377336099743843, 0.03025948815047741, 0.019635895267128944, -0.019840721040964127, 0.010186633095145226, 0.00392581382766366, -0.010330010205507278, 0.008261277340352535, 0.03929910063743591, 0.032007329165935516, 0.04563502222299576, -0.007496597245335579, 0.03656810149550438, 0.010104702785611153, -0.017109720036387444, -0.05729639530181885, -0.0143104437738657, -0.06477934122085571, -0.04178431257605553, -0.00033070711651816964, -0.009974980726838112, -0.040637291967868805, 0.05762411653995514, -0.02774696797132492, 0.03989992290735245, 0.043095193803310394, -8.054318459471688e-05, -0.03935372084379196, 0.04552578181028366, 0.02138373628258705, -0.00974284578114748, 0.014556234702467918, 0.008595825172960758, 0.010145667940378189, -0.01289715152233839, 0.048830293118953705, 0.00889623537659645, 0.050605446100234985, -0.04211203381419182, -0.011490685865283012, 0.021848006173968315, -0.11197103559970856, -0.010582627728581429, 0.012815221212804317, -0.03214387968182564, -0.012152954004704952, 0.024565352126955986, 0.04937649518251419, -0.017642265185713768, 0.0033744927495718002, -0.041838932782411575, 0.02274923585355282, -0.014679129235446453, -0.005175246391445398, -0.047819823026657104, 0.008534377440810204, -0.029221707955002785, -0.00526741798967123, -0.02837509848177433, -0.02489307150244713, -0.012193918228149414, 0.017232615500688553, -0.015252639539539814, 0.04639970511198044, -0.02982252836227417, -0.036349620670080185, 0.006731917150318623, -0.03979068249464035, -0.02138373628258705, -0.04134735092520714, 0.012569431215524673, 0.011354135349392891, 0.03733278065919876, -0.009312712587416172, 0.0012989322422072291, 0.024865761399269104, -0.05631323531270027, 0.00562927545979619, 0.022612687200307846, -0.02680477313697338, -0.010835245251655579, -0.015785183757543564, 0.002845361363142729, -0.023500261828303337, 0.0021694388706237078, 0.043286360800266266, -0.011538478545844555, -0.0010761850280687213, -0.038561731576919556, -0.017833435907959938, 0.01936279609799385, -0.02982252836227417, 0.0004175444191787392, -0.006803605705499649, 0.01024808082729578, -0.0035434735473245382, -0.021042361855506897, -0.011381445452570915, -0.0034769054036587477, -0.0276104174554348, -0.030341418460011482, -0.0014406029367819428, 0.0347929485142231, -0.047574032098054886, 0.0012673550518229604, 0.007305426988750696, -0.01822943054139614, 0.04623584449291229, -0.009039612486958504, -0.007476114667952061, -0.015990009531378746, 0.006919673178344965, 0.014037343673408031, -0.01563498005270958, -0.017300890758633614, -0.03501142933964729, -0.05063275620341301, 0.019594930112361908, 0.04787444323301315, -0.05112433433532715, 0.008657272905111313, 0.02722807787358761, 0.07248076051473618, 0.05150667577981949, 0.014460649341344833, 0.017109720036387444, -0.04219396412372589, 0.022544411942362785, -0.032744698226451874, -0.01370962429791689, -0.042904023081064224, 0.013975896872580051, 0.021219875663518906, -0.007401012349873781, -0.0029682565946131945, 0.007510252296924591, -0.042521681636571884, 0.03146113082766533, -0.0022718512918800116, 0.01104007102549076, 0.012733290903270245, 0.017000479623675346, -0.012207573279738426, -0.015908079221844673, 0.0007817489677108824, -0.030996859073638916, 0.020400576293468475, 0.034465231001377106, 0.013812036253511906, 0.04784713312983513, 0.00992718804627657, -0.01979975588619709, 0.016727380454540253, 0.05604013800621033, 0.014924919232726097, 0.030423348769545555, 0.01551208458840847, 0.052681006491184235, 0.012712808325886726, 0.008233967237174511, 0.01050069835036993, 0.039626821875572205, 0.019895341247320175, 0.03380978852510452, -0.014324098825454712, 0.03129727020859718, 0.04121080040931702, -0.00974284578114748, 0.006834329571574926, -0.036977749317884445, -0.003082617186009884, -0.008022314868867397, 0.020414231345057487, 0.03834325075149536, 0.02004554495215416, -0.004953352734446526, 0.0068445708602666855, -0.0012263900134712458, -0.011647718027234077, -0.024797488003969193, -0.005253762938082218, 0.028265858069062233, 0.00875968486070633, 0.019772445783019066, -0.007988177239894867, -0.04710976406931877, 0.0068513983860611916, 0.00870506465435028, 0.021233530715107918, 0.05216211453080177, -0.03189808875322342, -0.02232593111693859, -0.02786986343562603, -0.05341837555170059, 0.012111988849937916, -0.016440624371170998, 0.04568964242935181, 0.03656810149550438, 0.07269924134016037, -0.02452438697218895, -0.020223060622811317, 0.03271738812327385, -0.002205283148214221, 0.057132538408041, -0.01428313460201025, -0.022175725549459457, -0.018707355484366417, -0.005830686539411545, 0.010657730512320995, -0.04872105270624161, -0.02647705189883709, -0.07428321987390518, 0.010514353401958942, 0.007203014567494392, 0.016563519835472107, -0.0119822658598423, 0.03198001906275749, -0.010459733195602894, 0.006923086941242218, 0.004786078818142414, -0.005960409063845873, 0.009326367639005184, -0.0062608192674815655, -0.009722363203763962, -0.05707791820168495, 0.025889888405799866, 0.00316113349981606, 0.02647705189883709, 0.0022650237660855055, -0.023158887401223183, 0.03869828209280968, 0.009954498149454594, -0.003932641353458166, -0.020892156288027763, -0.004233051091432571, -0.04929456487298012, -0.005868237931281328, 0.030669139698147774, 0.01816115528345108, -0.05464732646942139, -0.03233505040407181, -0.04836602509021759, -0.023227162659168243, 0.03593996912240982, -0.04812023416161537, -0.07155222445726395, -0.05931733548641205, -0.020482506603002548, 0.031870778650045395, 0.00015159188478719443, -0.054947737604379654, 0.0066056083887815475, -0.06838425993919373, -0.004345704801380634, -0.011688683182001114, 0.010104702785611153, 0.018338670954108238, 0.015334569849073887, 0.027528487145900726, 0.02061905525624752, -0.008664100430905819, 0.015867114067077637, -0.028921298682689667, -0.024196667596697807, 0.027760623022913933, 0.06570787727832794, -0.028784748166799545, -0.06450624018907547, 0.04664549231529236, 0.004963594023138285, 0.0032891491428017616, -0.025739682838320732, -0.005158177576959133, -0.02703690715134144, -0.02919439785182476, 0.03790629282593727, 0.027951793745160103, 0.004441290162503719, 0.031679607927799225, 0.006779709365218878, -0.011572616174817085, -0.01943107135593891, 0.007394184824079275, 0.01478836964815855, 0.008664100430905819, -0.05074199661612511, -0.08864828944206238, 0.051479365676641464, 0.0008171666413545609, -0.01614021509885788, 0.02199821174144745, -0.06264916062355042, 0.014965884387493134, -0.013381903991103172, 0.021766075864434242, 0.013477489352226257, 0.04743748530745506, -0.015238984487950802, -0.039435651153326035, 0.0259854719042778, 0.022039176896214485, -0.012774256058037281, 0.006492954213172197, 0.05756949633359909, -0.018502529710531235, -0.018202120438218117, -0.01650889962911606, 0.0014320685295388103, 0.0346837118268013, 0.03233505040407181, 0.03285393863916397, 0.019198935478925705, 0.05131550505757332, 0.049704212695360184, -0.023090612143278122, 0.011360962875187397, 0.011702338233590126, 0.018707355484366417, 0.009606295265257359, -0.02358219213783741, 0.020277680829167366, 0.06423313915729523, -0.018447909504175186, 0.03318165987730026, 0.03949027135968208, 0.015853459015488625, -0.04140197113156319, 0.046618182212114334, -0.013791553676128387, -0.015539394691586494, -0.04844795539975166, 0.0244697667658329, 0.007906246930360794, 0.052626386284828186, 0.008056452497839928, -0.012849358841776848, -0.02433321624994278, 0.012835703790187836, 0.0265999473631382, 0.002695156494155526, -0.013812036253511906, -0.009681398048996925, -0.051479365676641464, 0.06652718037366867, 0.022148417308926582, -0.04426952451467514, -0.05240790545940399, -0.007626319769769907, -0.027951793745160103, 0.02149297669529915, 0.041074253618717194, -0.0026012782473117113, -0.02157490700483322, -0.002814637729898095, -0.020127475261688232, 0.03148844093084335, 0.0037278160452842712, -0.0054415189661085606, 0.0038234011735767126, 0.0033369415905326605, -0.03501142933964729, 0.019567620009183884, 0.03776974231004715, -0.026326848194003105, -0.027596762403845787, -0.031379200518131256, -0.040883082896471024, 0.007523907348513603, 0.01709606498479843, 0.02281751111149788, 0.057351015508174896, -0.0050660064443945885, 0.026258572936058044, -0.010528008453547955, -0.01739647425711155, -0.07586719840765, -0.011681855656206608, -0.021738765761256218, -0.04538923501968384, -0.020851191133260727, -0.008930373005568981, 0.00501138623803854, -0.07007747888565063, -0.013661831617355347, 0.012180263176560402, -0.015867114067077637, -0.007387357298284769, 0.03487487882375717, 0.021848006173968315, -0.0007727878983132541, 0.025575822219252586, 0.010780625976622105, 0.05131550505757332, -0.08329552412033081, -0.037933599203825, -0.004523220006376505, -0.018680045381188393, -0.04686397314071655, 0.04394180327653885, -0.014911264181137085, 0.030041009187698364, -0.006694365758448839, -0.004659770056605339, 0.020086510106921196, 0.013101976364850998, -0.025930851697921753, -0.011989093385636806, -0.027569452300667763, -0.024920381605625153, -0.027064217254519463, -0.03968144208192825, -0.011251723393797874, -0.006772881839424372, 0.016235800459980965, -0.0022855063434690237, -0.028538959100842476, 0.06669104099273682, -0.045361924916505814, -0.01910335011780262, -0.006318853236734867, 0.007319082040339708, -0.007612664718180895, 0.02218938060104847, 0.018761975690722466, -0.016481589525938034, 0.018447909504175186, -0.0038165736477822065, -0.04585350304841995, 0.001716263359412551, -0.023063302040100098, -0.03757857158780098, -0.004045295063406229, -0.01822943054139614, -0.018270395696163177, 0.019130660220980644, 0.04426952451467514, 0.0016991945449262857, 0.04973152279853821, -0.0011120294220745564, 0.003509335918352008, 0.019144315272569656, 0.02445611171424389, 0.019895341247320175, 0.03711429983377457, -0.034274060279130936, -0.006933328229933977, -0.01904872991144657, 0.003963364753872156, -0.0019458380993455648, 0.003987261094152927, 0.014665474183857441, -0.026217607781291008, -0.020086510106921196, -0.050277724862098694, -0.01741012930870056, 0.013238525949418545, -0.05508428439497948, -0.0009276868076995015, -0.02963135950267315, 0.02403280697762966, 0.007319082040339708, 0.05478387698531151, 0.014406029134988785, -0.006103786639869213, 0.026640912517905235, -0.03001369908452034, 0.04986807331442833, -0.0127947386354208, -0.00562927545979619, -0.016167525202035904, -0.03853442147374153, 0.0041169836185872555, 0.027378283441066742, 0.019267210736870766, 0.04418759420514107, -0.03593996912240982, 0.02384163625538349, -0.012262193486094475, -0.037988219410181046, 0.0007104869000613689, 0.023363711312413216, 0.018010949715971947, -0.022435171529650688, 0.022558066993951797, 0.022244000807404518, 0.009142025373876095, 0.01790170930325985, -0.002147249411791563, 0.009633605368435383, -0.03435599058866501, 0.003328407183289528, -0.019690515473484993, -0.03195270895957947, 0.02995907887816429, -0.0027190526016056538, 0.009305885061621666, 0.0612836591899395, -0.022913096472620964, -0.045170754194259644, 0.01459719892591238, -0.011845716275274754, 0.006236922927200794, -0.007824317552149296, -0.03279931843280792, -0.014351408928632736, 0.009340022690594196, -0.03689581900835037, 0.00559513783082366, -0.005625861696898937, 0.02157490700483322, -0.026954978704452515, 0.010951313190162182, -0.021219875663518906, 0.0075853546150028706, -0.03353669121861458, -0.025015966966748238, 0.01538918912410736, -0.006998189724981785, 0.023227162659168243, 0.006158406846225262, -0.00744197703897953, 0.009340022690594196, 0.002208696911111474, -0.0447884127497673, 0.016809310764074326, 0.017628610134124756, 0.0031628403812646866, -0.008063280023634434, -0.01226902101188898, -0.023418331518769264, 0.02685939334332943, 0.024046462029218674, -0.017369164153933525, 0.01620849035680294, -0.030532589182257652, 0.0016266523161903024, -0.040391501039266586, -0.023431986570358276, 0.005410795100033283, -0.027897173538804054, -0.038944073021411896, -0.025903543457388878, 0.04260361194610596, 0.017737850546836853, -0.03189808875322342, 0.01009104773402214, -0.02281751111149788, 0.00715522188693285, -0.0075785270892083645, 0.032061949372291565, 0.008821132592856884, -0.013361421413719654, -0.0015669116983190179, 0.014446994289755821, 0.03121533989906311, 0.040828462690114975, -0.011558961123228073, 0.02081022597849369, 0.02117891050875187, 0.0040009161457419395, 0.0069674658589065075, 0.047765202820301056, 0.045798882842063904, 0.028538959100842476, 0.026709187775850296, 0.02804737724363804, 0.0002910222683567554, -0.008466102182865143, 0.005827272776514292, 0.00769459456205368, -0.052052874118089676, 0.006441748235374689, -0.005878479219973087, 0.0012417519465088844, 0.011968610808253288, 0.018884871155023575, -0.004294498823583126, -0.013252181001007557, 0.026149332523345947, 0.005018213763833046, -0.029112469404935837, -0.017573989927768707, -0.027146147564053535, -0.017382819205522537, 0.005325451493263245, 0.0022394205443561077, -0.022353241220116615, 0.006789950653910637, -0.027842553332448006, 0.02137008123099804, -0.0060218567959964275, -0.03247160091996193, -0.01657717488706112, -0.016809310764074326, 0.03323628008365631, -0.005752170458436012, 0.013791553676128387, -0.0007424908690154552, 0.04604467377066612, -0.002515934407711029, -0.009947670623660088, -0.050660066306591034, -0.0012366313021630049, 0.039572201669216156, -0.06417851895093918, 0.012842531315982342, 0.018447909504175186, 0.01796998456120491, -0.0397360622882843, -0.01075331587344408, 0.01078745350241661, -0.014556234702467918, 0.01119027566164732, -0.023541226983070374, -0.00698112091049552, 0.029167087748646736, 0.022558066993951797, 0.019622240215539932, -0.006885535549372435, 0.027910828590393066, -0.04484303295612335, -0.00901230238378048, -0.015853459015488625, -0.011907163076102734, -0.025111552327871323, 0.017614955082535744, -0.031051479279994965, -0.02963135950267315, -0.00015329875168390572, 0.0016010492108762264, -0.09482035040855408, -0.006233509164303541, 0.03411019966006279, -0.008425137028098106, 0.0013066132087260485, -0.04235782101750374, -0.019308175891637802, -0.009531192481517792, 0.008739202283322811, -0.017683230340480804, -0.012439708225429058, -0.003983847331255674, 0.015553049743175507, -0.01645427942276001, 0.028866678476333618, -0.017232615500688553, -0.02208014205098152, -0.018202120438218117, -0.02117891050875187, -0.006045753136277199, -0.05969967693090439, -0.04683666303753853, 0.044105663895606995, -0.02452438697218895, -0.0036731960717588663, 0.026026437059044838, -0.01765592023730278, -0.055712416768074036, -0.005612206645309925, -0.0028709645848721266, 0.02711883746087551, 0.003649299731478095, 0.022025521844625473, 0.0077901799231767654, -0.0038063323590904474, 0.039763372391462326, 0.019526654854416847, -0.05502966418862343, -0.012494328431785107, 0.001117150066420436, -0.04091039299964905, 0.0003921546449419111, -0.050960473716259, -0.0018775630742311478, 0.03979068249464035, -0.01676834560930729, -0.007373702246695757, 0.015785183757543564, 0.02636781334877014, -0.012330468744039536, 0.008240794762969017, 0.0259854719042778, 0.01104007102549076, -0.01308149378746748, -0.010227598249912262, -0.011033243499696255, -0.004772423766553402, 0.003529818495735526, -0.04148390144109726, 0.013395559042692184, 0.0250842422246933, 0.005642930511385202, 0.024852106347680092, 0.008227139711380005, 0.013422869145870209, -0.0017341854982078075, -0.0022513687144964933, 0.0038268149364739656, -0.01588076911866665, 0.029522119089961052, 0.02162952721118927, 0.0552208349108696, -0.014296788722276688, -0.01270598080009222, -0.015088779851794243, 0.043286360800266266, -0.0209331214427948, -0.03826132044196129, -0.03473832830786705, -0.005031868815422058, -0.00687188096344471, -0.004089673515409231, 0.009558502584695816, -0.008404655382037163, -0.005796549376100302, -0.0429859533905983, -0.021479321643710136, 0.015170709230005741, 0.03531184047460556, 0.004509564954787493, -0.03932641074061394, -0.010992278344929218, -0.010439250618219376, -0.03544839099049568, 0.004710976500064135, 0.05541200563311577, -0.025575822219252586, 0.009066922590136528, -0.032690078020095825, -0.015211674384772778, -0.0022684375289827585, 0.031816158443689346, 0.005410795100033283, 0.002934118965640664, 0.024551697075366974, -0.006172061897814274, 0.02680477313697338, -0.0042364648543298244, 0.01753302477300167, -0.04350484162569046, 0.004881663713604212, -0.003348889760673046, -0.01650889962911606, 0.01311563141644001, 0.03790629282593727, 0.011463375762104988, -0.02401915192604065, 0.04047343134880066, -0.01689123921096325, -0.052298665046691895, 0.02149297669529915, 0.03462909162044525, -0.013231698423624039, 0.006762640550732613, 0.0014303616480901837, 0.02635415829718113, -0.0346837118268013, 0.004898732528090477, 0.0119822658598423, -0.008971337229013443, 0.024947691708803177, 0.022599032148718834, 0.017437439411878586, 0.014324098825454712, -0.008384172804653645, -0.008752857334911823, 0.05404650419950485, -0.026217607781291008, -0.0244697667658329, -0.018188465386629105, -0.014173894189298153, -0.03998185321688652, -0.039189860224723816, 0.0074556320905685425, 0.03380978852510452, -0.005472242832183838, -0.03290855884552002, -0.050851233303546906, -0.0077970074489712715, 0.026149332523345947, -0.014296788722276688, -0.01999092660844326, -0.0022974545136094093, -0.0004975541960448027, -0.03132458031177521, 0.00675922678783536, 0.0015011969953775406, 0.0036731960717588663, 0.015198019333183765, 0.012009575963020325, -0.03531184047460556, -0.04609929397702217, 0.01144289318472147, 0.021083327010273933, -0.002910222625359893, -0.010985450819134712, -0.03107878938317299, 0.008602652698755264, -0.027883518487215042, 0.013525281101465225, 0.029740598052740097, 0.030860308557748795, 0.021916281431913376, -0.03430137038230896, -0.009865740314126015, 0.007223497144877911, 0.009462918154895306, -0.014064653776586056, 0.023486606776714325, 0.027378283441066742, -0.02408742718398571, 0.0189121812582016, -0.03015024960041046, -0.00537665793672204, 0.022926751524209976, -0.011859371326863766, -0.04451531171798706, 0.027665037661790848, 0.023909911513328552, 0.03083299845457077, 0.026135677471756935, 0.007025499362498522, 0.025807958096265793, -0.01144289318472147, 0.0033335278276354074, -0.002684915205463767, 0.004840699024498463, 0.005291313864290714, 0.02232593111693859, -0.010207115672528744, -0.010350492782890797, -0.002089215675368905, -0.020100165158510208, 0.028457028791308403, 0.0249750018119812, -0.027159802615642548, -0.026053747162222862, 0.01267867162823677, -0.017929019406437874, 0.009142025373876095, -0.003939468879252672, 0.02239420637488365, -0.03337283059954643, 0.00461539113894105, -0.0005299848271533847, -0.0714976042509079, -0.037742432206869125, 0.01601731963455677, 0.0020192337688058615, 0.023309091106057167, -0.004465186502784491, -0.029740598052740097, -0.020414231345057487, -0.005489311646670103, -0.000790283374954015, 0.03318165987730026, 0.039817992597818375, -0.005851169116795063, 0.01362086646258831, 0.02421032264828682, 0.0035605423618108034, 0.01910335011780262, 0.04205741360783577, -0.021588562056422234, 0.007312254514545202, 0.028921298682689667, -0.02157490700483322, -0.03334552049636841, 0.021151600405573845, 0.0076672849245369434, 0.008527549915015697, -0.038998689502477646, 0.016003664582967758, -0.009271747432649136, -0.03820670023560524, 0.0837324857711792, 0.003983847331255674, -0.018802940845489502, 0.007564872037619352, -0.02528906799852848, 0.010507525876164436, 0.016822965815663338, -0.010732833296060562, 0.03544839099049568, -0.03689581900835037, 0.004926042631268501, 0.03501142933964729, 0.016877584159374237, -0.0189121812582016, 0.024824798107147217, -0.003519577207043767, -0.01159992627799511, -0.04009108990430832, 0.010855727829039097, 0.02750117890536785, -0.0427674725651741, -0.01670007035136223, -0.03045065887272358, 0.023937221616506577, -0.02307695709168911, 0.008616307750344276, -0.010528008453547955, -0.005137695465236902, -0.020755605772137642, 0.029412878677248955, -0.0037551261484622955, 0.012473845854401588, -0.008063280023634434, -0.005810203962028027, -0.002753190230578184, 0.007148394361138344, 0.057733356952667236, 0.042712852358818054, 0.01084890030324459, -0.011046898551285267, -0.022353241220116615, 0.00038191338535398245, 0.03853442147374153, 0.015867114067077637, -0.010623592883348465, 0.0009695052867755294, -0.031160719692707062, 0.009107887744903564, -0.02987714856863022, 0.009654087945818901, 0.06161137670278549, 0.0132999736815691, -0.030559899285435677, -0.022558066993951797, 0.024483421817421913, -0.005694136489182711, -0.00948339980095625, 0.006154993083328009, 0.019526654854416847, 0.02578064799308777, 0.00810424517840147, -0.0500592440366745, 0.024360526353120804, 0.013054183684289455, -0.009462918154895306, 0.02773331291973591, 0.0124875009059906, -0.021342771127820015, -0.006813846994191408, 0.026081057265400887, -0.0158261489123106, 0.0398453027009964, -0.009019129909574986, 0.031870778650045395, -0.0037960910703986883, 0.007353219669312239, 0.007052809465676546, 0.022244000807404518, -0.021219875663518906, -0.02755579724907875, -0.016822965815663338, -0.04123811051249504, 0.02011382021009922, -0.016235800459980965, -0.0018673217855393887, 0.03263545781373978, 0.0008466102299280465, 0.03039603866636753, -0.023677777498960495, -0.001456818194128573, -0.036595411598682404, 0.04336829110980034, -0.01842060126364231, -0.014460649341344833, 0.03088761866092682, 0.016058284789323807, 0.025261757895350456, -0.012350951321423054, 0.008220312185585499, 0.015184364281594753, -0.00479290634393692, 0.024619972333312035, -0.010118357837200165, -0.04254899173974991, -0.014774714596569538, 0.026272227987647057, 0.03320896998047829, 0.01796998456120491, -0.06324997544288635, 0.009189818054437637, 0.014870299026370049, -0.015047814697027206, -0.006274474319070578, -0.004079432226717472, -0.024073772132396698, -0.010186633095145226, -0.014010034501552582, 0.02698228694498539, -0.03539377078413963, -0.05844341591000557, 0.011483858339488506, -0.0043661873787641525, 0.02150663174688816, 0.005823859013617039, 0.02527541294693947, -0.0042398786172270775, 0.024852106347680092, -0.01201640348881483, 0.021411046385765076, 0.013177079148590565, -0.020851191133260727, -0.019062384963035583, -0.025179827585816383, -0.043477531522512436, 0.005571241490542889, -0.010220770724117756, 0.03260814771056175, 0.022844821214675903, -0.005793135613203049, -0.032881248742341995, -0.04011840000748634, -0.018898526206612587, 0.03096954897046089, 0.020264025777578354, 0.027460213750600815, -0.01626311056315899, 0.00176149548497051, -0.009701880626380444, 0.012692325748503208, -0.02213476225733757, -0.010323182679712772, 0.03662272170186043, 0.015525739639997482, 0.03738740086555481, 0.02535734325647354, 0.02168414555490017, 0.02325447089970112, 0.014829333871603012, 0.0073327370919287205, 0.024060117080807686, -0.020441541448235512, -0.019390106201171875, -0.002089215675368905, -0.015198019333183765, 0.0016437211306765676, 0.011927645653486252, 0.0336732380092144, 0.00803596992045641, -0.005885306745767593, -0.016495244577527046, -0.013730106875300407, -0.0038131598848849535, 0.020851191133260727, -0.012118816375732422, 0.0017922192346304655, 0.008950854651629925, 0.02055078186094761, -0.008766512386500835, 0.006998189724981785, 0.014965884387493134, -0.020291335880756378, -0.009974980726838112, 0.0011461669346317649, 0.004939697682857513, -0.013463834300637245, 0.03045065887272358, 0.008650445379316807, -0.03645886108279228, 0.017546679824590683, 0.014815679751336575, -0.0006823234725743532, -0.0027787932194769382, 0.002198455622419715, -0.00515476381406188, -0.01639965921640396, 0.023240815848112106, 0.02220303565263748, 0.003063841490074992, 0.04055536165833473, 0.002749776467680931, 0.03613113984465599, -0.025179827585816383, -0.019062384963035583, 0.10050082951784134, -0.03869828209280968, -0.0003251597809139639, -0.01009104773402214, 0.0033010973129421473, 0.031679607927799225, -0.004314981400966644, -0.011197103187441826, -0.015320914797484875, 0.009189818054437637, 0.021452011540532112, -0.0335640013217926, -0.0023640226572752, 0.0065100230276584625, -0.008657272905111313, 0.005997960455715656, -0.011463375762104988, -0.01144289318472147, -0.026586292311549187, -0.006025270558893681, -0.01758764497935772, 0.010691868141293526, -0.02623126283288002, -0.010166150517761707, -0.027706002816557884, 0.013272663578391075, -0.028975918889045715, 0.01162723544985056, 0.041511211544275284, -0.012938116677105427, -0.02049616165459156, -0.002587623195722699, 0.020823881030082703, 0.009032784961163998, 0.02370508760213852, 0.00027331343153491616, -0.032498911023139954, -0.0010855727596208453, 0.007981349714100361, -0.015921734273433685, -0.0014576716348528862, -0.025521202012896538, 0.013921276666224003, -0.014365063980221748, -0.0022923338692635298, -0.011750130914151669, 0.028156617656350136, 0.030177559703588486, 0.0021557838190346956, -0.016631795093417168, -0.01727358065545559, 0.011654545553028584, 0.032444290816783905, 0.003290856024250388, 0.021397391334176064, -0.002872671466320753, -0.005994546692818403, 0.02201186679303646, 0.022530756890773773, 0.009101060219109058, -0.021848006173968315, -0.02421032264828682, 0.0001270555512746796, -0.022407861426472664, -0.014829333871603012, -0.011463375762104988, -0.05423767492175102, -0.028921298682689667, 0.01488395407795906, 0.03503873944282532, -0.00047195106162689626, 0.00021015905076637864, -0.019690515473484993, 0.0031628403812646866, 0.03733278065919876, 0.009428780525922775, 0.0022206450812518597, -0.020250370725989342, 0.0023879187647253275, 0.01835232600569725, 0.017314545810222626, -0.01488395407795906, 0.041265420615673065, 0.02005920000374317, 0.004024812486022711, 0.012350951321423054, -0.005762411747127771, 0.020755605772137642, 0.009633605368435383, -0.006704607047140598, 0.0060184430330991745, 0.0023640226572752, -0.008056452497839928, -0.005711205303668976, 0.0044515314511954784, -0.02124718576669693, -0.006544160656630993, -0.009640432894229889, 0.012344123795628548, 0.001279303221963346, 0.010589455254375935, 0.008780167438089848, -0.019895341247320175, -0.0012912512756884098, -0.04339560121297836, -0.017259925603866577, 0.026777463033795357, -0.0018246498657390475, 0.016304073855280876, -0.03454716131091118, 0.010425595566630363, -0.013614038936793804, -0.015129744075238705, -0.013893966563045979, 0.025821613147854805, 0.0007407839875668287, -0.022025521844625473, -0.006175475660711527, 0.004171603824943304, -0.013750589452683926, 0.02169780060648918, 0.022913096472620964, 0.012671844102442265, -0.02206648699939251, 0.010842072777450085, 0.025889888405799866, 0.0070869470946490765, 0.013893966563045979, 0.029330948367714882, -0.00908057764172554, 0.00023426866391673684, -0.00012257500202395022, 0.024005496874451637, 0.0029648428317159414, 0.02679111808538437, -0.011272205971181393, -0.0009985221549868584, -0.0028470682445913553, -0.01374376192688942, -0.0064758858643472195, -0.019472036510705948, 0.004492496140301228, 0.020591745153069496, -0.01507512480020523, 0.005690722726285458, 0.02471555769443512, -0.00781749002635479, -0.009592640213668346, -0.022025521844625473, 0.008834787644445896, -0.007250807248055935, 0.03473832830786705, -0.02837509848177433, 0.005984305404126644, -0.005120626650750637, -0.0129927359521389, 0.011094690300524235, 0.012030058540403843, -0.032061949372291565, -0.014296788722276688, -0.016563519835472107, 0.01390762161463499, -0.0011837182100862265, -0.05360954627394676, 0.0061379242688417435, 0.02604009211063385, 0.0018690286669880152, 0.005578069016337395, -0.01370962429791689, -0.03512066975235939, 0.00176149548497051, -0.03088761866092682, -0.01416023913770914, 0.018243085592985153, 0.0712791234254837, -0.04577157273888588, -0.002188214333727956, 0.013600383885204792, -0.028648197650909424, -0.002551778918132186, -0.0010949606075882912, -0.018051914870738983, 0.008500239811837673, 0.018488874658942223, -0.0003072375839110464, 0.017164340242743492, -0.02313157729804516, -0.0316522978246212, -0.008554860018193722, -0.050468895584344864, 0.04402373358607292, 0.011804751120507717, 0.011709165759384632, -0.002509106881916523, -0.005246935412287712, 0.01210516132414341, -0.018488874658942223, -0.005970650352537632, -0.011804751120507717, -0.0017469871090725064, 0.013736934401094913, 0.0009114714921452105, -0.012262193486094475, 0.03561225160956383, 0.00860948022454977, -0.007564872037619352, 0.054893117398023605, 0.014515269547700882, -6.848837801953778e-05, -0.0044822548516094685, 0.02832047827541828, 0.03599458932876587, -0.04112887382507324, 0.023568537086248398, 0.022872131317853928, 0.014474304392933846, -0.019021419808268547, 0.009490227326750755, -0.025616787374019623, -0.016973169520497322, 0.003652713494375348, -0.007052809465676546, 0.0017922192346304655, -0.018488874658942223, -0.00839100033044815, 0.011668200604617596, -0.007394184824079275, -0.02924901805818081, -0.012296331115067005, 0.02629953809082508, 0.014146584086120129, -0.024920381605625153, -0.02680477313697338, 0.0016036095330491662, -0.01999092660844326, 0.023759707808494568, -0.014610853977501392, 0.0009311005705967546, -0.03484756872057915, -0.010568972676992416, -0.024729212746024132, -0.02274923585355282, -0.010828417725861073, 0.03563956171274185, -0.0234592966735363, 0.028402408584952354, 0.030232178047299385, -0.020004581660032272, 0.03831594064831734, -0.0037721949629485607, 0.03315434977412224, 0.017055099830031395, -0.0010002290364354849, 0.029549429193139076, 0.018761975690722466, -0.03853442147374153, -0.00016951406723819673, 0.0029426533728837967, 0.035721492022275925, -0.017546679824590683, 0.036295000463724136, 0.01078745350241661, 0.02812930755317211, -0.014132929034531116, 0.00305018643848598, -0.005332279019057751, -0.0032959766685962677, 0.028402408584952354, 0.006861639674752951, -0.016918549314141273, -0.004031640011817217, -0.007059636991471052, -0.014119273982942104, -0.020946776494383812, 0.008582170121371746, 0.025575822219252586, -0.0021779730450361967, 0.014692784287035465, -0.0056463442742824554, -0.0199226513504982, -0.012371433898806572, 0.007639974821358919, -0.053117964416742325, -0.004881663713604212, -0.015785183757543564, -0.014201204292476177, 0.004915801342576742, 0.035284530371427536, -0.0013296559918671846, 0.004058950114995241, 0.014624509029090405, -0.010084220208227634, -0.0027770863380283117, 0.03787898272275925, 0.007558044511824846, 0.0036766098346561193, -0.004990904126316309, 0.0009379280963912606, 0.016194835305213928, 0.020660020411014557, 0.002256489358842373, -0.0015148520469665527, 0.0265999473631382, 0.003164547262713313, 0.005499552935361862, 0.01594904437661171, 0.0076672849245369434, -0.021902626380324364, -0.0042091547511518, 0.014515269547700882, -0.007203014567494392, 0.013142941519618034, 0.0008146063191816211, 0.03462909162044525, -0.01396224182099104, 0.010227598249912262, 0.04798368364572525, 0.03064182959496975, -0.013327283784747124, 0.009121542796492577, 0.0019731479696929455, 0.030232178047299385, 0.009237609803676605, 0.010575800202786922, 0.058989617973566055, -0.020031891763210297, 0.006612435448914766, -0.021042361855506897, 0.028593577444553375, -0.020072855055332184, 0.013265836052596569, -0.003840469755232334, 0.008397827856242657, -0.030914928764104843, 0.06559863686561584, -0.004874836187809706, 0.0005513207870535553, 0.019444726407527924, 0.017642265185713768, -0.03992723301053047, -0.033946339040994644, 0.012562603689730167, 0.015198019333183765, 0.0070937746204435825, 0.0398453027009964, 0.025452926754951477, -0.008445619605481625, 0.010637247934937477, 0.002746362704783678, 0.00755121698603034, -0.01892583630979061, 0.002049957402050495, 0.02968597784638405, 0.028702817857265472, -0.02982252836227417, 0.003536646021530032, 0.007141567301005125, -0.020264025777578354, -0.030368728563189507, 0.0061447517946362495, 0.033509381115436554, -0.010924003086984158, -0.002732707653194666, 0.011333653703331947, -0.002894860925152898, 0.04416028410196304, -0.032007329165935516, 0.03820670023560524, 0.02352757193148136, 0.006062821950763464, -0.02528906799852848, 0.002403280697762966, 0.01216660812497139, -0.04375063255429268, -0.008534377440810204, -0.005270831752568483, -0.005209384020417929, 0.06527091562747955, 0.0099613256752491, -0.02786986343562603, 0.038807522505521774, -0.017259925603866577, 0.008725547231733799, 0.04798368364572525, -0.013074666261672974, 0.005786308087408543, -0.03768781200051308, -0.01028221845626831, -0.0033232865389436483]\n"
          ]
        }
      ],
      "source": [
        "response = client.embeddings.create(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    input=\"I am a programmer\",\n",
        ")\n",
        "print(response.data[0].embedding)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoaNYnZ8wyo-"
      },
      "source": [
        "### 16-2 다중 입력 사용 예제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAH0T-B-xDUE",
        "outputId": "17ecd092-da35-4ae3-ecd0-f14e4a2e0851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력 0의 임베딩: [0.028793223202228546, 0.016364755108952522, -0.05375950038433075, -0.052046485245227814, 0.028046056628227234]..(truncated)\n",
            "입력 1의 임베딩: [0.052467718720436096, 0.00905882939696312, -0.03377489373087883, -0.04818594455718994, 0.03129849582910538]..(truncated)\n"
          ]
        }
      ],
      "source": [
        "model = \"text-embedding-3-small\"\n",
        "inputs = [\n",
        "    \"나는 프로그래머입니다\",\n",
        "    \"나는 작가입니다\"\n",
        "]\n",
        "response = client.embeddings.create(\n",
        "    model=model,\n",
        "    input=inputs,\n",
        ")\n",
        "for i, embedding in enumerate(response.data):\n",
        "    print(\n",
        "        f\"입력 {i}의 임베딩: \"\n",
        "        f\"{embedding.embedding[:5]}..(truncated)\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1JNivzxwHs2"
      },
      "source": [
        "### 16-4. 코사인 유사도 쉽게 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80xwaLohxU7p"
      },
      "source": [
        "### 코사인 유사도 탐색"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X9soEaFxb1T",
        "outputId": "0bd88ef0-dcd3-4dac-a1c4-dd7e77c42c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "벡터 A: [2 3 5 2 6 7 9 2 3 4]\n",
            "벡터 B: [3 6 3 1 0 9 2 3 4 5]\n",
            "A와 B 사이의 코사인 유사도: 0.7539959431593041\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# 두 벡터 정의\n",
        "A = np.array([2,3,5,2,6,7,9,2,3,4])\n",
        "B = np.array([3,6,3,1,0,9,2,3,4,5])\n",
        "\n",
        "# 벡터 출력\n",
        "print(\"벡터 A: {}\".format(A))\n",
        "print(\"벡터 B: {}\".format(B))\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
        "\n",
        "# 코사인 유사도 출력\n",
        "print(\n",
        "    \"A와 B 사이의 코사인 유사도: \"\n",
        "    f\"{cosine}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFMR9MZESq2k",
        "outputId": "8b6b66c5-b112-44e5-fcf6-5d3eb98691e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numpy                              1.26.4\n"
          ]
        }
      ],
      "source": [
        "!pip list | grep numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iC7hMaCxcQs"
      },
      "source": [
        "### 예제2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn4slJM9xiyE",
        "outputId": "a2f57f5a-0ea0-457a-ea49-b5c140cd0bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "벡터 A: [2 3 5 2 6 7 9 2 3 4]\n",
            "벡터 B: [3 6 3 1 0 9 2 3 4 5]\n",
            "A와 B 사이의 코사인 유사도: 0.7539959431593041\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy import spatial\n",
        "\n",
        "# 두 벡터 정의\n",
        "A = np.array([2,3,5,2,6,7,9,2,3,4])\n",
        "B = np.array([3,6,3,1,0,9,2,3,4,5])\n",
        "\n",
        "# 벡터 출력\n",
        "print(f\"벡터 A: {A}\")\n",
        "print(f\"벡터 B: {B}\")\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "# 1에서 코사인 거리를 빼서 유사도를 구함\n",
        "cosine = 1 - spatial.distance.cosine(A, B)\n",
        "\n",
        "# 코사인 유사도 출력\n",
        "print(f\"A와 B 사이의 코사인 유사도: {cosine}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXnNP9XtxjcE"
      },
      "source": [
        "### 예제 3 - p120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGcggx9Exjfd",
        "outputId": "71e89fde-3167-4f22-80f9-9db7b1c0377d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "벡터 A: [2 3 5 2 6 7 9 2 3 4]\n",
            "벡터 B: [3 6 3 1 0 9 2 3 4 5]\n",
            "코사인 유사도: 0.7539959431593041\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 두 벡터 정의\n",
        "A = np.array([2, 3, 5, 2, 6, 7, 9, 2, 3, 4])\n",
        "B = np.array([3, 6, 3, 1, 0, 9, 2, 3, 4, 5])\n",
        "\n",
        "# 벡터 출력\n",
        "print(f\"벡터 A: {A}\")\n",
        "print(f\"벡터 B: {B}\")\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "cosine = cosine_similarity([A], [B])\n",
        "\n",
        "# 코사인 유사도 출력\n",
        "print(f\"코사인 유사도: {cosine[0][0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RuRbDiyxjjP",
        "outputId": "3b751303-4994-48ab-9250-f3aad3874ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy를 사용한 A와 B 사이의 코사인 유사도: 0.7539959431593041\n",
            "SciPy를 사용한 A와 B 사이의 코사인 유사도: 0.7539959431593041\n",
            "Scikit-learn을 사용한 A와 B 사이의 코사인 유사도: 0.7539959431593041\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from scipy import spatial\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 두 벡터 정의\n",
        "A = np.array([2,3,5,2,6,7,9,2,3,4])\n",
        "B = np.array([3,6,3,1,0,9,2,3,4,5])\n",
        "\n",
        "# NumPy를 사용하여 코사인 유사도 계산\n",
        "cosine_np = np.dot(A,B)/(norm(A)*norm(B))\n",
        "\n",
        "# 코사인 유사도 출력\n",
        "print(f\"NumPy를 사용한 A와 B 사이의 코사인 유사도: {cosine_np}\")\n",
        "\n",
        "# SciPy를 사용하여 코사인 유사도 계산\n",
        "cosine_sc = 1 - spatial.distance.cosine(A, B)\n",
        "\n",
        "# 코사인 유사도 출력\n",
        "print(f\"SciPy를 사용한 A와 B 사이의 코사인 유사도: {cosine_sc}\")\n",
        "\n",
        "# Scikit-learn을 사용하여 코사인 유사도 계산\n",
        "cosine_sk = cosine_similarity([A], [B])\n",
        "\n",
        "# 코사인 유사도 출력\n",
        "print(f\"Scikit-learn을 사용한 A와 B 사이의 코사인 유사도: {cosine_sk[0][0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqwqO3dsHQSH"
      },
      "source": [
        "### 16-5 오픈AI 텍스트 임베딩 사용 예제"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "16.6 임베딩의 내부 작동 원리"
      ],
      "metadata": {
        "id": "BzxD9ROXACzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbjFGG3Vxjm0"
      },
      "source": [
        "```\n",
        "apple\n",
        "banana\n",
        "cherry\n",
        "dog\n",
        "cat\n",
        "house\n",
        "car\n",
        "tree\n",
        "phone computer television book\n",
        "music\n",
        "food\n",
        "water\n",
        "sky\n",
        "air\n",
        "sun\n",
        "moon\n",
        "star\n",
        "ocean\n",
        "desk\n",
        "bed\n",
        "sofa\n",
        "lamp\n",
        "carpet\n",
        "window\n",
        "door\n",
        "floor\n",
        "ceiling\n",
        "wall\n",
        "clock\n",
        "watch\n",
        "jewelry\n",
        "ring\n",
        "necklace\n",
        "bracelet\n",
        "earring\n",
        "wallet\n",
        "key\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJFF4nZIWWL_",
        "outputId": "86ad0565-4840-4833-8ab9-fd533150ae8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-19 09:57:07--  https://raw.githubusercontent.com/LDJWJ/OpenAIGPTForPythonDevelopersFiles/main/datasets/ch16_textEmbedding/words.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 249 [text/plain]\n",
            "Saving to: ‘words.csv’\n",
            "\n",
            "words.csv           100%[===================>]     249  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-19 09:57:08 (8.12 MB/s) - ‘words.csv’ saved [249/249]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/LDJWJ/OpenAIGPTForPythonDevelopersFiles/main/datasets/ch16_textEmbedding/words.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9LDHRfJxjp9",
        "outputId": "7f4e3dc1-622f-4286-9377-8c601bb56dfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          text\n",
            "0        apple\n",
            "1       banana\n",
            "2       cherry\n",
            "3          dog\n",
            "4          cat\n",
            "5        house\n",
            "6          car\n",
            "7         tree\n",
            "8        phone\n",
            "9     computer\n",
            "10  television\n",
            "11        book\n",
            "12       music\n",
            "13        food\n",
            "14       water\n",
            "15         sky\n",
            "16         air\n",
            "17         sun\n",
            "18        moon\n",
            "19        star\n",
            "20       ocean\n",
            "21        desk\n",
            "22         bed\n",
            "23        sofa\n",
            "24        lamp\n",
            "25      carpet\n",
            "26      window\n",
            "27        door\n",
            "28       floor\n",
            "29     ceiling\n",
            "30        wall\n",
            "31       clock\n",
            "32       watch\n",
            "33     jewelry\n",
            "34        ring\n",
            "35    necklace\n",
            "36    bracelet\n",
            "37     earring\n",
            "38      wallet\n",
            "39         key\n",
            "40       photo\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('words.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tWqrTa4xjtR"
      },
      "source": [
        "### 각 단어에 대한 임베딩 얻기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxfXo3ri4qbH",
        "outputId": "8b24cad2-d3f9-4558-bb0d-0b416609321d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          text\n",
            "0        apple\n",
            "1       banana\n",
            "2       cherry\n",
            "3          dog\n",
            "4          cat\n",
            "5        house\n",
            "6          car\n",
            "7         tree\n",
            "8        phone\n",
            "9     computer\n",
            "10  television\n",
            "11        book\n",
            "12       music\n",
            "13        food\n",
            "14       water\n",
            "15         sky\n",
            "16         air\n",
            "17         sun\n",
            "18        moon\n",
            "19        star\n",
            "20       ocean\n",
            "21        desk\n",
            "22         bed\n",
            "23        sofa\n",
            "24        lamp\n",
            "25      carpet\n",
            "26      window\n",
            "27        door\n",
            "28       floor\n",
            "29     ceiling\n",
            "30        wall\n",
            "31       clock\n",
            "32       watch\n",
            "33     jewelry\n",
            "34        ring\n",
            "35    necklace\n",
            "36    bracelet\n",
            "37     earring\n",
            "38      wallet\n",
            "39         key\n",
            "40       photo\n",
            "[-0.003191132564097643, -0.007989912293851376, -0.013196242973208427, -0.015193721279501915, -0.013892138376832008, 0.00029317825101315975, -0.002801302121952176, -0.045027025043964386, -0.0031218649819493294, -0.018608763813972473, 0.04250118136405945, 0.01198486890643835, 0.01191399060189724, -0.007203808519989252, -0.01829947717487812, -0.0019201564136892557, 0.02770695462822914, 0.004507212899625301, 0.017358729615807533, -0.01868608593940735, -0.011462947353720665, 0.017887094989418983, -0.011153660714626312, -0.00043694835039786994, -0.008576269261538982, 0.011121443472802639, -0.002646658569574356, -0.016804590821266174, -0.004578091204166412, 0.00399817805737257, -4.321660890127532e-05, -0.007435773499310017, -0.014768451452255249, -0.0198974609375, -0.040568139404058456, -0.0009125575888901949, 0.0015778467059135437, 0.010122704319655895, 0.00018746493151411414, -0.011514495126903057, 0.010309564881026745, 0.0011864054249599576, -0.013814817182719707, 0.004001399967819452, 0.0019958673510700464, -0.004768173675984144, -0.017320068553090096, -0.0006987146334722638, -0.021791841834783554, 0.017822660505771637, 0.0014256194699555635, 0.01814483478665352, 0.002748143393546343, -0.006147078238427639, -0.002653102157637477, 0.0025741695426404476, 0.0009141684276983142, -0.008002799935638905, 0.011675582267343998, -0.002954334719106555, 0.0028625151608139277, -0.012590556405484676, 0.007390669081360102, -0.003012326080352068, -0.006726990919560194, -0.016946347430348396, -0.01792575605213642, -0.0027143151964992285, -0.021972259506583214, 0.0029333934653550386, 0.03600615635514259, 0.010431990958750248, 0.0075968606397509575, -0.02360890433192253, 0.023183634504675865, 0.01076060812920332, -0.0106639564037323, 0.014523599296808243, 0.003891860833391547, -0.007629077881574631, 0.01619890332221985, -0.016263337805867195, -0.01306737307459116, 0.01868608593940735, 0.0217016339302063, -0.011572486720979214, -0.005721808411180973, 0.028866780921816826, -0.013492642901837826, 0.0005428630392998457, 0.02043871209025383, 0.008035017177462578, 0.007745060604065657, 0.013093147426843643, -0.009884295053780079, 0.009310825727880001, -0.010348225943744183, 0.03092869371175766, -0.007848156616091728, -0.030103929340839386, -0.00675276480615139, 0.013750381767749786, -0.04188260808587074, -0.014510712586343288, -0.012558338232338428, -0.011462947353720665, -0.016121581196784973, -0.011791564524173737, 0.025696590542793274, -0.014497825875878334, -0.0019636498764157295, 0.039202120155096054, 0.007745060604065657, -0.04729512706398964, -0.01067039929330349, -0.009819860570132732, 0.02734612114727497, -0.02222999930381775, -0.0011815727921202779, -0.023505806922912598, 0.0005247407243587077, 0.03804229572415352, 0.02186916396021843, -0.0015456292312592268, 0.012996494770050049, -0.001050286926329136, 0.00342148682102561, -0.027629634365439415, -0.0015287151327356696, 0.011269642971456051, 0.030438989400863647, 0.0025322868023067713, 0.007487321272492409, 0.011675582267343998, -0.0032394586596637964, 0.025980103760957718, -0.020567581057548523, 0.025309981778264046, -0.015618991106748581, -0.042913563549518585, -0.0041044955141842365, 0.03157304227352142, -0.01219105999916792, 0.010560860857367516, 0.0018218933837488294, 0.030851373448967934, 0.01688191294670105, 0.003270065179094672, -0.008647147566080093, -0.014278747141361237, 0.010129147209227085, -0.028737911954522133, 0.010689729824662209, -0.0016197293298318982, 0.005467290990054607, 0.01465246919542551, 0.002097352175042033, 0.0001878676557680592, -0.016314886510372162, -0.01722986064851284, 0.006920295301824808, 0.012107294984161854, 0.025000695139169693, -0.0156705379486084, 0.030335893854498863, 0.031057564541697502, 0.026199182495474815, -0.023750659078359604, -0.009897181764245033, 0.005483399610966444, -0.002345426008105278, -0.0005126592004671693, -0.017448939383029938, 0.03603192791342735, -0.01520660798996687, 0.003927299752831459, 0.008911330252885818, 0.002063523745164275, -0.025271320715546608, -0.017809772863984108, -0.02491048537194729, 0.01395657379180193, 0.012390808202326298, 0.01917579025030136, 0.012558338232338428, -0.0016833586851134896, 0.022255772724747658, -0.01447205152362585, -0.0014860271476209164, -0.012268382124602795, -0.006288834381848574, 0.02364756353199482, -0.023196520283818245, -0.017023669555783272, -0.6903284788131714, -0.02308053895831108, 0.035645321011543274, -2.2640268070972525e-05, 0.02739766798913479, 0.004613530356436968, 0.00567992590367794, -0.001213790150359273, 0.008718025870621204, 0.012139512225985527, -0.003753325901925564, 0.006053647492080927, 0.01829947717487812, 0.008215434849262238, -0.004542652051895857, -0.005367417354136705, 0.00024706710246391594, -0.0006334744393825531, -0.0053706387989223, 0.0076935128308832645, -0.011901103891432285, -0.004107717424631119, -0.01447205152362585, 0.011160103604197502, -0.0012991662370041013, -0.007184477988630533, 0.004474995657801628, -0.0007784526678733528, -0.004848717246204615, 0.020322728902101517, -0.02006499096751213, 0.03360918164253235, -0.009665217250585556, -0.011501608416438103, 0.045774467289447784, -0.0167272686958313, -0.008402295410633087, 0.039021704345941544, 0.014459164813160896, 0.035078294575214386, -0.009033756330609322, -0.02202380821108818, 0.014704016968607903, -0.007854599505662918, -0.029047198593616486, -0.0023228737991303205, 0.007332677952945232, -0.005924778059124947, -0.0039047477766871452, 0.001415954320691526, 0.01226193830370903, -0.018518555909395218, 0.005244991276413202, 0.021598538383841515, -0.02134079858660698, -0.005486621521413326, 0.020477373152971268, -0.012874068692326546, 0.015412799082696438, 0.02201092056930065, 0.011063451878726482, 0.008118782192468643, 0.004671521484851837, -0.023737773299217224, -0.013086703605949879, -0.0038274258840829134, -0.02384086884558201, 0.008299199864268303, 0.009536347351968288, 0.004014286678284407, 0.0015560999745503068, 0.013479756191372871, -0.033506084233522415, 0.028712138533592224, 0.02186916396021843, 0.02791314758360386, 0.02186916396021843, -0.016405094414949417, 0.0010800879681482911, -0.018570102751255035, 0.00023478422372136265, -0.002872180426493287, -0.021572764962911606, 0.007506651803851128, 0.01972992904484272, -0.0088919997215271, -0.023866642266511917, 0.010438434779644012, 0.010032495483756065, 0.002715925918892026, 0.015271042473614216, 0.025812573730945587, 0.002728812862187624, -0.001192043418996036, 0.005531725939363241, 0.014008121564984322, -0.006527243182063103, 0.01511639915406704, 0.020657790824770927, -0.01315758191049099, -0.0009214173769578338, 0.0025451737456023693, 0.00025028883828781545, -0.0015722085954621434, 0.006875190883874893, -0.012268382124602795, -0.0025999434292316437, 0.007603303994983435, 0.028377076610922813, -0.009033756330609322, -0.0014441445237025619, 0.017384503036737442, -0.012281268835067749, 0.007107156328856945, 0.020155198872089386, -0.025000695139169693, 0.03497519716620445, -0.014910208061337471, 0.009304381906986237, -0.023222295567393303, 0.005882895551621914, 0.012087964452803135, 0.013647286221385002, -0.010425547137856483, 0.01617312990128994, 0.0052772085182368755, -0.021057285368442535, 0.010348225943744183, -0.037062887102365494, -0.0035020303912460804, -0.0020232521928846836, 0.0071715908125042915, 0.016765929758548737, -0.007583973463624716, 0.01850566826760769, -0.00942036509513855, 0.018969599157571793, 0.0028625151608139277, 0.02809356339275837, 0.018235042691230774, -0.015696313232183456, -0.005058130249381065, -0.02701105922460556, 0.027062607929110527, 0.006881634704768658, -0.012661434710025787, -0.003914413042366505, -0.016134468838572502, 0.011688468977808952, 0.03518138825893402, -0.009317269548773766, -0.007564643397927284, -0.018067512661218643, -0.015567443333566189, 0.001960428198799491, 0.00108894775621593, -0.00907241739332676, -0.026070311665534973, -0.02488471195101738, -0.00306387385353446, 0.021946486085653305, 0.008556938730180264, -0.008576269261538982, 0.0011477444786578417, -0.012500347569584846, -0.021276364102959633, -0.011295417323708534, 0.04090319946408272, -0.017345841974020004, -0.016469528898596764, -0.03250090405344963, -0.002922117244452238, 0.012049304321408272, -0.0004288940108381212, -0.005886116996407509, 0.0007627467275597155, -0.004539430141448975, -0.03443394601345062, -0.01359573844820261, 0.002509734593331814, 0.021714521571993828, 0.000812280923128128, 0.009317269548773766, -0.021920712664723396, 0.029201842844486237, 0.008395851589739323, 0.01085081696510315, 0.004478217102587223, -0.00035096818464808166, 0.007139373570680618, -0.01597982458770275, 0.0028431846294552088, 0.0027449217159301043, 0.007422886788845062, 0.0007703983574174345, -0.02987196482717991, 0.0027449217159301043, 0.017822660505771637, 0.005631599575281143, 0.009336600080132484, -0.014729790389537811, 0.00852472148835659, 0.022603720426559448, -0.0016994673060253263, 0.00435579102486372, -0.01458803378045559, -0.014072556048631668, -0.018003078177571297, 0.019304659217596054, 0.018544329330325127, 0.006504691205918789, 0.004510434810072184, -0.003241069382056594, -0.023389825597405434, 0.00728113017976284, 0.019871685653924942, -0.004049725830554962, 0.004739177878946066, 0.0017075216164812446, 0.003988512791693211, -0.003875751979649067, -0.006134191062301397, 0.013479756191372871, -4.9785936425905675e-05, 0.003804873675107956, 0.0037339956033974886, 0.0076226345263421535, 0.02752653881907463, 0.01341532077640295, -0.021211929619312286, -0.028892556205391884, 0.005760469473898411, 0.015387025661766529, 0.006797869224101305, -0.014343181625008583, -0.012558338232338428, 0.014149878174066544, -0.017165426164865494, 0.03822271153330803, 0.009755426086485386, -0.019433530047535896, 0.009723207913339138, 0.0032217390835285187, -0.021418120712041855, 0.014510712586343288, 0.006543351802974939, 0.02770695462822914, -0.009278608486056328, -0.00907886028289795, -0.011398512870073318, 0.0017590695060789585, -0.010702616535127163, -0.019485076889395714, 0.02273259125649929, 0.02984618954360485, -0.008975764736533165, 0.004739177878946066, 0.010193582624197006, 0.015077738091349602, 0.026160521432757378, -0.001639865105971694, 0.0014497825177386403, -0.005644486751407385, 0.005837791133671999, 0.02452387660741806, -0.004922816995531321, -0.012828964740037918, -0.001611674902960658, 0.0007881178753450513, -0.0177839994430542, -0.025838347151875496, -0.02503935620188713, 0.017539147287607193, -0.004474995657801628, 0.026598677039146423, 0.011205208487808704, -0.014575147069990635, -0.008440956473350525, 0.024485215544700623, 0.012841851450502872, -0.021907825022935867, -0.05902225896716118, 0.00706205191090703, 0.007822382263839245, -0.011617590673267841, -0.014188538305461407, -0.016985008493065834, 0.009401034563779831, -0.018737634643912315, -0.00045023803249932826, 0.015361251309514046, 0.017629355192184448, 0.009046643041074276, -0.01509062573313713, -0.00949768628925085, -0.0038725303020328283, 0.026907963678240776, -0.01900826022028923, 0.012068633921444416, -0.00015393871581181884, 0.005844234488904476, -0.0337638258934021, -0.02881523407995701, -0.03786187618970871, 0.01599271222949028, 0.006546573713421822, -0.006108417175710201, -0.0004514461907092482, 0.008093008771538734, -0.006327495444566011, -0.008756686933338642, -0.020838208496570587, -0.005177334416657686, -0.005602604243904352, -0.008569825440645218, -0.019807251170277596, -0.025670817121863365, -0.008389408700168133, 0.05453759804368019, 0.019678382202982903, -0.026031650602817535, -0.0152968168258667, 0.00036627144436351955, -0.01260344311594963, 0.08113627880811691, 0.005905447527766228, -0.010825042612850666, 0.005003360565751791, 0.00994873046875, 0.0007502624648623168, -0.010889478027820587, -0.01271942537277937, -0.0006201847572810948, 0.00898865144699812, -0.011630477383732796, -0.007178034633398056, 0.004542652051895857, -0.0032716759014874697, 0.0096072256565094, -0.010870147496461868, -0.004359012935310602, 0.00182028254494071, 0.018595878034830093, -0.01200419943779707, 0.027088381350040436, -0.0015979825984686613, 0.012326373718678951, 0.0033860476687550545, 0.007745060604065657, -0.019794363528490067, 0.006688330322504044, 0.034227754920721054, 0.0107412775978446, -0.034047339111566544, 0.01846700720489025, 0.01271942537277937, -0.008956434205174446, 0.007474434562027454, -0.013273565098643303, 0.005609047599136829, 0.004304243251681328, 0.01954951137304306, 0.009542791172862053, -0.03647008538246155, 0.01439473032951355, 0.015438573434948921, 0.009723207913339138, -0.00021344020206015557, -0.0024501325096935034, 0.008582713082432747, -0.010077599436044693, 0.005319091025739908, -0.0019652608316391706, -0.017796887084841728, 0.030129702761769295, 0.02860904298722744, -0.006156743038445711, 0.018196381628513336, 0.01881495490670204, 0.026224955916404724, -0.007867486216127872, 0.0007285157334990799, -0.0006298499647527933, -0.003492365125566721, -0.021650085225701332, -0.0027143151964992285, -0.002055469434708357, -0.007706399541348219, -0.015541668981313705, -0.03291328623890877, -0.017861321568489075, -0.037939198315143585, -0.026779094710946083, -0.006688330322504044, -0.008666478097438812, -0.009755426086485386, -0.01886650361120701, 0.0007293211529031396, 0.007165147457271814, 0.01288051251322031, 0.029021425172686577, -0.03773300722241402, -0.014549373649060726, 0.02097996510565281, -0.010077599436044693, -0.021366573870182037, 0.008408739231526852, -0.027758503332734108, 0.00733912130817771, 0.008859782479703426, 0.035825736820697784, -0.020322728902101517, 0.0008674532291479409, -0.003895082511007786, 0.028325529769062996, -0.012506790459156036, 0.027938921004533768, -0.002190782455727458, -0.006855860818177462, 0.003946630284190178, 0.00038157470407895744, -0.003695334540680051, 0.0049936953000724316, -0.005083904135972261, 0.015374138951301575, -0.0373721718788147, 0.013196242973208427, -0.008969321846961975, 0.014149878174066544, 0.010876591317355633, 0.01953662559390068, 0.010986129753291607, -0.02685641683638096, -0.02308053895831108, 0.03144417330622673, -0.013260677456855774, -0.0039176344871521, 0.00824765209108591, 0.02360890433192253, 0.016301998868584633, 0.013402434065937996, 0.01652107760310173, 0.005335199646651745, -0.02578679844737053, -0.01182378176599741, -0.008795347064733505, 0.008602042682468891, 0.02273259125649929, 0.003286173800006509, 0.0036760042421519756, -0.013737495057284832, 0.0015899281715974212, -0.011205208487808704, 0.005312647670507431, -0.008608486503362656, 0.01216528657823801, -0.017307182773947716, -0.023325391113758087, -0.01972992904484272, 0.0004393646668177098, 0.001069617341272533, 0.0022729369811713696, 0.008440956473350525, 0.01182378176599741, -0.03232048451900482, -0.01048353873193264, 0.005522060673683882, -0.014935982413589954, -0.01668860763311386, -0.025193998590111732, -0.001192043418996036, 0.004407338798046112, -0.013106034137308598, 0.019407756626605988, -0.0021360130049288273, -0.0028464063070714474, -0.005325534380972385, 0.0002023654815275222, -0.011520938947796822, -0.02876368537545204, -0.018750520423054695, 0.002577391220256686, 0.04822298884391785, 0.03211429342627525, 0.029408033937215805, 0.006375821307301521, 0.028892556205391884, -0.007158704102039337, -0.022088242694735527, -0.012049304321408272, 0.007248912937939167, -0.002414693357422948, -0.019343320280313492, 0.01637932099401951, 0.016624173149466515, 0.009471912868320942, 0.035439129918813705, -0.005116121377795935, -0.026353824883699417, 0.011694912798702717, 0.0012210390996187925, 0.009716765023767948, -0.021637199446558952, -0.014832885935902596, -0.006746321450918913, 0.01956239901483059, 0.007983469404280186, -0.00034875323763117194, -0.0011477444786578417, 0.002301932545378804, 0.02308053895831108, 0.002947891131043434, 0.00047802552580833435, -0.0025338977575302124, 0.025284208357334137, -0.017680903896689415, 0.00834430381655693, -0.024614086374640465, 0.005892560817301273, -0.011920434422791004, 0.009098190814256668, 0.01970415562391281, 0.014291633851826191, 0.01306737307459116, -0.0016881912015378475, 0.016044260933995247, 0.011134330183267593, 0.010953912511467934, -0.009877852164208889, 0.007964138872921467, 0.021392347291111946, -0.01564476452767849, 0.03293905779719353, -0.01198486890643835, -0.02966577187180519, -0.03074827790260315, -0.03541335463523865, -0.04376410320401192, -0.00693318247795105, -0.0013563521206378937, -0.033686503767967224, 0.030129702761769295, -0.004764951765537262, -0.029639998450875282, 0.013879251666367054, -0.0005215189885348082, 0.04141867533326149, 0.004600643180310726, 0.040052659809589386, 0.010605964809656143, -0.01020646933466196, -0.017294295132160187, 0.03554222360253334, -0.01845412142574787, -0.00942036509513855, 0.02189493738114834, 0.018918052315711975, -0.027603859081864357, -0.0040078433230519295, 0.0010768662905320525, 0.017513373866677284, -0.009220616891980171, -0.03092869371175766, 0.02595433034002781, 0.001902436837553978, 0.004336460493505001, -0.019961895421147346, 0.0018782737897709012, -0.02912452071905136, 0.005302982404828072, -0.029743093997240067, 0.0009149739053100348, -0.017513373866677284, 0.002960778074339032, -0.035258710384368896, -0.010335338301956654, -0.0033055043313652277, 0.009729651734232903, 0.007403556257486343, 0.0066367825493216515, -0.008937103673815727, 0.006259839050471783, -0.0017413499299436808, -0.015915390104055405, -0.017732450738549232, 0.016778817400336266, 0.00018776697106659412, 0.004491104278713465, 0.00033566492493264377, 0.009278608486056328, 0.0026933737099170685, -0.021005738526582718, -0.016405094414949417, 0.028531720861792564, 0.019317546859383583, -0.012062191031873226, -0.009375260211527348, 0.02097996510565281, 0.016830364242196083, -0.0040883868932724, -0.0013217184459790587, 0.004407338798046112, -0.002772306324914098, 0.0003257983480580151, 0.01670149527490139, 0.020219633355736732, -0.02099285088479519, 0.01260344311594963, -0.021946486085653305, -0.01792575605213642, -0.020335616543889046, -0.012307043187320232, -0.0016237564850598574, -0.010270903818309307, -0.020348504185676575, -0.008440956473350525, 0.008415182121098042, 0.005754025653004646, -0.006118082441389561, -0.014446278102695942, 0.002050636801868677, 0.02007787674665451, -0.012654990889132023, 0.01689479872584343, 0.0017091325717046857, 0.010019608773291111, -0.01368594728410244, 0.023570243269205093, 0.006569125689566135, -0.004404117353260517, 0.007719286717474461, -0.01351841725409031, -0.018376799300312996, -0.03897015377879143, 0.0004631249757949263, -0.008531165309250355, 0.006939625833183527, -0.010676843114197254, 0.01722986064851284, 0.009974503889679909, 0.0020345281809568405, -0.021920712664723396, 0.011153660714626312, 0.01438184268772602, -0.032629773020744324, -0.006553017068654299, -0.001002766308374703, -0.013969460502266884, 0.00413671275600791, -0.0061857388354837894, 0.013260677456855774, 0.013492642901837826, -0.024846050888299942, 0.004974365234375, -0.007732173427939415, 0.024614086374640465, -0.008486060425639153, -0.036856696009635925, -0.004204369615763426, -0.004181817173957825, -0.01845412142574787, 0.024059947580099106, -0.024111494421958923, -0.009961617179214954, -0.005609047599136829, 0.01518083456903696, -0.024923373013734818, -0.0034762562718242407, -0.009884295053780079, -0.008202547207474709, 0.00529009522870183, 0.0014819999923929572, -0.02948535606265068, -0.017835546284914017, -0.03531026095151901, 0.019059807062149048, -0.0027014282532036304, -0.0077386172488331795, -0.010515755973756313, -0.0031428064685314894, -0.028892556205391884, 0.008556938730180264, 0.002359923906624317, 0.015515894629061222, -0.0029430584982037544, 0.0011936542578041553, -0.0058990041725337505, -0.0010978075442835689, -0.015155060216784477, -0.010051826015114784, -0.0035729084629565477, -0.008685808628797531, -0.01636643335223198, -0.012081521563231945, 0.010096929967403412, -0.0005819266079925001, 0.011688468977808952, -0.018930938094854355, 0.008698695339262486, 0.0016736934194341302, 0.00949124339967966, 0.01438184268772602, -0.0165081899613142, -0.0040883868932724, 0.0035600215196609497, 0.015477234497666359, 0.031727686524391174, -0.009839191101491451, 0.02293878234922886, -0.00390796922147274, -0.006668999791145325, -0.0009632999426685274, -0.006553017068654299, -0.0058732302859425545, -0.007719286717474461, 0.009639442898333073, -0.013531303964555264, 0.004339682403951883, -0.01474267803132534, -0.0016390597447752953, -0.016997894272208214, -0.011843112297356129, 0.003324834629893303, 0.00019551928562577814, 0.0058281258679926395, 0.041109390556812286, 0.010251573286950588, -0.021559877321124077, -0.02256505936384201, -0.00019179415539838374, -0.01555455569177866, -0.011604703962802887, 0.008569825440645218, -0.01953662559390068, 0.008859782479703426, -0.005924778059124947, -0.006246951874345541, -0.025129564106464386, -0.018209269270300865, -0.0003322418488096446, -0.007873930037021637, -0.015167946927249432, 0.0061406344175338745, 0.0107412775978446, -0.014987530186772346, 0.00986496452242136, -0.01900826022028923, -0.009742538444697857, -0.015618991106748581, 0.006517577916383743, 0.00021303749235812575, -0.01796441711485386, -0.023763546720147133, -0.006694773677736521, 0.0036180128809064627, -0.0003469410294201225, -0.024472329765558243, 0.00395951746031642, 0.010425547137856483, 0.01582518219947815, 0.23010948300361633, -0.0032249607611447573, -0.0017767890822142363, 0.024820277467370033, -0.01412410382181406, 0.005222438834607601, 0.021379459649324417, -0.006243729963898659, -0.0015939553268253803, 0.02256505936384201, -0.021611426025629044, 0.006868747528642416, -0.0012870847713202238, -0.0005915918154641986, 0.003126697614789009, 0.009742538444697857, -0.017152538523077965, 0.0013756825355812907, -0.015322591178119183, -0.02701105922460556, 0.001755847712047398, -0.008279869332909584, 0.0015182445058599114, -0.000983435777015984, 0.02631516382098198, 0.019949007779359818, -0.013608625158667564, -0.014819999225437641, 0.009033756330609322, -0.003049375955015421, -0.004301021341234446, -0.01306737307459116, -0.010328895412385464, -0.006965399719774723, -0.017268521711230278, 0.005406077951192856, 0.00023075705394148827, 0.014446278102695942, 0.018802069127559662, 0.016791703179478645, -0.021778956055641174, 0.00905952975153923, -0.016417982056736946, 0.0012580890906974673, -0.015283930115401745, 0.02189493738114834, 0.005718586966395378, -0.012087964452803135, 0.010857260785996914, 0.013789042830467224, 0.0036888911854475737, 0.0077643911354243755, 0.024485215544700623, 0.00969743449240923, -0.03801652044057846, -0.0056605953723192215, 0.0512385368347168, 0.0037404389586299658, 0.02384086884558201, 0.004333239048719406, -0.019691267982125282, 0.013982347212731838, -0.005644486751407385, 0.005995656363666058, -0.013892138376832008, 0.02382798120379448, -0.013789042830467224, 0.002827076008543372, 0.007977025583386421, -0.01154026947915554, 0.021095946431159973, -0.017822660505771637, 0.0007985885604284704, -0.00626628240570426, -0.028583267703652382, -0.015580330044031143, 0.015941165387630463, 0.012339260429143906, 0.014008121564984322, 0.019343320280313492, -0.015515894629061222, -0.012919173575937748, -0.00018565270875114948, -0.002997828181833029, -0.01138562522828579, -0.023054763674736023, -0.013466869480907917, 0.008853338658809662, -0.010528642684221268, -0.00046191681758500636, 0.004339682403951883, -0.03273286670446396, -0.006072978023439646, -0.008776017464697361, 0.01581229455769062, 0.013879251666367054, -0.009626556187868118, 0.03211429342627525, -0.01022579986602068, -0.0029205065220594406, -0.03827425837516785, -0.06113572046160698, 0.03329989314079285, 0.004323573783040047, 0.006411260459572077, -0.002190782455727458, 0.00364056508988142, -0.007306904066354036, 0.0016801368910819292, 0.004452443215996027, -0.008299199864268303, -0.013660172931849957, 0.0018524999031797051, 0.010960356332361698, -0.0018669978016987443, 0.012107294984161854, -0.010728390887379646, 0.0047262911684811115, -0.003120254259556532, 0.0017848433926701546, -0.022320207208395004, -0.026005877181887627, -0.014265860430896282, 0.007055608555674553, -0.005892560817301273, -0.0277327299118042, -0.001910491264425218, 0.001461058622226119, -0.0005066184676252306, -0.0575789213180542, 0.01216528657823801, -0.005148339085280895, -0.005203108303248882, 0.012932060286402702, -0.0032314041163772345, 0.02523265965282917, 0.0167272686958313, -0.003589017316699028, -0.006797869224101305, 0.004855160601437092, 0.012680764310061932, -0.0029205065220594406, 0.010341782122850418, 0.007223139051347971, -0.00014034700870979577, -0.012435912154614925, 0.005837791133671999, 0.0011356630129739642, -0.037578362971544266, -0.04814566671848297, -0.04461464285850525, 0.012674321420490742, 0.0011356630129739642, -0.01083148643374443, 0.02613474614918232, -0.008840451948344707, -0.03714020550251007, -0.013196242973208427, -0.00042486682650633156, 0.0055897170677781105, -0.04074855521321297, -0.01578652113676071, 0.025116676464676857, -0.0238150954246521, -0.011256756260991096, -0.01101190410554409, -0.16557161509990692, 0.015258155763149261, 0.021727407351136208, -0.008556938730180264, 0.0013700445415452123, -0.008099451661109924, 0.023583129048347473, 0.004845495335757732, -0.02059335634112358, 0.013660172931849957, 0.019330434501171112, 0.002229443285614252, -0.038686640560626984, -0.0023550912737846375, -0.007197365164756775, 0.005882895551621914, 0.007970582693815231, 0.014691130258142948, 0.025992989540100098, 0.02149544283747673, 0.04461464285850525, -0.022822799161076546, 0.01439473032951355, -0.011881773360073566, 0.02186916396021843, -0.00029519182862713933, -0.010567303746938705, 0.026018764823675156, -0.007087825797498226, -0.019266000017523766, -0.021546989679336548, -0.007571086753159761, 0.006459586787968874, 0.018595878034830093, 0.004764951765537262, 0.012236164882779121, -0.009272164665162563, -0.005428630392998457, -0.012642104178667068, -0.0007277103140950203, 0.015915390104055405, 0.02737189456820488, 0.01313825137913227, 0.0019121021032333374, 0.002722369506955147, 0.017268521711230278, 0.00942680798470974, 0.013299338519573212, 0.013905025087296963, -0.028995651751756668, 0.002609608694911003, -0.0016148966969922185, 0.028505947440862656, -0.0026965956203639507, 0.04430535435676575, 0.0023534803185611963, 0.003505252068862319, 0.0012927227653563023, 0.013724608346819878, -0.002388919470831752, -0.0011195542756468058, -0.017719564959406853, -0.004172151908278465, 0.009214174002408981, -0.011688468977808952, -0.007416442967951298, -0.004056169185787439, 0.028299756348133087, -0.022474851459264755, 0.0017204086761921644, -0.020709337666630745, 0.0363154411315918, 0.0016575846821069717, -0.014832885935902596, -0.006978286895900965, 0.02009076438844204, -0.006372599862515926, 0.009181955829262733, 0.0008964488515630364, -0.02096707746386528, -0.011836669407784939, 0.03726907819509506, -0.011179434135556221, -0.027062607929110527, 0.01793864369392395, 0.0038274258840829134, 0.013789042830467224, -0.020747998729348183, 0.002965610707178712, -0.006369377952069044, 0.026237841695547104, -0.02842862531542778, -0.008196104317903519, -0.029072972014546394, 0.030774051323533058, 0.013009382411837578, 0.00479394756257534, -0.002524232491850853, 0.0032716759014874697, -0.009098190814256668, 0.012023529969155788, -0.016920574009418488, -0.014871546998620033, 0.006765651982277632, 0.018750520423054695, 0.0217016339302063, 0.006810756400227547, 0.011701355688273907, 0.0358772873878479, 0.013273565098643303, -0.006408039014786482, -0.0038403128273785114, 0.009781199507415295, 0.02469140850007534, 0.011611147783696651, 0.02721725031733513, 0.010554417036473751, -0.007139373570680618, 0.0025032912380993366, -0.013080260716378689, 0.05670260637998581, 0.0013088315026834607, -0.003991734702140093, 0.033325668424367905, -0.003595460671931505, -0.01846700720489025, -0.10948757827281952, -0.029253389686346054, -0.0031105889938771725, 0.009446138516068459, 0.006201847456395626, 0.009188399650156498, 0.00905308686196804, 0.021263478323817253, -0.002237497828900814, 0.014149878174066544, -0.009175512939691544, -0.03203697130084038, -0.0041753738187253475, -0.010644625872373581, -0.000696298317052424, 0.001127608702518046, 0.026547130197286606, -0.00789970438927412, -0.002728812862187624, -0.0038113172631710768, 0.010084043256938457, 0.008260538801550865, 0.004658634774386883, -0.028325529769062996, -0.0003656673652585596, -0.008067234419286251, -0.028712138533592224, 0.02310631237924099, 0.005090347491204739, 0.010876591317355633, -0.003953073639422655, 0.0009423586307093501, -0.006546573713421822, -0.016405094414949417, -0.0009085303754545748, 0.013724608346819878, -0.002601554151624441, 0.00297849765047431, 0.02631516382098198, -0.006701217032968998, 0.00861493032425642, -0.0014602532610297203, 0.004919595550745726, -0.00719092134386301, -0.002371199894696474, -0.005667038727551699, -0.00949768628925085, 0.001833169488236308, -0.00013621915422845632, -0.0313410758972168, 0.004098052158951759, 0.009188399650156498, -0.04337749257683754, -0.00044419727055355906, 0.03853200003504753, -0.014845773577690125, 0.012822520919144154, 0.028892556205391884, 0.01351841725409031, 0.014046781696379185, -0.007873930037021637, -0.008028573356568813, 0.0138663649559021, 0.039202120155096054, 0.002446910832077265, -0.0031379738356918097, -0.025090903043746948, -0.018247930333018303, 0.011334077455103397, -0.022294433787465096, 0.009980947710573673, 0.022964555770158768, -0.017668016254901886, 0.0024887933395802975, -0.001723630353808403, 0.018724747002124786, -0.02256505936384201, -0.02293878234922886, 0.013647286221385002, -0.01412410382181406, -0.013724608346819878, -0.01322201732546091, 0.008743799291551113, -0.03126375377178192, 0.007770834490656853, 0.008582713082432747, -0.002664378145709634, 0.008009242825210094, -0.01227482594549656, 0.006836530286818743, -0.006939625833183527, 0.027835825458168983, 0.01271298248320818, -0.040954746305942535, -0.023028990253806114, 0.012036416679620743, 0.018067512661218643, -0.01110855583101511, 0.015399912372231483, 0.013299338519573212, -0.009658773429691792, -0.00907886028289795, -0.04092897102236748, 0.00421725632622838, -0.00015494550461880863, 0.0065916781313717365, -0.001069617341272533, -0.01083148643374443, -0.005067795515060425, -0.008537608198821545, -0.029975060373544693, -0.0038016519974917173, -0.017564920708537102, 0.003804873675107956, -0.0024775173515081406, 0.008602042682468891, -0.015167946927249432, -0.022616608068346977, 0.00613741297274828, 0.0006958956364542246, 0.0009415532113052905, -0.005438295658677816, 0.010799269191920757, 0.005386747419834137, 0.01065106876194477, -0.003975626081228256, 0.004056169185787439, 0.028686363250017166, -0.022887233644723892, 0.006056869402527809, -0.02204958163201809, 0.014923094771802425, 0.012423025444149971, -0.0287894606590271, 0.015425686724483967, 0.030103929340839386, -0.02416304312646389, -0.024291912093758583, 0.01076060812920332, 0.008305642753839493, -0.0076226345263421535, -0.014832885935902596, -0.01866031251847744, -0.000569039664696902, 0.0061857388354837894, -0.016856137663125992, -0.00211346079595387, 0.0073133474215865135, 0.012410138733685017, -0.005129008553922176, 0.03141839802265167, 0.012481017038226128, 0.0217016339302063, 0.019601060077548027, 0.009020869620144367, 0.008685808628797531, -0.003891860833391547, -0.037578362971544266, 0.009349486790597439, 0.016843251883983612, -0.017693791538476944, -0.023673338815569878, -0.0034859215375036, 0.00457486929371953, 0.011392069049179554, -0.01395657379180193, -0.007319791242480278, 0.014807112514972687, -0.007087825797498226, -0.019124243408441544, 0.01456226035952568, -0.041856832802295685, -0.023222295567393303, -5.18498636665754e-05, 0.021817617118358612, 0.008447399362921715, 0.006952512543648481, 0.0024388565216213465, -0.012229721061885357, -0.016804590821266174, -0.01583806984126568, 0.02538730390369892, 0.001807395601645112, 4.656419696402736e-05, 0.003223349805921316, -0.009111077524721622, 0.037552591413259506, 0.020168086513876915, -0.018003078177571297, 0.0059698824770748615, 0.013698833994567394, 0.005341643467545509, 0.004023951943963766, -0.009684547781944275, 0.01520660798996687, -0.0013885694788768888, 0.010154921561479568, 0.029562676325440407, 0.007861043326556683, -0.00023136113304644823, 0.007319791242480278, 0.016289113089442253, -0.00014366942923516035, -0.013827703893184662, -0.023686224594712257, -0.007029834669083357, -0.008150999434292316, 0.003337721573188901, -0.011656251735985279, -0.02436923421919346, -0.016211790964007378, 0.02417592890560627, 0.016611285507678986, 0.006243729963898659, 0.014162764884531498, 0.018028851598501205, -0.01518083456903696, 0.03141839802265167, -0.00871158204972744, -0.014446278102695942, -0.02146966941654682, 0.024085721001029015, 0.002068356378003955, 0.01119876466691494, 0.008627817034721375, -0.026379598304629326, 0.008157443255186081, -0.0011437173234298825, 0.03002660721540451, -0.005857121665030718, 0.011804452165961266, 0.0007768418290652335, -0.008022130466997623, 0.01110855583101511, -0.01128897350281477, 0.012249051593244076, -0.038119614124298096, 0.00015172376879490912, 0.012126625515520573, 0.029975060373544693, 0.012964277528226376, 0.0522952675819397, 0.007294016890227795, -0.007158704102039337, -0.0013853478012606502, -0.00421725632622838, -0.006153521593660116, 0.02117326855659485, 0.005953773856163025, -0.017680903896689415, 0.0006729407468810678, -0.0022439411841332912, -0.017384503036737442, 0.02010365203022957, -0.02487182430922985, -0.010419104248285294, -0.0055607217364013195, -0.018376799300312996, 0.013647286221385002, -0.011063451878726482, -0.011424286291003227, 0.04904775321483612, -0.0007679820409975946, 0.01707521639764309, 0.010560860857367516, -0.00613741297274828, -0.013144695200026035, 0.022152677178382874, 0.008795347064733505, -0.008827565237879753, -0.012506790459156036, -0.004465330392122269, 0.004752065055072308, -0.019652608782052994, -0.018698973581194878, 0.02257794700562954, -0.02202380821108818, -0.012506790459156036, -0.0007285157334990799, 0.0006761624827049673, 0.017307182773947716, -0.011392069049179554, 0.019227338954806328, -0.019459303468465805, -0.012674321420490742, -0.012242607772350311, 0.013073816895484924, -0.012977165170013905, -0.004455665126442909, -0.027088381350040436]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 텍스트 임베딩을 가져오는 함수 정의\n",
        "def get_embedding(text, model):\n",
        "    text = text.replace(\"\\n\", \" \")  # 텍스트에서 줄바꿈 제거\n",
        "    return client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    ).data[0].embedding  # 임베딩 반환\n",
        "\n",
        "# CSV 파일로부터 데이터프레임 생성\n",
        "df = pd.read_csv('words.csv')\n",
        "print(df)\n",
        "\n",
        "# 입력 데이터 정의\n",
        "input = \"The black cat sat on the mat\"\n",
        "\n",
        "# 사용할 모델 정의\n",
        "model = \"text-embedding-ada-002\"\n",
        "\n",
        "# get_embedding() 함수를 사용하여 입력에 대한 임베딩을 가져옴\n",
        "embedding = get_embedding(input, model=model)\n",
        "print(embedding)  # 임베딩 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYxEozAy5GJz"
      },
      "source": [
        "### OpenAI 임베딩을 활용한 텍스트 벡터화 및 CSV 데이터 변환 스크립트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB-Z6IDq5W7T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 텍스트 임베딩을 가져오는 함수 정의\n",
        "def get_embedding(text, model):\n",
        "    text = text.replace(\"\\n\", \" \")  # 텍스트에서 줄바꿈 제거\n",
        "    return client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    ).data[0].embedding  # 임베딩 반환\n",
        "\n",
        "# CSV 파일로부터 데이터프레임 생성\n",
        "df = pd.read_csv('words.csv')\n",
        "\n",
        "# 입력 텍스트 정의\n",
        "input = \"The black cat sat on the mat\"\n",
        "\n",
        "# 사용할 모델 정의\n",
        "model = \"text-embedding-ada-002\"\n",
        "\n",
        "# 데이터프레임의 각 텍스트에 대해 임베딩 열 생성\n",
        "df['embedding'] = df['text'].apply(\n",
        "    lambda x: get_embedding( x, model=model )\n",
        ")\n",
        "\n",
        "# 새로운 데이터프레임을 CSV 파일로 저장\n",
        "df.to_csv('embeddings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMb69o8X6-7X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 텍스트 임베딩을 가져오는 함수 정의\n",
        "def get_embedding(text, model):\n",
        "    text = text.replace(\"\\n\", \" \")  # 텍스트에서 줄바꿈 제거\n",
        "    return client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    ).data[0].embedding  # 임베딩 반환\n",
        "\n",
        "# words.csv는 단어가 포함된 'text' 열이 있는 CSV 파일입니다.\n",
        "df = pd.read_csv('words.csv')\n",
        "\n",
        "# 사용할 모델 정의\n",
        "model = \"text-embedding-ada-002\"\n",
        "\n",
        "# 데이터프레임의 각 단어에 대해 임베딩을 가져옴\n",
        "df['embedding'] = df['text'].apply(\n",
        "    lambda x: get_embedding(x, model=model)\n",
        ")\n",
        "# 데이터프레임을 CSV 파일로 저장\n",
        "df.to_csv('embeddings.csv')\n",
        "\n",
        "# CSV 파일 읽기\n",
        "df = pd.read_csv('embeddings.csv')\n",
        "\n",
        "# embedding 열을 NumPy 배열로 변환\n",
        "df['embedding'] = df['embedding'].apply(eval).apply(np.array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gweMOxR_7exm"
      },
      "source": [
        "### 16.5 오픈AI 텍스트 임베딩 사용 예제\n",
        "* 최종 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPuNtMkn9AiH",
        "outputId": "83956c8c-977c-4a14-f691-a414e7bf011a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검색어를 입력하세요: office\n",
            "    Unnamed: 0        text                                          embedding  \\\n",
            "0            0       apple  [0.007730893790721893, -0.023138046264648438, ...   \n",
            "1            1      banana  [-0.014053216204047203, -0.03304014727473259, ...   \n",
            "2            2      cherry  [0.006510504521429539, -0.01894085668027401, -...   \n",
            "3            3         dog  [-0.003476932644844055, -0.01781758852303028, ...   \n",
            "4            4         cat  [-0.0070539116859436035, -0.01734057068824768,...   \n",
            "5            5       house  [-0.007240159437060356, 0.007166280411183834, ...   \n",
            "6            6         car  [-0.007482267916202545, -0.021632038056850433,...   \n",
            "7            7        tree  [-0.007778085768222809, -0.013066908344626427,...   \n",
            "8            8       phone  [-0.0013657707022503018, -0.023023227229714394...   \n",
            "9            9    computer  [-0.003095467807725072, -0.014320866204798222,...   \n",
            "10          10  television  [-0.005108153913170099, -0.018662655726075172,...   \n",
            "11          11        book  [-0.00703745661303401, -0.019520645961165428, ...   \n",
            "12          12       music  [-0.001933888765051961, -0.023452673107385635,...   \n",
            "13          13        food  [0.022421086207032204, -0.026948681101202965, ...   \n",
            "14          14       water  [0.019145702943205833, -0.012435761280357838, ...   \n",
            "15          15         sky  [0.004894931800663471, -0.0014347214018926024,...   \n",
            "16          16         air  [0.008958079852163792, -0.023514049127697945, ...   \n",
            "17          17         sun  [0.02463594824075699, -0.0025690707843750715, ...   \n",
            "18          18        moon  [0.017463749274611473, -0.009382566437125206, ...   \n",
            "19          19        star  [0.011688734404742718, -0.009672462940216064, ...   \n",
            "20          20       ocean  [0.005397390108555555, 3.828329863608815e-05, ...   \n",
            "21          21        desk  [0.012898282147943974, -0.020884225144982338, ...   \n",
            "22          22         bed  [0.0059449998661875725, 0.004055066499859095, ...   \n",
            "23          23        sofa  [0.011893154121935368, -0.011614514514803886, ...   \n",
            "24          24        lamp  [0.00688182283192873, -0.008740827441215515, 0...   \n",
            "25          25      carpet  [0.009332302957773209, -0.013087349943816662, ...   \n",
            "26          26      window  [0.007322357036173344, -0.016710715368390083, ...   \n",
            "27          27        door  [-0.004923377651721239, -0.027041634544730186,...   \n",
            "28          28       floor  [0.01881076581776142, -0.021379636600613594, -...   \n",
            "29          29     ceiling  [-0.01649574749171734, -0.010994984768331051, ...   \n",
            "30          30        wall  [0.001094791223295033, 0.014711256138980389, -...   \n",
            "31          31       clock  [-0.011162938550114632, -0.013790330849587917,...   \n",
            "32          32       watch  [-0.0025084922090172768, -0.010459018871188164...   \n",
            "33          33     jewelry  [-0.01604277454316616, 0.010460982099175453, -...   \n",
            "34          34        ring  [-0.020498422905802727, -0.025555063039064407,...   \n",
            "35          35    necklace  [-0.024890458211302757, 0.002433406887575984, ...   \n",
            "36          36    bracelet  [-0.03427419438958168, 0.005139813292771578, -...   \n",
            "37          37     earring  [-0.025889739394187927, -0.009100515395402908,...   \n",
            "38          38      wallet  [0.015408715233206749, -0.02021433413028717, 0...   \n",
            "39          39         key  [0.003569443942978978, -0.02877584472298622, 0...   \n",
            "40          40       photo  [0.004378130193799734, -0.03160664066672325, -...   \n",
            "\n",
            "    similarity  \n",
            "0     0.829284  \n",
            "1     0.804623  \n",
            "2     0.791658  \n",
            "3     0.827397  \n",
            "4     0.801491  \n",
            "5     0.874104  \n",
            "6     0.820692  \n",
            "7     0.823654  \n",
            "8     0.852465  \n",
            "9     0.860660  \n",
            "10    0.799033  \n",
            "11    0.839400  \n",
            "12    0.819411  \n",
            "13    0.829856  \n",
            "14    0.816531  \n",
            "15    0.817010  \n",
            "16    0.800267  \n",
            "17    0.814690  \n",
            "18    0.800138  \n",
            "19    0.810940  \n",
            "20    0.797077  \n",
            "21    0.889205  \n",
            "22    0.822869  \n",
            "23    0.813829  \n",
            "24    0.832987  \n",
            "25    0.801819  \n",
            "26    0.829170  \n",
            "27    0.832589  \n",
            "28    0.860204  \n",
            "29    0.813635  \n",
            "30    0.827834  \n",
            "31    0.814200  \n",
            "32    0.817438  \n",
            "33    0.782350  \n",
            "34    0.819195  \n",
            "35    0.776997  \n",
            "36    0.779265  \n",
            "37    0.775763  \n",
            "38    0.824915  \n",
            "39    0.814880  \n",
            "40    0.832089  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_embedding(text, model):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return client.embeddings.create(\n",
        "        input = [text],\n",
        "        model=model\n",
        "    ).data[0].embedding\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    numerator = np.dot(a, b)\n",
        "    denominator = np.linalg.norm(a) * np.linalg.norm(b)\n",
        "    return numerator / denominator\n",
        "\n",
        "# 'words.csv' 파일에서 데이터프레임 생성 ('text' 열에 단어들이 포함됨)\n",
        "df = pd.read_csv('words.csv')\n",
        "\n",
        "# 사용할 모델 정의\n",
        "model = \"text-embedding-ada-002\"\n",
        "\n",
        "# 데이터프레임의 각 단어에 대한 임베딩 생성\n",
        "df['embedding'] = df['text'].apply(\n",
        "    lambda x: get_embedding(x, model=model)\n",
        ")\n",
        "\n",
        "# 임베딩이 포함된 데이터프레임을 CSV 파일로 저장\n",
        "df.to_csv('embeddings.csv')\n",
        "\n",
        "# 저장한 CSV 파일 다시 읽기\n",
        "df = pd.read_csv('embeddings.csv')\n",
        "\n",
        "# 임베딩 열을 NumPy 배열로 변환\n",
        "df['embedding'] = df['embedding'].apply(eval).apply(np.array)\n",
        "\n",
        "# 사용자로부터 검색어 입력 받기\n",
        "user_search = input(\"검색어를 입력하세요: \")\n",
        "\n",
        "# 검색어에 대한 임베딩 생성\n",
        "search_term_embedding = get_embedding(user_search, model=model)\n",
        "\n",
        "# 검색어와 데이터프레임의 각 단어 사이의 코사인 유사도 계산\n",
        "df['similarity'] = df['embedding'].apply(\n",
        "    lambda x: cosine_similarity(x, search_term_embedding)\n",
        ")\n",
        "\n",
        "# 데이터프레임 출력\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zENbqwL0-sM6"
      },
      "source": [
        "### 유사도를 기준으로 정렬하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sklt17LX_WDU",
        "outputId": "7791205a-af4c-481b-9c67-c67e928cac1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Unnamed: 0      text                                          embedding  \\\n",
            "21          21      desk  [0.012898282147943974, -0.020884225144982338, ...   \n",
            "5            5     house  [-0.007240159437060356, 0.007166280411183834, ...   \n",
            "9            9  computer  [-0.003095467807725072, -0.014320866204798222,...   \n",
            "28          28     floor  [0.01881076581776142, -0.021379636600613594, -...   \n",
            "8            8     phone  [-0.0013657707022503018, -0.023023227229714394...   \n",
            "11          11      book  [-0.00703745661303401, -0.019520645961165428, ...   \n",
            "24          24      lamp  [0.00688182283192873, -0.008740827441215515, 0...   \n",
            "27          27      door  [-0.004923377651721239, -0.027041634544730186,...   \n",
            "40          40     photo  [0.004378130193799734, -0.03160664066672325, -...   \n",
            "13          13      food  [0.022421086207032204, -0.026948681101202965, ...   \n",
            "\n",
            "    similarity  \n",
            "21    0.889205  \n",
            "5     0.874104  \n",
            "9     0.860660  \n",
            "28    0.860204  \n",
            "8     0.852465  \n",
            "11    0.839400  \n",
            "24    0.832987  \n",
            "27    0.832589  \n",
            "40    0.832089  \n",
            "13    0.829856  \n"
          ]
        }
      ],
      "source": [
        "### 정렬 추가\n",
        "# 유사도를 기준으로 데이터프레임 정렬 (내림차순)\n",
        "df = df.sort_values(by='similarity', ascending=False)\n",
        "\n",
        "# 상위 10개의 유사한 단어 출력\n",
        "print(df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8OzSz_DNOJA"
      },
      "source": [
        "## CHAPTER 17. 고급 임베딩 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 목차\n",
        "- 17.1 선호하는 커피 예측하기\n",
        "- 17.2 퍼지 검색으로 더 유연한 커피 검색 구현하기\n",
        "- 17.3 제로샷 분류기로 뉴스 기사 분류하기\n",
        "- 17.4 제로샷 분류기의 정밀도 평가\n",
        "- 17.5 제로샷 분류기의 정밀도 활용 예시"
      ],
      "metadata": {
        "id": "x58EHjQqAi0t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpaotRPN_nTX"
      },
      "source": [
        "## Advanced Embedding Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5T22Hyu_ukD"
      },
      "source": [
        "### 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxdKa00M_8GR",
        "outputId": "e9b35a28-e899-4073-935d-b7c0e3e45635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-19 10:17:11--  https://raw.githubusercontent.com/LDJWJ/OpenAIGPTForPythonDevelopersFiles/main/datasets/ch17_coffee_reviews_dataset/simplified_coffee.csv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96397 (94K) [application/octet-stream]\n",
            "Saving to: ‘data/simplified_coffee.csv.gz’\n",
            "\n",
            "data/simplified_cof 100%[===================>]  94.14K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-12-19 10:17:12 (942 KB/s) - ‘data/simplified_coffee.csv.gz’ saved [96397/96397]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 디렉터리 만들기\n",
        "!rm -rf data\n",
        "!mkdir -p data\n",
        "\n",
        "# 데이터 셋 다운로드\n",
        "!wget https://raw.githubusercontent.com/LDJWJ/OpenAIGPTForPythonDevelopersFiles/main/datasets/ch17_coffee_reviews_dataset/simplified_coffee.csv.gz -O data/simplified_coffee.csv.gz\n",
        "\n",
        "# .gz 파일 압축 풀기\n",
        "!gunzip -k data/simplified_coffee.csv.gz\n",
        "\n",
        "# 저장소 삭제하기\n",
        "!rm data/simplified_coffee.csv.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TBT-juKAQl1",
        "outputId": "6f438232-8a3b-454c-e672-a43b18dc3acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk==3.8.1\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (4.67.1)\n",
            "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "Successfully installed nltk-3.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk==3.8.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIBglcBUZm4J"
      },
      "source": [
        "### 17-1 선호하는 커피예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgRIdzUFcOzG"
      },
      "source": [
        "### OpenAI 초기화 및 함수 기본 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iroIKPKFaEv0"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "with open(\"chatgpt.env\") as env:\n",
        "  for line in env:\n",
        "    key, value = line.strip().split(\"=\")\n",
        "    os.environ[key] = value\n",
        "\n",
        "\n",
        "client = OpenAI( api_key=os.environ['API_KEY'] )\n",
        "\n",
        "def get_embedding(text, model):\n",
        "  text = text.replace(\"\\n\", \" \")\n",
        "  return client.embeddings.create(\n",
        "      input = [text],\n",
        "      model=model\n",
        "  ).data[0].embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrJa4BEiZxWG"
      },
      "source": [
        "### 17-1 선호하는 커피예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ffLS7G5c9xZ",
        "outputId": "e6d87ab5-b192-45e7-90a9-999fc813a0c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 어간 추출(stemming)을 위한 PorterStemmer 임포트\n",
        "# 표제어 추출(lemmatization)을 위한 WordNetLemmatizer 임포트\n",
        "import nltk\n",
        "\n",
        "# 필요한 NLTK 데이터 다운로드\n",
        "nltk.download('wordnet')  # WordNet 데이터 다운로드\n",
        "nltk.download('omw-1.4')  # WordNet의 다국어 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCxpp9qJddOr"
      },
      "outputs": [],
      "source": [
        "# utils.py - 유틸리티 함수 모음 파일\n",
        "import pandas as pd  # pandas 라이브러리 임포트\n",
        "import numpy as np   # numpy 라이브러리 임포트\n",
        "import nltk          # 자연어 처리를 위한 nltk 라이브러리 임포트\n",
        "\n",
        "# 두 벡터 간의 코사인 유사도를 계산하는 함수\n",
        "def cosine_similarity(a, b):\n",
        "    numerator = np.dot(a, b)  # 벡터 내적 계산\n",
        "    denominator = np.linalg.norm(a) * np.linalg.norm(b)  # 두 벡터의 크기 곱 계산\n",
        "    return numerator / denominator  # 코사인 유사도 반환\n",
        "\n",
        "# NLTK 데이터 다운로드 함수\n",
        "def download_nltk_data():\n",
        "    # 'punkt' 토크나이저 모델 체크 및 다운로드\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt')  # 'punkt' 모델이 이미 존재하는지 확인\n",
        "    except LookupError:\n",
        "        nltk.download('punkt')  # 존재하지 않으면 'punkt' 모델 다운로드\n",
        "\n",
        "    # 'stopwords' 코퍼스 체크 및 다운로드\n",
        "    try:\n",
        "        nltk.data.find('corpora/stopwords')  # 'stopwords' 코퍼스가 이미 존재하는지 확인\n",
        "    except LookupError:\n",
        "        nltk.download('stopwords')  # 존재하지 않으면 'stopwords' 다운로드\n",
        "\n",
        "# 텍스트 전처리 함수\n",
        "def preprocess_text(text):\n",
        "    from nltk.corpus import stopwords        # 불용어(stopwords) 모듈 임포트\n",
        "    from nltk.stem import PorterStemmer       # 어간 추출(stemming)을 위한 PorterStemmer 임포트\n",
        "    from nltk.tokenize import word_tokenize   # 단어 토크나이저(word_tokenize) 임포트\n",
        "\n",
        "    # 텍스트를 단어 단위로 토큰화\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # 모든 단어를 소문자로 변환\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    # 구두점(punctuation) 제거\n",
        "    words = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "    # 불용어(stop words) 제거\n",
        "    stop_words = set(stopwords.words('english'))  # 영어 불용어 집합 생성\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # 어간 추출 (Stemming)\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    # 전처리된 단어들을 공백으로 연결하여 반환\n",
        "    return ' '.join(stemmed_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqz_TB0-Z9DU",
        "outputId": "78b09394-645f-48fb-ff16-a848b84dd573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  ['running', 'runner', 'jumps', 'easily', 'better']\n",
            "Stemmed:  ['run', 'runner', 'jump', 'easili', 'better']\n",
            "Lemmatized:  ['run', 'runner', 'jump', 'easily', 'good']\n"
          ]
        }
      ],
      "source": [
        "# 어간 추출(stemming)을 위한 PorterStemmer 임포트\n",
        "# 표제어 추출(lemmatization)을 위한 WordNetLemmatizer 임포트\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# 어간 추출기와 표제어 추출기 초기화\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# 처리할 단어 목록\n",
        "words = [\n",
        "    'running',\n",
        "    'runner',\n",
        "    'jumps',\n",
        "    'easily',\n",
        "    'better'\n",
        "]\n",
        "\n",
        "# 어간 추출 과정\n",
        "stemmed_words = [\n",
        "    stemmer.stem(word) for word in words\n",
        "]\n",
        "\n",
        "# 표제어 추출 과정 (품사 지정 포함)\n",
        "# (POS: Part of Speech)\n",
        "lemmatized_words = []\n",
        "for word in words:\n",
        "    # 기본적으로 명사(n)로 설정\n",
        "    pos_tag = 'n'\n",
        "    if word in ['better']:\n",
        "        # 'better'는 형용사로 처리\n",
        "        pos_tag = 'a'\n",
        "    elif word in ['running', 'jumps']:\n",
        "        # 'running', 'jumps'는 동사로 처리\n",
        "        pos_tag = 'v'\n",
        "    elif word in ['easily']:\n",
        "        # 'easily'는 부사로 처리\n",
        "        pos_tag = 'r'\n",
        "    else:\n",
        "        # 그 외의 경우는 명사로 처리\n",
        "        pos_tag = 'n'\n",
        "\n",
        "    # 표제어 추출 수행\n",
        "    lemmatized_word = lemmatizer.lemmatize(\n",
        "        word,\n",
        "        pos=pos_tag\n",
        "    )\n",
        "    lemmatized_words.append(lemmatized_word)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Original: \", words)               # 원본 단어 리스트 출력\n",
        "print(\"Stemmed: \", stemmed_words)        # 어간 추출 결과 출력\n",
        "print(\"Lemmatized: \", lemmatized_words)  # 표제어 추출 결과 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnPx67sH3EIO"
      },
      "source": [
        "### 필수 함수 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TID4uw6mafwZ"
      },
      "outputs": [],
      "source": [
        "# utils.py - 유틸리티 함수 모음 파일\n",
        "import pandas as pd  # pandas 라이브러리 임포트\n",
        "import numpy as np   # numpy 라이브러리 임포트\n",
        "import nltk          # 자연어 처리를 위한 nltk 라이브러리 임포트\n",
        "\n",
        "# 두 벡터 간의 코사인 유사도를 계산하는 함수\n",
        "def cosine_similarity(a, b):\n",
        "    numerator = np.dot(a, b)  # 벡터 내적 계산\n",
        "    denominator = np.linalg.norm(a) * np.linalg.norm(b)  # 두 벡터의 크기 곱 계산\n",
        "    return numerator / denominator  # 코사인 유사도 반환\n",
        "\n",
        "# NLTK 데이터 다운로드 함수\n",
        "def download_nltk_data():\n",
        "    # 'punkt' 토크나이저 모델 체크 및 다운로드\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt')  # 'punkt' 모델이 이미 존재하는지 확인\n",
        "    except LookupError:\n",
        "        nltk.download('punkt')  # 존재하지 않으면 'punkt' 모델 다운로드\n",
        "\n",
        "    # 'stopwords' 코퍼스 체크 및 다운로드\n",
        "    try:\n",
        "        nltk.data.find('corpora/stopwords')  # 'stopwords' 코퍼스가 이미 존재하는지 확인\n",
        "    except LookupError:\n",
        "        nltk.download('stopwords')  # 존재하지 않으면 'stopwords' 다운로드\n",
        "\n",
        "# 텍스트 전처리 함수\n",
        "def preprocess_text(text):\n",
        "    from nltk.corpus import stopwords        # 불용어(stopwords) 모듈 임포트\n",
        "    from nltk.stem import PorterStemmer       # 어간 추출(stemming)을 위한 PorterStemmer 임포트\n",
        "    from nltk.tokenize import word_tokenize   # 단어 토크나이저(word_tokenize) 임포트\n",
        "\n",
        "    # 텍스트를 단어 단위로 토큰화\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # 모든 단어를 소문자로 변환\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    # 구두점(punctuation) 제거\n",
        "    words = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "    # 불용어(stop words) 제거\n",
        "    stop_words = set(stopwords.words('english'))  # 영어 불용어 집합 생성\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # 어간 추출 (Stemming)\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    # 전처리된 단어들을 공백으로 연결하여 반환\n",
        "    return ' '.join(stemmed_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFBFhWWz4GBm",
        "outputId": "890ba6f4-c07c-443b-8e7a-6aec8253a86e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "커피 이름을 입력하세요: Organic Ethiopia Kirite\n",
            "Organic Ethiopia Kirite와 가장 유사한 커피들은 다음과 같습니다:\n",
            "Ethiopia Hambela Alaka\n",
            "Kenya Kirinyaga Mukangu AB\n",
            "Colombia David Gomez 100% Caturra\n",
            "Kenya AB Muchoki\n",
            "Ethiopia Shakiso Mormora\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd  # 데이터 프레임 처리를 위한 pandas 임포트\n",
        "import numpy as np   # 수치 연산을 위한 numpy 임포트\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# utils.py를 작성한 경우, 아래 부분을 import하여 가져올 수 있다.\n",
        "# from utils import (\n",
        "#     cosine_similarity,        # 코사인 유사도 함수\n",
        "#     download_nltk_data,       # NLTK 데이터 다운로드 함수\n",
        "#     preprocess_text           # 텍스트 전처리 함수\n",
        "# )\n",
        "# 작성하지 않은 경우, 위의 필수 함수를 구글 코랩에 작성 후, 아래 코드를 작성한다.\n",
        "\n",
        "def get_embedding(text, model):\n",
        "    # 텍스트 내 줄바꿈을 공백으로 변환\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    # 임베딩 생성 및 반환\n",
        "    return client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    ).data[0].embedding\n",
        "\n",
        "# 필요한 NLTK 데이터 다운로드\n",
        "download_nltk_data()\n",
        "\n",
        "# 데이터셋 파일 경로 설정\n",
        "dataset_file_path = os.path.join(\n",
        "  'data',                     # 데이터 폴더 지정\n",
        "    'simplified_coffee.csv'     # CSV 파일 이름\n",
        ")\n",
        "\n",
        "# 사용자로부터 커피 이름 입력 받기\n",
        "input_coffee_name = input(\"커피 이름을 입력하세요: \")\n",
        "\n",
        "# CSV 파일을 Pandas DataFrame으로 로드 (예제에서는 첫 50행만 가져옴)\n",
        "df = pd.read_csv(\n",
        "    dataset_file_path,\n",
        "    nrows=50\n",
        ")\n",
        "\n",
        "# 리뷰 텍스트 전처리 (전처리된 텍스트를 'preprocessed_review' 열에 추가)\n",
        "df['preprocessed_review'] = df['review'].apply(\n",
        "    preprocess_text\n",
        ")\n",
        "\n",
        "# 사용할 모델 설정\n",
        "model = \"text-embedding-3-small\"\n",
        "\n",
        "# 각 리뷰에 대한 임베딩 생성\n",
        "review_embeddings = []\n",
        "for review in df['preprocessed_review']:\n",
        "    review_embeddings.append(\n",
        "        get_embedding(review,model=model)\n",
        "    )\n",
        "\n",
        "# 입력된 커피 이름의 인덱스 가져오기\n",
        "try:\n",
        "    input_coffee_index = df[df['name'] == input_coffee_name].index[0]\n",
        "except:\n",
        "    # 유효하지 않은 커피 이름 입력 시 오류 메시지 출력 후 종료\n",
        "    print(\"유효한 커피 이름을 입력해 주세요.\")\n",
        "    exit()\n",
        "\n",
        "# 입력된 커피의 리뷰와 다른 모든 리뷰 간의 코사인 유사도 계산\n",
        "similarities = []  # 유사도를 저장할 리스트\n",
        "input_review_embedding = review_embeddings[input_coffee_index]  # 입력된 커피 리뷰의 임베딩 가져오기\n",
        "\n",
        "for review_embedding in review_embeddings:\n",
        "    similarity = cosine_similarity(\n",
        "        input_review_embedding,  # 입력된 리뷰의 임베딩\n",
        "        review_embedding         # 비교할 리뷰의 임베딩\n",
        "    )\n",
        "    similarities.append(similarity)  # 계산된 유사도를 리스트에 추가\n",
        "\n",
        "# 입력된 커피의 리뷰를 제외한 가장 유사한 리뷰의 인덱스 가져오기\n",
        "most_similar_indices = \\\n",
        "    np.argsort(similarities)[-6:-1]\n",
        "\n",
        "# 가장 유사한 커피의 이름 가져오기\n",
        "similar_coffee_names = df.iloc[most_similar_indices]['name'].tolist()\n",
        "\n",
        "# 결과 출력\n",
        "print(\n",
        "    f\"{input_coffee_name}와 가장 유사한 커피들은 다음과 같습니다:\"\n",
        ")\n",
        "for coffee_name in similar_coffee_names:\n",
        "    print(coffee_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkoKp7xfbxZh"
      },
      "source": [
        "### 17-2 퍼지 검색으로 더 유연한 커피 검색 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARHPDrIigEzw"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(a, b):\n",
        "    numerator = np.dot(a, b)\n",
        "    denominator = np.linalg.norm(a) * np.linalg.norm(b)\n",
        "    return numerator / denominator\n",
        "\n",
        "\n",
        "def download_nltk_data():\n",
        "  # Check and download the 'punkt' tokenizer models\n",
        "  try:\n",
        "      nltk.data.find('tokenizers/punkt')\n",
        "  except LookupError:\n",
        "      nltk.download('punkt')\n",
        "\n",
        "\n",
        "  # Check and download the 'stopwords' corpus\n",
        "  try:\n",
        "      nltk.data.find('corpora/stopwords')\n",
        "  except LookupError:\n",
        "      nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.stem import PorterStemmer\n",
        "    from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "\n",
        "    # Convert to lower case\n",
        "    tokens = [\n",
        "        word.lower() for word in tokens\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Remove punctuation\n",
        "    words = [\n",
        "        word for word in tokens if word.isalpha()\n",
        "    ]\n",
        "    # Filter out stop words\n",
        "    stop_words = set(\n",
        "        stopwords.words('english')\n",
        "\n",
        "    )\n",
        "    words = [\n",
        "        word for word in words if word not in stop_words\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [\n",
        "        stemmer.stem(word) for word in words\n",
        "    ]\n",
        "\n",
        "    return ' '.join(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce4TBBz_c6-W",
        "outputId": "52753595-ba92-4323-9edf-939d1f48fcb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "커피 이름을 입력하세요: Ethiopian Kirite\n",
            "유사한 커피 이름을 검색 중입니다...\n",
            "Ethiopian Kirite와 가장 유사한 커피들은 다음과 같습니다:\n",
            "El Peñon Nicaragua\n",
            "Colombia David Gomez 100% Caturra\n",
            "Panama Auromar Estate Geisha Peaberry\n",
            "Ethiopia Yirgacheffe Natural G1\n",
            "Ethiopia Shakiso Mormora\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd  # 데이터 프레임 처리를 위한 pandas 임포트\n",
        "import numpy as np   # 수치 연산을 위한 numpy 임포트\n",
        "\n",
        "# from utils import (\n",
        "#     cosine_similarity,        # 코사인 유사도 함수\n",
        "#     download_nltk_data,       # NLTK 데이터 다운로드 함수\n",
        "#     preprocess_text           # 텍스트 전처리 함수\n",
        "# )\n",
        "\n",
        "# 사용되는 함수 정의 필요.\n",
        "# download_nltk_data()\n",
        "# cosine_similarity()\n",
        "# preprocess_text()\n",
        "\n",
        "def get_embedding(text, model):\n",
        "    # 텍스트 내 줄바꿈을 공백으로 변환\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    # 임베딩 생성 및 반환\n",
        "    return client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    ).data[0].embedding\n",
        "\n",
        "# 필요한 NLTK 데이터 다운로드\n",
        "download_nltk_data()\n",
        "\n",
        "# 데이터셋 파일 경로 설정\n",
        "dataset_file_path = os.path.join(\n",
        "    'data',                     # 데이터 폴더 지정\n",
        "    'simplified_coffee.csv'     # CSV 파일 이름\n",
        ")\n",
        "\n",
        "# 사용자로부터 커피 이름 입력 받기\n",
        "input_coffee_name = input(\"커피 이름을 입력하세요: \")\n",
        "\n",
        "# CSV 파일을 Pandas DataFrame으로 로드 (예제에서는 첫 50행만 가져옴)\n",
        "df = pd.read_csv( dataset_file_path, nrows=50 )\n",
        "\n",
        "# 리뷰 텍스트 전처리 (전처리된 텍스트를 'preprocessed_review' 열에 추가)\n",
        "df['preprocessed_review'] = df['review'].apply( preprocess_text )\n",
        "\n",
        "# 사용할 모델 설정\n",
        "model = \"text-embedding-ada-002\"\n",
        "\n",
        "# 각 리뷰에 대한 임베딩 생성\n",
        "review_embeddings = []\n",
        "for review in df['preprocessed_review']:\n",
        "    review_embeddings.append(\n",
        "        get_embedding( review, model=model )\n",
        "    )\n",
        "\n",
        "# 입력된 커피 이름의 인덱스 가져오기\n",
        "try:\n",
        "    input_coffee_index = df[\n",
        "        df['name'] == input_coffee_name\n",
        "    ].index[0]  # 입력된 커피 이름과 정확히 일치하는 인덱스 가져오기\n",
        "\n",
        "except IndexError:\n",
        "    # 유사한 커피 이름을 찾기 위해 임베딩 생성\n",
        "    print(\"유사한 커피 이름을 검색 중입니다...\")\n",
        "    name_embeddings = []\n",
        "    for name in df['name']:\n",
        "        name_embeddings.append(\n",
        "            get_embedding( name, model=model )\n",
        "        )\n",
        "\n",
        "    # 입력된 커피 이름에 대해 코사인 유사도 검색 수행\n",
        "    input_coffee_embedding = get_embedding( input_coffee_name, model=model )\n",
        "\n",
        "    # 각 커피 이름과 입력된 커피 이름의 유사도 계산\n",
        "    _similarities = []\n",
        "    for name_embedding in name_embeddings:\n",
        "        _similarities.append(\n",
        "            cosine_similarity( input_coffee_embedding, name_embedding )\n",
        "        )\n",
        "\n",
        "    # 가장 유사한 커피 이름의 인덱스 가져오기\n",
        "    input_coffee_index = _similarities.index( max(_similarities) )\n",
        "\n",
        "except:\n",
        "    # 데이터베이스에 해당 커피 이름이 없을 때 오류 메시지 출력\n",
        "    print(\n",
        "        \"죄송합니다, 해당 커피 이름은 데이터베이스에 없습니다. \"\n",
        "        \"다시 시도해 주세요.\"\n",
        "    )\n",
        "    raise SystemExit  # 프로그램 종료\n",
        "\n",
        "# 입력된 커피의 리뷰와 다른 모든 리뷰 간의 코사인 유사도 계산\n",
        "similarities = []  # 유사도를 저장할 리스트\n",
        "input_review_embedding = review_embeddings[input_coffee_index]  # 입력된 커피 리뷰의 임베딩 가져오기\n",
        "\n",
        "for review_embedding in review_embeddings:\n",
        "    similarity = cosine_similarity(\n",
        "        input_review_embedding,  # 입력된 리뷰의 임베딩\n",
        "        review_embedding         # 비교할 리뷰의 임베딩\n",
        "    )\n",
        "    similarities.append(similarity)  # 계산된 유사도를 리스트에 추가\n",
        "\n",
        "# 입력된 커피의 리뷰를 제외한 가장 유사한 리뷰의 인덱스 가져오기\n",
        "most_similar_indices = np.argsort(similarities)[-6:-1]\n",
        "\n",
        "# 가장 유사한 커피의 이름 가져오기\n",
        "similar_coffee_names = df.iloc[most_similar_indices]['name'].tolist()\n",
        "\n",
        "# 결과 출력\n",
        "print(\n",
        "    f\"{input_coffee_name}와 가장 유사한 커피들은 다음과 같습니다:\"\n",
        ")\n",
        "for coffee_name in similar_coffee_names:\n",
        "    print(coffee_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYGlSmF4fQEz"
      },
      "source": [
        "### 17-3. 제로샷 분류기로 뉴스 기사 분류하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3-rwK_chDyO",
        "outputId": "ec395874-e93c-469c-b6eb-b399f175f97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'텍사스 엘파소 쇼핑몰 총격 사건으로 1명 사망, 3명 부상..' => WORLD NEWS\n",
            "'오웬 클라인 감독, '퍼니 페이지스'를 '자기 비판적' 데뷔작이라고 부르다..' => COMEDY\n",
            "'휴가를 원하는 가족들을 위한 15가지 봄방학 아이디어..' => PARENTING\n",
            "'미국, 중동에 더 많은 군대를 파견할 준비 중..' => U.S. NEWS\n",
            "'브루스 윌리스의 가족, '그의 상태가 전두측두 치매로 진행되었다'고 말하다..' => PARENTING\n",
            "'유니버설의 새로운 슈퍼 닌텐도 월드 내부 모습 공개..' => WORLD NEWS\n",
            "'바르셀로나 2-2 맨체스터 유나이티드: 마커스 래시포드 빛났지만 라피냐가 홈팀을 위해 동점..' => SPORTS\n",
            "'시카고 불스, NBA 챔피언십 우승..' => SPORTS\n",
            "'새로운 아이폰 12 출시..' => TECH\n",
            "'과학자들, 새로운 공룡 종 발견..' => WORLD NEWS\n",
            "'새로운 코로나바이러스 백신 출시..' => WORLD NEWS\n",
            "'새로운 스타워즈 영화 개봉..' => WORLD NEWS\n",
            "'아마존 주가, 새로운 최고치 기록..' => U.S. NEWS\n"
          ]
        }
      ],
      "source": [
        "# .py 형태로 작성할 경우, 아래 2줄의 임포트가 필요합니다.\n",
        "# from api import get_embedding\n",
        "# from utils import cosine_similarity\n",
        "\n",
        "def get_embedding(text, model):\n",
        "    # 텍스트 내 줄바꿈을 공백으로 변환\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    # 임베딩 생성 및 반환\n",
        "    return client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    ).data[0].embedding\n",
        "\n",
        "# 두 벡터 간의 코사인 유사도를 계산하는 함수\n",
        "def cosine_similarity(a, b):\n",
        "    numerator = np.dot(a, b)  # 벡터 내적 계산\n",
        "    denominator = np.linalg.norm(a) * np.linalg.norm(b)  # 두 벡터의 크기 곱 계산\n",
        "    return numerator / denominator  # 코사인 유사도 반환\n",
        "\n",
        "categories = [\n",
        "    'U.S. NEWS',\n",
        "    'COMEDY',\n",
        "    'PARENTING',\n",
        "    'WORLD NEWS',\n",
        "    'CULTURE & ARTS',\n",
        "    'TECH',\n",
        "    'SPORTS'\n",
        "]\n",
        "\n",
        "# 문장을 분류하는 함수 정의\n",
        "def classify_sentence(sentence, model):\n",
        "    # 문장의 임베딩(embedding) 생성\n",
        "    sentence_embedding = get_embedding(\n",
        "        sentence,\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    # 문장과 각 카테고리 간의 유사도 점수 계산\n",
        "    similarity_scores = {}\n",
        "    for category in categories:\n",
        "        category_embeddings = get_embedding(category,model=model)\n",
        "        similarity_scores[category] = cosine_similarity(\n",
        "            sentence_embedding,\n",
        "            category_embeddings\n",
        "        )\n",
        "\n",
        "    # 유사도 점수가 가장 높은 카테고리 반환\n",
        "    return max(\n",
        "        similarity_scores,\n",
        "        key=similarity_scores.get\n",
        "    )\n",
        "\n",
        "# 문장 분류하기\n",
        "sentences = [\n",
        "    \"텍사스 엘파소 쇼핑몰 총격 사건으로 1명 사망, 3명 부상\",\n",
        "    \"오웬 클라인 감독, '퍼니 페이지스'를 '자기 비판적' 데뷔작이라고 부르다\",\n",
        "    \"휴가를 원하는 가족들을 위한 15가지 봄방학 아이디어\",\n",
        "    \"미국, 중동에 더 많은 군대를 파견할 준비 중\",\n",
        "    \"브루스 윌리스의 가족, '그의 상태가 전두측두 치매로 진행되었다'고 말하다\",\n",
        "    \"유니버설의 새로운 슈퍼 닌텐도 월드 내부 모습 공개\",\n",
        "    \"바르셀로나 2-2 맨체스터 유나이티드: 마커스 래시포드 빛났지만 라피냐가 홈팀을 위해 동점 만들어\",\n",
        "    \"시카고 불스, NBA 챔피언십 우승\",\n",
        "    \"새로운 아이폰 12 출시\",\n",
        "    \"과학자들, 새로운 공룡 종 발견\",\n",
        "    \"새로운 코로나바이러스 백신 출시\",\n",
        "    \"새로운 스타워즈 영화 개봉\",\n",
        "    \"아마존 주가, 새로운 최고치 기록\",\n",
        "]\n",
        "\n",
        "model = \"text-embedding-ada-002\"\n",
        "for sentence in sentences:\n",
        "    category = classify_sentence( sentence, model=model )\n",
        "    print(f\"'{sentence[:50]}..' => {category}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6GxlUOch6Fs"
      },
      "source": [
        "### 17-4. 제로샷 분류기의 정밀도 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__3qTI7tkMiW"
      },
      "source": [
        "### 데이터 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_iACzwVkSFf",
        "outputId": "d2bb5cdd-6ffc-402d-9a01-bc0067561209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-19 11:46:36--  https://raw.githubusercontent.com/LDJWJ/OpenAIGPTForPythonDevelopersFiles/main/datasets/ch17_news_category_dataset/news.json.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26378283 (25M) [application/zip]\n",
            "Saving to: ‘data/news.json.zip’\n",
            "\n",
            "data/news.json.zip  100%[===================>]  25.16M  39.3MB/s    in 0.6s    \n",
            "\n",
            "2024-12-19 11:46:39 (39.3 MB/s) - ‘data/news.json.zip’ saved [26378283/26378283]\n",
            "\n",
            "Archive:  data/news.json.zip\n",
            "  inflating: data/news.json          \n",
            "total 85252\n",
            "-rw-rw-r-- 1 root root 87295572 Sep 24  2022 news.json\n"
          ]
        }
      ],
      "source": [
        "# 디렉터리 생성\n",
        "!rm -rf data\n",
        "!mkdir -p data\n",
        "\n",
        "# 데이터셋 다운로드\n",
        "!wget https://raw.githubusercontent.com/LDJWJ/OpenAIGPTForPythonDevelopersFiles/main/datasets/ch17_news_category_dataset/news.json.zip -O data/news.json.zip\n",
        "\n",
        "# 압축 해제 후 data 디렉터리에 저장\n",
        "!unzip data/news.json.zip -d data\n",
        "\n",
        "# 압축 파일 삭제\n",
        "!rm data/news.json.zip\n",
        "\n",
        "# 파일 생성 확인\n",
        "!ls -ltr data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guBQ1Y0olV0A"
      },
      "source": [
        "### 최종 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbEjo2VDmCGw",
        "outputId": "c493fdf0-71d5-49b1-bc37-90bff7374d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    잘못된 예측: Over 4 Million Americans Roll Up Sleeves For Omicr...\n",
            "실제: U.S. NEWS\n",
            "예측: GOOD NEWS\n",
            "    잘못된 예측: American Airlines Flyer Charged, Banned For Life A...\n",
            "실제: U.S. NEWS\n",
            "예측: TRAVEL\n",
            "    잘못된 예측: 23 Of The Funniest Tweets About Cats And Dogs This...\n",
            "실제: COMEDY\n",
            "예측: WEIRD NEWS\n",
            "    올바른 예측: The Funniest Tweets From Parents This Week (Sept. ...\n",
            "실제: PARENTING\n",
            "예측: PARENTING\n",
            "    잘못된 예측: Woman Who Called Cops On Black Bird-Watcher Loses ...\n",
            "실제: U.S. NEWS\n",
            "예측: WEIRD NEWS\n",
            "    잘못된 예측: Cleaner Was Dead In Belk Bathroom For 4 Days Befor...\n",
            "실제: U.S. NEWS\n",
            "예측: WEIRD NEWS\n",
            "    잘못된 예측: Reporter Gets Adorable Surprise From Her Boyfriend...\n",
            "실제: U.S. NEWS\n",
            "예측: WEIRD NEWS\n",
            "    올바른 예측: Puerto Ricans Desperate For Water After Hurricane ...\n",
            "실제: WORLD NEWS\n",
            "예측: WORLD NEWS\n",
            "    잘못된 예측: How A New Documentary Captures The Complexity Of B...\n",
            "실제: CULTURE & ARTS\n",
            "예측: PARENTING\n",
            "    올바른 예측: Biden At UN To Call Russian War An Affront To Body...\n",
            "실제: WORLD NEWS\n",
            "예측: WORLD NEWS\n",
            "    잘못된 예측: World Cup Captains Want To Wear Rainbow Armbands I...\n",
            "실제: WORLD NEWS\n",
            "예측: QUEER VOICES\n",
            "    올바른 예측: Man Sets Himself On Fire In Apparent Protest Of Fu...\n",
            "실제: WORLD NEWS\n",
            "예측: WORLD NEWS\n",
            "    잘못된 예측: Fiona Threatens To Become Category 4 Storm Headed ...\n",
            "실제: WORLD NEWS\n",
            "예측: MEDIA\n",
            "    잘못된 예측: Twitch Bans Gambling Sites After Streamer Scams Fo...\n",
            "실제: TECH\n",
            "예측: MONEY\n",
            "    잘못된 예측: Virginia Thomas Agrees To Interview With Jan. 6 Pa...\n",
            "실제: U.S. NEWS\n",
            "예측: GOOD NEWS\n",
            "    올바른 예측: Russian Cosmonaut Valery Polyakov Who Broke Record...\n",
            "실제: WORLD NEWS\n",
            "예측: WORLD NEWS\n",
            "    잘못된 예측: 'Reboot' Is A Clever And Not Too Navel-Gazey Look ...\n",
            "실제: CULTURE & ARTS\n",
            "예측: ENTERTAINMENT\n",
            "    올바른 예측: Maury Wills, Base-Stealing Shortstop For Dodgers, ...\n",
            "실제: SPORTS\n",
            "예측: SPORTS\n",
            "    올바른 예측: 4 Russian-Controlled Ukrainian Regions Schedule Vo...\n",
            "실제: WORLD NEWS\n",
            "예측: WORLD NEWS\n",
            "    잘못된 예측: Fiona Barrels Toward Turks And Caicos Islands As C...\n",
            "실제: WORLD NEWS\n",
            "예측: TRAVEL\n",
            "정밀도: 0.35\n"
          ]
        }
      ],
      "source": [
        "# utils.py로 만들어서 사용할 경우, from -- import –의 형태로 import가 필요.\n",
        "# from utils import cosine_similarity\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_score\n",
        "import json\n",
        "\n",
        "def get_embedding(text, model):\n",
        "    # 텍스트에서 줄바꿈(\\n)을 공백(\" \")으로 대체\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    # 임베딩 생성\n",
        "    return client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    ).data[0].embedding\n",
        "\n",
        "# 두 벡터 간의 코사인 유사도를 계산하는 함수\n",
        "def cosine_similarity(a, b):\n",
        "    numerator = np.dot(a, b)  # 벡터 내적 계산\n",
        "    denominator = np.linalg.norm(a) * np.linalg.norm(b)  # 두 벡터의 크기 곱 계산\n",
        "    return numerator / denominator  # 코사인 유사도 반환\n",
        "\n",
        "# 데이터셋에서 모든 카테고리(고유 값) 찾기\n",
        "categories = set()\n",
        "with open('data/news.json', 'r') as file:\n",
        "    for line in file:\n",
        "        data = json.loads(line)\n",
        "        categories.add(data['category'])\n",
        "categories = list(categories)\n",
        "\n",
        "# 문장을 분류하는 함수 정의\n",
        "def classify_sentence(sentence, model):\n",
        "    # 문장의 임베딩 얻기\n",
        "    sentence_embedding = get_embedding(\n",
        "        sentence,\n",
        "        model=model\n",
        "    )\n",
        "    # 문장과 각 카테고리 간의 유사도 점수 계산\n",
        "    similarity_scores = {}\n",
        "    for category in categories:\n",
        "        category_embeddings = get_embedding(\n",
        "            category,\n",
        "            model=model\n",
        "        )\n",
        "        similarity_scores[\n",
        "            category\n",
        "        ] = cosine_similarity(\n",
        "            sentence_embedding,\n",
        "            category_embeddings\n",
        "        )\n",
        "    # 가장 높은 유사도 점수를 가진 카테고리 반환\n",
        "    return max(\n",
        "        similarity_scores,\n",
        "        key=similarity_scores.get\n",
        "    )\n",
        "\n",
        "def evaluate_precision(categories):\n",
        "    # 데이터셋 로드\n",
        "    df = pd.read_json(\n",
        "        \"data/news.json\",\n",
        "        lines=True\n",
        "    ).head(20)\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    model = \"text-embedding-ada-002\"\n",
        "    # 각 문장 분류\n",
        "    for _, row in df.iterrows():\n",
        "        real_category = row['category']\n",
        "        predicted_category = classify_sentence(\n",
        "            row['headline'],\n",
        "            model=model\n",
        "        )\n",
        "        y_true.append(real_category)\n",
        "        y_pred.append(predicted_category)\n",
        "        if real_category != predicted_category:\n",
        "            print(\n",
        "                \"    잘못된 예측: \"\n",
        "                f\"{row['headline'][:50]}...\\n\"\n",
        "                f\"실제: {real_category[:20]}\\n\"\n",
        "                f\"예측: {predicted_category[:20]}\"\n",
        "            )\n",
        "        else:\n",
        "            print(\n",
        "                \"    올바른 예측: \"\n",
        "                f\"{row['headline'][:50]}...\\n\"\n",
        "                f\"실제: {real_category[:20]}\\n\"\n",
        "                f\"예측: {predicted_category[:20]}\"\n",
        "            )\n",
        "\n",
        "    # 정밀도 점수 계산\n",
        "    return precision_score(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        average='micro',\n",
        "        labels=categories\n",
        "    )\n",
        "\n",
        "# 분류기의 정밀도 평가\n",
        "precision = evaluate_precision(categories)\n",
        "print(f\"정밀도: {precision}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6mIzfbcnM7X"
      },
      "source": [
        "### Practical Application of Fine-Tuning - p178"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCNfr-ycBW6X"
      },
      "source": [
        "* data.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oq8uipNn6TN"
      },
      "source": [
        "```\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a smart home assistant\"}, {\"role\": \"user\", \"content\": \"When do I have to start the heater?\"}, {\"role\": \"assistant\",\"content\": \"Every day in the morning at 7AM. You should stop it at 2PM\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a smart home assistant.\"}, {\"role\": \"user\", \"content\": \"Where is the garage remote control?\"}, {\"role\": \"assistant\", \"content\": \"Next to the yellow door, on the key ring\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a smart home assistant.\"}, {\"role\": \"user\", \"content\": \"Is it necessary to program the scent diffuser every day?\"},{\"role\": \"assistant\", \"content\": \"The scent diffuser is already programmed, you just need to recharge it when its battery is low\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a smart home assistant.\"}, {\"role\": \"user\", \"content\": \"How do I reset the WiFi router?\"}, {\"role\": \"assistant\", \"content\": \"Unplug the router, wait for 30 seconds, then plug it back in.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a smart home assistant.\"}, {\"role\": \"user\", \"content\": \"How do I connect my phone to the smart TV?\"}, {\"role\": \"assistant\", \"content\": \"Go to settings on your phone, select 'Screen Mirroring', and choose the smart TV from the list.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a smart home assistant.\"}, {\"role\": \"user\", \"content\": \"What's the Wi-Fi password?\"}, {\"role\": \"assistant\", \"content\": \"The Wi-Fi password is 'HomeNetwork123'.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a smart home assistant.\"}, {\"role\": \"user\", \"content\": \"How to hard-reset the smart TV?\"}, {\"role\": \"assistant\", \"content\": \"Press and hold the power button on the remote for 10 seconds.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a smart home assistant.\"}, {\"role\": \"user\", \"content\": \"How to call the police?\"}, {\"role\": \"assistant\", \"content\":\"Dial 911 on your phone.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a smart home assistant.\"}, {\"role\": \"user\", \"content\": \"How to change the wifi password?\"}, {\"role\": \"assistant\", \"content\": \"Go to the router settings, select 'Wireless', and change the password.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a smart home assistant.\"}, {\"role\": \"user\", \"content\": \"How to change the channel on the TV?\"}, {\"role\": \"assistant\", \"content\": \"Press the 'Channel Up' or 'Channel Down' button on the remote.\"}]}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHLG60pnZF_2"
      },
      "source": [
        "```\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"}, {\"role\": \"user\", \"content\": \"히터를 언제 켜야 하나요?\"}, {\"role\": \"assistant\", \"content\": \"매일 아침 7시에 켜세요. 오후 2시에 꺼야 합니다.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"}, {\"role\": \"user\", \"content\": \"차고 리모컨이 어디에 있나요?\"}, {\"role\": \"assistant\", \"content\": \"노란색 문 옆, 열쇠 고리에 있습니다.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"}, {\"role\": \"user\", \"content\": \"향기 디퓨저를 매일 프로그래밍해야 하나요?\"}, {\"role\": \"assistant\", \"content\": \"향기 디퓨저는 이미 프로그래밍되어 있으므로 배터리가 낮을 때 충전만 하면 됩니다.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"}, {\"role\": \"user\", \"content\": \"WiFi 라우터를 어떻게 재설정하나요?\"}, {\"role\": \"assistant\", \"content\": \"라우터의 전원을 뽑고 30초 동안 기다린 후 다시 연결하세요.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"}, {\"role\": \"user\", \"content\": \"내 휴대폰을 스마트 TV에 어떻게 연결하나요?\"}, {\"role\": \"assistant\", \"content\": \"휴대폰 설정에서 '스크린 미러링'을 선택한 후 목록에서 스마트 TV를 선택하세요.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"}, {\"role\": \"user\", \"content\": \"와이파이 비밀번호가 뭐야?\"}, {\"role\": \"assistant\", \"content\": \"와이파이 비밀번호는 'HomeNetwork123'입니다.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"}, {\"role\": \"user\", \"content\": \"스마트 TV를 하드 리셋하는 방법은?\"}, {\"role\": \"assistant\", \"content\": \"리모컨의 전원 버튼을 10초 동안 누르고 계세요.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"}, {\"role\": \"user\", \"content\": \"경찰에 어떻게 전화하나요?\"}, {\"role\": \"assistant\", \"content\": \"휴대폰에서 911에 전화하세요.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"}, {\"role\": \"user\", \"content\": \"와이파이 비밀번호를 어떻게 변경하나요?\"}, {\"role\": \"assistant\", \"content\": \"라우터 설정으로 이동하여 '무선'을 선택한 후 비밀번호를 변경하세요.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"}, {\"role\": \"user\", \"content\": \"TV 채널을 어떻게 변경하나요?\"}, {\"role\": \"assistant\", \"content\": \"리모컨에서 '채널 업' 또는 '채널 다운' 버튼을 누르세요.\"}]}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJPG82lQqGTU"
      },
      "outputs": [],
      "source": [
        "### fine_tuning.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUXt82LSZwk2",
        "outputId": "99d71478-b7e0-4885-c317-4f03e33e02bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file-TDD2E7WUk5AGnYKuwYuSSs\n"
          ]
        }
      ],
      "source": [
        "import os, sys  # os와 sys 모듈 불러오기\n",
        "\n",
        "# 파일 경로 정의\n",
        "file_path = os.path.join('data.jsonl')  # 업로드할 파일 이름\n",
        "\n",
        "# 파일 업로드\n",
        "uploaded = client.files.create(\n",
        "    file=open(file_path, \"rb\"),  # 파일을 읽기 모드(rb)로 열어 업로드\n",
        "    purpose=\"fine-tune\"  # 목적을 파인 튜닝으로 설정\n",
        ")\n",
        "\n",
        "# 업로드된 파일 ID 가져오기\n",
        "file_id = uploaded.id\n",
        "print(file_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qfcORZ5aaYn"
      },
      "source": [
        "### 20-1 파인 튜닝의 실제 적용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4eqzkbfaaSt",
        "outputId": "69f1ae89-2a82-410f-a721-e2a34fe741b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file-K7GVPhYsw8NyEKcoATzZHt\n"
          ]
        }
      ],
      "source": [
        "import os, sys  # os와 sys 모듈 불러오기\n",
        "\n",
        "# 파일 경로 정의\n",
        "file_path = os.path.join('data.jsonl')  # 업로드할 파일 이름\n",
        "\n",
        "# 파일 업로드\n",
        "uploaded = client.files.create(\n",
        "    file=open(file_path, \"rb\"),  # 파일을 읽기 모드(rb)로 열어 업로드\n",
        "    purpose=\"fine-tune\"  # 목적을 파인 튜닝으로 설정\n",
        ")\n",
        "\n",
        "# 업로드된 파일 ID 가져오기\n",
        "file_id = uploaded.id\n",
        "print(file_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5vy9kKPdNed",
        "outputId": "dbf62cdd-b653-4936-9d09-feb4722f2ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "파일 유효성 검사 중입니다.\n",
            "................................................................................................................................파인 튜닝이 진행 중입니다.\n",
            "파인 튜닝 상태 queued\n",
            ".............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "파인 튜닝이 완료되었습니다.\n",
            "새로운 모델 이름: ft:gpt-4o-mini-2024-07-18:personal::AWhT4nWt\n"
          ]
        }
      ],
      "source": [
        "# 사용할 모델 설정\n",
        "model = \"gpt-4o-mini-2024-07-18\"\n",
        "\n",
        "# 파인 튜닝 작업 생성\n",
        "fine_tune_job = client.fine_tuning.jobs.create(\n",
        "    training_file=file_id,  # 업로드된 파일 ID를 학습 데이터로 사용\n",
        "    model=model  # 사용할 모델 지정\n",
        ")\n",
        "\n",
        "print()\n",
        "print(\"파일 유효성 검사 중입니다.\")  # 파일 유효성 검사 중 메시지 출력\n",
        "\n",
        "# 파일 유효성 검사 진행 확인\n",
        "while fine_tune_job.status == \"validating_files\":\n",
        "    fine_tune_job = client.fine_tuning.jobs.retrieve(fine_tune_job.id)  # 현재 작업 상태를 다시 불러옴\n",
        "    print(\".\", end=\"\", flush=True)  # 진행 표시 출력\n",
        "\n",
        "print(\"파인 튜닝이 진행 중입니다.\")  # 파인 튜닝 진행 중 메시지 출력\n",
        "print(\"파인 튜닝 상태\", fine_tune_job.status)\n",
        "\n",
        "# 파인 튜닝이 실행 중이거나 대기 중일 때 작업 상태 확인\n",
        "while fine_tune_job.status == \"running\" or fine_tune_job.status == \"queued\":\n",
        "    fine_tune_job = client.fine_tuning.jobs.retrieve(fine_tune_job.id)  # 현재 작업 상태를 다시 불러옴\n",
        "    print(\".\", end=\"\", flush=True)   # 진행 표시 출력\n",
        "\n",
        "print()\n",
        "print(\"파인 튜닝이 완료되었습니다.\")  # 파인 튜닝 완료 메시지 출력\n",
        "\n",
        "# 새로운 모델 이름 출력\n",
        "print(\"새로운 모델 이름: \" + fine_tune_job.fine_tuned_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNcvbASaebZ_",
        "outputId": "45411c8d-49e9-48b4-cecc-79c8b202b1c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파인 튜닝 작업 status: succeeded\n"
          ]
        }
      ],
      "source": [
        "# 새로운 모델 이름 출력\n",
        "print(\"파인 튜닝 작업 status: \" + fine_tune_job.status)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brTgBrk1sCT3"
      },
      "source": [
        "### 파인튜닝 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye3tF0C8mfm-",
        "outputId": "25f84293-ba59-43d3-a9b3-3b772042268b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install colorama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPIkzLgAmc3z",
        "outputId": "2d7f8476-ff72-4142-ffc8-d03a0ef17d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: (종료하려면 'exit' 또는 'quit'을 입력하세요.): 와이파이 비밀번호 변경은?\n",
            "Output: 라우터 설정으로 이동하여 '무선'을 선택한 후 비밀번호를 변경하세요.\n",
            "\n",
            "Input: (종료하려면 'exit' 또는 'quit'을 입력하세요.): TV 채널 변경\n",
            "Output: 리모컨에서 '채널 업' 또는 '채널 다운' 버튼을 누르세요.\n",
            "\n",
            "Input: (종료하려면 'exit' 또는 'quit'을 입력하세요.): exit\n"
          ]
        }
      ],
      "source": [
        "# 모델 이름 설정\n",
        "# model = \"$FINE_TUNED_MODEL\"\n",
        "model = \"ft:gpt-4o-mini-2024-07-18:personal::AEFlKEZh\"\n",
        "\n",
        "# 기본 시스템 메시지 설정\n",
        "base_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"  # 스마트 홈 역할 정의\n",
        "    }\n",
        "]\n",
        "\n",
        "# 사용자 입력을 계속 받기 위한 무한 반복문\n",
        "while True:\n",
        "    messages = base_messages.copy()  # 기본 메시지를 복사하여 새로운 메시지 리스트 생성\n",
        "\n",
        "    # 사용자 입력 받기\n",
        "    request = input(\"Input: (종료하려면 'exit' 또는 'quit'을 입력하세요.): \")\n",
        "\n",
        "    # 'exit' 또는 'quit' 입력 시 반복문 종료\n",
        "    if request.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "\n",
        "    # 사용자 입력을 메시지 리스트에 추가\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{request}\"  # 사용자 입력을 content로 추가\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # OpenAI API에 대화 생성 요청 보내기\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,        # 사용할 모델 설정\n",
        "        messages=messages,  # 메시지 리스트 전달\n",
        "        max_tokens=200,     # 최대 토큰 수 설정\n",
        "        temperature=0,      # 응답의 무작위성 설정 (0으로 설정. 일관성 있는 응답 생성)\n",
        "    )\n",
        "\n",
        "    # API 응답 내용 추출\n",
        "    content = response.choices[0].message.content.strip()  # 응답 내용에서 공백 제거\n",
        "\n",
        "    # 간단히 출력\n",
        "    print(f\"Output: {content}\")\n",
        "    print()  # 출력 후 줄바꿈\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvEyCJPxisWe",
        "outputId": "fa00aeb4-1a5e-4535-911a-bf5df245aec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mInput: (종료하려면 'exit' 또는 'quit' 을 입력하세요. ): \u001b[0m와이파이 비밀번호 변경은?\n",
            "\u001b[33mOutput: \u001b[0m라우터 설정으로 이동하여 '무선'을 선택한 후 비밀번호를 변경하세요.\n",
            "\n",
            "\u001b[32mInput: (종료하려면 'exit' 또는 'quit' 을 입력하세요. ): \u001b[0mTV 채널 변경 \n",
            "\u001b[33mOutput: \u001b[0m리모컨에서 '채널 업' 또는 '채널 다운' 버튼을 누르세요.\n",
            "\n",
            "\u001b[32mInput: (종료하려면 'exit' 또는 'quit' 을 입력하세요. ): \u001b[0mquit\n"
          ]
        }
      ],
      "source": [
        "import click  # click 라이브러리 불러오기\n",
        "\n",
        "# 모델 이름 설정\n",
        "# model = \"$FINE_TUNED_MODEL\"\n",
        "model = \"ft:gpt-4o-mini-2024-07-18:personal::AEFlKEZh\"\n",
        "\n",
        "# 기본 시스템 메시지 설정\n",
        "base_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 스마트 홈 어시스턴트입니다.\"  # 스마트 홈 역할 정의\n",
        "    }\n",
        "]\n",
        "\n",
        "# 사용자 입력을 계속 받기 위한 무한 반복문\n",
        "while True:\n",
        "    messages = base_messages.copy()  # 기본 메시지를 복사하여 새로운 메시지 리스트 생성\n",
        "\n",
        "    # 사용자 입력 받기\n",
        "    request = input(\n",
        "        click.style(  # 입력 안내 스타일 지정\n",
        "            \"Input: (종료하려면 'exit' 또는 'quit' 을 입력하세요. ): \",\n",
        "            fg=\"green\"  # 녹색 텍스트로 프롬프트 표시\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # 'exit' 또는 'quit' 입력 시 반복문 종료\n",
        "    if request.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "\n",
        "    # 사용자 입력을 메시지 리스트에 추가\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{request}\"  # 사용자 입력을 content로 추가\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # OpenAI API에 대화 생성 요청 보내기\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,        # 사용할 모델 설정\n",
        "        messages=messages,  # 메시지 리스트 전달\n",
        "        max_tokens=200,     # 최대 토큰 수 설정\n",
        "        temperature=0,      # 응답의 무작위성 설정 (0으로 설정. 일관성 있는 응답 생성)\n",
        "    )\n",
        "\n",
        "    # API 응답 내용 추출\n",
        "    content = response.choices[0].message.content.strip()  # 응답 내용에서 공백 제거\n",
        "\n",
        "    # 스타일을 지정하여 출력\n",
        "    click.echo(\n",
        "        click.style(\"Output: \", fg=\"yellow\") + content  # 'Output:' 텍스트를 노란색으로 출력 후 응답 내용 출력\n",
        "    )\n",
        "    click.echo()  # 출력 후 줄바꿈"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No8gZlrWu6xB"
      },
      "source": [
        "### Fine-Tuning Best Practices - p185\n",
        " * data_analysis.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-4kcu-DAmDK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "import os\n",
        "\n",
        "file_path = os.path.join('src', 'data.jsonl')\n",
        "\n",
        "# validate the dataset file format\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    try:\n",
        "        dataset = [json.loads(line) for line in f]\n",
        "    except:\n",
        "        raise ValueError(\n",
        "            \"The dataset must be a valid JSONL file\"\n",
        "        )\n",
        "\n",
        "# validate the dataset size\n",
        "size = len(dataset)\n",
        "if size < 10:\n",
        "    raise ValueError(\n",
        "        \"The dataset must contain at least 10 examples\"\n",
        "    )\n",
        "\n",
        "# validate the dataset content\n",
        "format_errors = defaultdict(int)\n",
        "for line in dataset:\n",
        "    # Data Type Check:\n",
        "    # Verify if each entry is a dictionary\n",
        "    if not isinstance(line, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    # Presence of Message List:\n",
        "    # Check if there is a 'messages' list\n",
        "    messages = line.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        # Message Keys Check:\n",
        "        # Ensure each message has 'role' and 'content' keys\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        # Valid keys that a message can contain\n",
        "        valid_keys = (\n",
        "            \"role\",\n",
        "            \"content\",\n",
        "            \"name\",\n",
        "            \"function_call\"\n",
        "        )\n",
        "\n",
        "        # Unrecognized Keys in Messages:\n",
        "        # Check for any keys not in valid_keys\n",
        "        if any(k not in valid_keys for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        # Valid roles that a message can have\n",
        "        valid_roles = (\n",
        "            \"system\",\n",
        "            \"user\",\n",
        "            \"assistant\",\n",
        "            \"function\"\n",
        "        )\n",
        "\n",
        "        # Role Validation:\n",
        "        # Check if 'role' is one of the valid_roles\n",
        "        if message.get(\"role\", None) not in valid_roles:\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        # Content Validation:\n",
        "        # Check if 'content' is textual and a string\n",
        "        # Also, check if 'content' or 'function_call' is present\n",
        "        if (not content and not function_call) or \\\n",
        "                not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    # Assistant Message Presence:\n",
        "    # Check if there is at least one assistant message\n",
        "    if not any(\n",
        "        message.get(\"role\", None) == \"assistant\"\n",
        "        for message in messages\n",
        "    ):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "# Print the errors, if any\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "    raise ValueError(\n",
        "        \"The dataset contains errors\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrXv8Q5JBMSS"
      },
      "source": [
        "### fine_tuning.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noAm2A2PBrXi",
        "outputId": "1834c300-273d-4d96-e2d0-a4457e9fc052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "파일 검증 진행 중\n",
            ".......................................................................................................................................\n",
            "파인 튜닝 진행 중\n",
            "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "파인 튜닝 완료\n",
            "새로운 모델의 이름은: ft:gpt-4o-mini-2024-07-18:personal::AWiBWHv8\n"
          ]
        }
      ],
      "source": [
        "# fine_tuning.py\n",
        "\n",
        "# 인증 부분은 구글 코랩의 경우, 앞에서 수행되었다면, 생략이 가능합니다.\n",
        "# 인증 부분\n",
        "# init_api()\n",
        "\n",
        "import os, sys, json\n",
        "from collections import defaultdict\n",
        "\n",
        "# 데이터 파일 경로 설정\n",
        "file_path = os.path.join(\n",
        "    os.getcwd(),  # 현재 파일의 디렉터리 경로\n",
        "    'data_old.jsonl'  # 데이터 파일 이름\n",
        ")\n",
        "\n",
        "# 데이터셋 파일 형식 검증\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    try:\n",
        "        # 각 줄을 JSON 형식으로 로드하여 리스트로 저장\n",
        "        dataset = [json.loads(line) for line in f]\n",
        "    except:\n",
        "        # JSONL 파일 형식이 유효하지 않으면 오류 발생\n",
        "        raise ValueError(\"데이터셋은 유효한 JSONL 파일이어야 합니다.\")\n",
        "\n",
        "# 데이터셋 크기 검증\n",
        "size = len(dataset)\n",
        "if size < 10:\n",
        "    # 최소 10개 이상의 예제가 있어야 함\n",
        "    raise ValueError(\"데이터셋에는 최소 10개의 예제가 포함되어야 합니다.\")\n",
        "\n",
        "# 데이터셋 내용 검증\n",
        "format_errors = defaultdict(int)  # 형식 오류를 저장할 딕셔너리 초기화\n",
        "for line in dataset:\n",
        "    # 데이터 유형 확인:\n",
        "    # 각 항목이 딕셔너리인지 검증\n",
        "    if not isinstance(line, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    # 메시지 리스트 존재 여부 확인:\n",
        "    # 'messages' 리스트가 포함되어 있는지 확인\n",
        "    messages = line.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        # 메시지 키 확인:\n",
        "        # 각 메시지에 'role' 및 'content' 키가 있는지 확인\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        # 메시지에 포함될 수 있는 유효한 키\n",
        "        valid_keys = (\"role\", \"content\", \"name\", \"function_call\")\n",
        "\n",
        "        # 인식되지 않은 키 확인:\n",
        "        # 유효한 키 목록에 없는 키가 포함되어 있는지 확인\n",
        "        if any(k not in valid_keys for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        # 메시지에 허용되는 유효한 역할(role) 목록\n",
        "        valid_roles = (\"system\", \"user\", \"assistant\", \"function\")\n",
        "\n",
        "        # 역할(role) 확인:\n",
        "        # 'role' 값이 유효한 역할 중 하나인지 검증\n",
        "        if message.get(\"role\", None) not in valid_roles:\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        # 'content'와 'function_call' 값 가져오기\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        # 콘텐츠(content) 확인:\n",
        "        # 'content'가 텍스트 형태의 문자열인지, 또는 'function_call'이 있는지 검증\n",
        "        if (not content and not function_call) or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    # assistant 메시지 존재 여부 확인:\n",
        "    # 각 대화에 최소 한 개 이상의 assistant 메시지가 포함되어 있는지 확인\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "# 오류가 있는 경우, 오류 내용 출력\n",
        "if format_errors:\n",
        "    print(\"발견된 오류:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "    raise ValueError(\"데이터셋에 오류가 포함되어 있습니다.\")\n",
        "\n",
        "# 파일 업로드\n",
        "uploaded = client.files.create(\n",
        "    file=open(file_path, \"rb\"),  # 파일을 읽기 모드로 열어 업로드\n",
        "    purpose=\"fine-tune\"          # 파인 튜닝 용도로 파일 설정\n",
        ")\n",
        "file_id = uploaded.id  # 업로드된 파일의 ID 저장\n",
        "model = \"gpt-4o-mini-2024-07-18\"  # 파인 튜닝할 모델 설정\n",
        "\n",
        "# 파인 튜닝 작업 생성\n",
        "fine_tune_job = client.fine_tuning.jobs.create(\n",
        "    training_file=file_id,\n",
        "    model=model,\n",
        ")\n",
        "\n",
        "print(\"\\n파일 검증 진행 중\")\n",
        "while fine_tune_job.status == \"validating_files\":  # 파일 검증 중일 때 상태 체크\n",
        "    fine_tune_job = client.fine_tuning.jobs.retrieve(fine_tune_job.id)\n",
        "    print(\".\", end=\"\", flush=True)  # 진행 상황 표시\n",
        "\n",
        "print(\"\\n파인 튜닝 진행 중\")\n",
        "# 파인 튜닝 실행 중 또는 대기 중일 때 상태 체크\n",
        "while fine_tune_job.status == \"running\" or fine_tune_job.status == \"queued\":\n",
        "    fine_tune_job = client.fine_tuning.jobs.retrieve(fine_tune_job.id)\n",
        "    print(\".\", end=\"\", flush=True)  # 진행 상황 표시\n",
        "\n",
        "print(\"\\n파인 튜닝 완료\")\n",
        "print(\"새로운 모델의 이름은: \" + fine_tune_job.fine_tuned_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9zCQth27af_"
      },
      "source": [
        "### 20-2 파인 튜닝 최적화: 학습률, 배치 크기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIO-sX9-7adA",
        "outputId": "72bee118-a28c-4c5c-f5bb-74c481f69350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created_at=1701832706 => created_at : 2023-12-06 12:18:26\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timezone\n",
        "import pytz\n",
        "\n",
        "def format_timestamp_to_kst(timestamp):\n",
        "    \"\"\"\n",
        "    타임스탬프를 KST (한국 시간대) 시간 문자열로 변환, None이면 None을 반환\n",
        "    \"\"\"\n",
        "    if timestamp is not None:\n",
        "        utc_time = datetime.fromtimestamp(timestamp, tz=timezone.utc)\n",
        "        kst_time = utc_time.astimezone(pytz.timezone(\"Asia/Seoul\"))\n",
        "        return kst_time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    return None\n",
        "\n",
        "# 테스트\n",
        "print(f\"created_at=1701832706 => created_at : {format_timestamp_to_kst(1701832706)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkQFqtut7eVm",
        "outputId": "a8ab6135-3759-40c9-eb9c-270621054671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파인 튜닝 작업 리스트 개수 :  20\n",
            "FineTuningJob(id='ftjob-qyPIFHVajbqxkG94X75renNT', created_at=1732359078, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AWiBWHv8', finished_at=1732359704, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-USELLDQbs8dzQWLSHAY7Mg'], seed=652545077, status='succeeded', trained_tokens=5490, training_file='file-PD1qBJgtWLrGfe2Av2CR2u', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-qyPIFHVajbqxkG94X75renNT, fine_tuned_model : ft:gpt-4o-mini-2024-07-18:personal::AWiBWHv8\n",
            "생성일시 : 2024-11-23 19:51:18, 완료일시 : 2024-11-23 20:01:44\n",
            "\n",
            "FineTuningJob(id='ftjob-hNsa27PCpGvCqUXA54IM2BsV', created_at=1732356349, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AWhT4nWt', finished_at=1732356948, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-547MuzHxz9M3TBDLTXFZgk'], seed=1548496836, status='succeeded', trained_tokens=5490, training_file='file-K7GVPhYsw8NyEKcoATzZHt', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-hNsa27PCpGvCqUXA54IM2BsV, fine_tuned_model : ft:gpt-4o-mini-2024-07-18:personal::AWhT4nWt\n",
            "생성일시 : 2024-11-23 19:05:49, 완료일시 : 2024-11-23 19:15:48\n",
            "\n",
            "FineTuningJob(id='ftjob-CxUW0t7TJSWPgiaSYPL2mqRo', created_at=1732356159, error=Error(code='invalid_training_file', message=\"The job failed due to an invalid training file. This training file was blocked by our moderation system because it contains too many examples that violate OpenAI's usage policies, or because it attempts to create model outputs that violate OpenAI's usage policies.\", param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=[], seed=2013811195, status='failed', trained_tokens=None, training_file='file-JzDPT4bXb76x9Ys3mDSShx', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-CxUW0t7TJSWPgiaSYPL2mqRo, fine_tuned_model : None\n",
            "생성일시 : 2024-11-23 19:02:39, 완료일시 : None\n",
            "\n",
            "FineTuningJob(id='ftjob-1Km7l96m4xZYgppfze0woR6J', created_at=1732355873, error=Error(code='invalid_training_file', message=\"The job failed due to an invalid training file. This training file was blocked by our moderation system because it contains too many examples that violate OpenAI's usage policies, or because it attempts to create model outputs that violate OpenAI's usage policies.\", param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=[], seed=510970934, status='failed', trained_tokens=None, training_file='file-JzDPT4bXb76x9Ys3mDSShx', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-1Km7l96m4xZYgppfze0woR6J, fine_tuned_model : None\n",
            "생성일시 : 2024-11-23 18:57:53, 완료일시 : None\n",
            "\n",
            "FineTuningJob(id='ftjob-Xyxn5igwKRRqVADPyNBsTw2x', created_at=1732355151, error=Error(code='invalid_training_file', message=\"The job failed due to an invalid training file. This training file was blocked by our moderation system because it contains too many examples that violate OpenAI's usage policies, or because it attempts to create model outputs that violate OpenAI's usage policies.\", param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=[], seed=44431736, status='failed', trained_tokens=None, training_file='file-TDD2E7WUk5AGnYKuwYuSSs', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-Xyxn5igwKRRqVADPyNBsTw2x, fine_tuned_model : None\n",
            "생성일시 : 2024-11-23 18:45:51, 완료일시 : None\n",
            "\n",
            "FineTuningJob(id='ftjob-XMimELoyU0UfSTqj0R9XJa8M', created_at=1728262085, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AFWKuokN', finished_at=1728262582, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-GFvMJttkxU65RfI8fcNTVirX'], seed=528054414, status='succeeded', trained_tokens=118881, training_file='file-1OqhXE4OM9mZQZuQX3M0LxmV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-XMimELoyU0UfSTqj0R9XJa8M, fine_tuned_model : ft:gpt-4o-mini-2024-07-18:personal::AFWKuokN\n",
            "생성일시 : 2024-10-07 09:48:05, 완료일시 : 2024-10-07 09:56:22\n",
            "\n",
            "FineTuningJob(id='ftjob-E3jz9nIzpSIZG18HlURiSE8q', created_at=1728138686, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AF0GFc3e', finished_at=1728139285, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-oWvvjjXcJXmj7HiTgkXZWwN4'], seed=1041467022, status='succeeded', trained_tokens=9090, training_file='file-bv9w1ge1Osx6Istbc0IYX6So', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-E3jz9nIzpSIZG18HlURiSE8q, fine_tuned_model : ft:gpt-4o-mini-2024-07-18:personal::AF0GFc3e\n",
            "생성일시 : 2024-10-05 23:31:26, 완료일시 : 2024-10-05 23:41:25\n",
            "\n",
            "FineTuningJob(id='ftjob-E4br7E25Azqohz8Ui7nFWfU8', created_at=1728123742, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AEwNXrSA', finished_at=1728124362, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-6auzw4zUdPTeTGTAwtA4fBGb'], seed=1361002103, status='succeeded', trained_tokens=4290, training_file='file-CYTfu1uoT5PFKwQhyuwHSg65', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-E4br7E25Azqohz8Ui7nFWfU8, fine_tuned_model : ft:gpt-4o-mini-2024-07-18:personal::AEwNXrSA\n",
            "생성일시 : 2024-10-05 19:22:22, 완료일시 : 2024-10-05 19:32:42\n",
            "\n",
            "FineTuningJob(id='ftjob-13Vj8OpSDuMgTFHv11OJGIqO', created_at=1728122256, error=Error(code='invalid_training_file', message=\"The job failed due to an invalid training file. This training file was blocked by our moderation system because it contains too many examples that violate OpenAI's usage policies, or because it attempts to create model outputs that violate OpenAI's usage policies.\", param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=[], seed=1159594038, status='failed', trained_tokens=None, training_file='file-J8YnaDUfLdd0oG7kPRdjWPRC', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-13Vj8OpSDuMgTFHv11OJGIqO, fine_tuned_model : None\n",
            "생성일시 : 2024-10-05 18:57:36, 완료일시 : None\n",
            "\n",
            "FineTuningJob(id='ftjob-SxNrL5jGamgwtRIuSIaN8qY6', created_at=1728028379, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AEXtiPXn', finished_at=1728030256, hyperparameters=Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-3a4yOqfevrh8MsEyam9lh735'], seed=849673039, status='succeeded', trained_tokens=4618638, training_file='file-BCK5K0RyM5duyrvTxuJe4M0d', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-SxNrL5jGamgwtRIuSIaN8qY6, fine_tuned_model : ft:gpt-4o-mini-2024-07-18:personal::AEXtiPXn\n",
            "생성일시 : 2024-10-04 16:52:59, 완료일시 : 2024-10-04 17:24:16\n",
            "\n",
            "FineTuningJob(id='ftjob-MVUPTFjKe2L13wqMKjTmWBBG', created_at=1727963175, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AEGbetzX', finished_at=1727963788, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-LimxhD9VCw0c5bAQnbFYWCL8'], seed=1805877827, status='succeeded', trained_tokens=5490, training_file='file-c1pzGP2i0FnzYarzbAyhrgIM', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-MVUPTFjKe2L13wqMKjTmWBBG, fine_tuned_model : ft:gpt-4o-mini-2024-07-18:personal::AEGbetzX\n",
            "생성일시 : 2024-10-03 22:46:15, 완료일시 : 2024-10-03 22:56:28\n",
            "\n",
            "FineTuningJob(id='ftjob-sf6xqoSMN142dncJbGBzWJLD', created_at=1727961309, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AEG7SH0t', finished_at=1727961916, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-x3kmfWbhSrnbviKYQjC9vUQJ'], seed=1669646840, status='succeeded', trained_tokens=5490, training_file='file-Gat2Oa9aqHw1QZuHdNx1wAVw', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-sf6xqoSMN142dncJbGBzWJLD, fine_tuned_model : ft:gpt-4o-mini-2024-07-18:personal::AEG7SH0t\n",
            "생성일시 : 2024-10-03 22:15:09, 완료일시 : 2024-10-03 22:25:16\n",
            "\n",
            "FineTuningJob(id='ftjob-vHq0HB82SdKrarbDQqVca6Aj', created_at=1727960152, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AEFlKEZh', finished_at=1727960544, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-gPW047wXY6kQV9R1lqoEvSYM'], seed=1694970729, status='succeeded', trained_tokens=5490, training_file='file-2e2UkBslMdun2ZNOKql1ATO4', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-vHq0HB82SdKrarbDQqVca6Aj, fine_tuned_model : ft:gpt-4o-mini-2024-07-18:personal::AEFlKEZh\n",
            "생성일시 : 2024-10-03 21:55:52, 완료일시 : 2024-10-03 22:02:24\n",
            "\n",
            "FineTuningJob(id='ftjob-9GaZNW5chngXZPVepRXOtSC4', created_at=1725863630, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=[], seed=1198886713, status='cancelled', trained_tokens=None, training_file='file-2Ni358mDjFmGkXrbMGRt70FZ', validation_file=None, estimated_finish=1732364751, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-9GaZNW5chngXZPVepRXOtSC4, fine_tuned_model : None\n",
            "생성일시 : 2024-09-09 15:33:50, 완료일시 : None\n",
            "\n",
            "FineTuningJob(id='ftjob-GeWsoZeDZR4ZKevnWuShxzPy', created_at=1725860503, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::A5SqrihB', finished_at=1725865907, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-Kw0CSvQT0oh79GAGoyMlLKi3'], seed=1946659868, status='succeeded', trained_tokens=1134567, training_file='file-NafYqd87IzkiWmI08UzcjK2H', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-GeWsoZeDZR4ZKevnWuShxzPy, fine_tuned_model : ft:gpt-3.5-turbo-0125:personal::A5SqrihB\n",
            "생성일시 : 2024-09-09 14:41:43, 완료일시 : 2024-09-09 16:11:47\n",
            "\n",
            "FineTuningJob(id='ftjob-WaMlshjKxAnAEgMtoehUpbvG', created_at=1725858359, error=Error(code='exceeded_quota', message='Creating this fine-tuning job would exceed your hard limit, please check your plan and billing details.                     Cost of job ftjob-WaMlshjKxAnAEgMtoehUpbvG: USD 34.78. Quota remaining for org-ujuF1J8GkXR8ggNiF9BMBXJp: USD 27.45.', param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=[], seed=2115041226, status='failed', trained_tokens=None, training_file='file-MRiU4GaMgpZUiLpLa5clxBPQ', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-WaMlshjKxAnAEgMtoehUpbvG, fine_tuned_model : None\n",
            "생성일시 : 2024-09-09 14:05:59, 완료일시 : None\n",
            "\n",
            "FineTuningJob(id='ftjob-Ql6ztL0bP0Eo18CU0iuxOAPw', created_at=1725856542, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::A5QUuqiE', finished_at=1725856858, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-w0UhMixAtrKLZXzdKGDtLGxO'], seed=1454211294, status='succeeded', trained_tokens=4330, training_file='file-ov8CcxPnll6YFCKtvKPBivsQ', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-Ql6ztL0bP0Eo18CU0iuxOAPw, fine_tuned_model : ft:gpt-3.5-turbo-0125:personal::A5QUuqiE\n",
            "생성일시 : 2024-09-09 13:35:42, 완료일시 : 2024-09-09 13:40:58\n",
            "\n",
            "FineTuningJob(id='ftjob-Tg6ZNQishggY9YrHON3JM5LC', created_at=1725799870, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::A5Bkf5k8', finished_at=1725800175, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-byMXQ29W9gYjZXQZToex0CVx', 'file-hPfES2dGzTd0s5IiUxrdUN8T'], seed=1892695423, status='succeeded', trained_tokens=4330, training_file='file-guBSMArl3D9YY14Rft0gQfyi', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-Tg6ZNQishggY9YrHON3JM5LC, fine_tuned_model : ft:gpt-3.5-turbo-0125:personal::A5Bkf5k8\n",
            "생성일시 : 2024-09-08 21:51:10, 완료일시 : 2024-09-08 21:56:15\n",
            "\n",
            "FineTuningJob(id='ftjob-gAXVRcetBjDCd3fBOaYczeNC', created_at=1721025492, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9lAFhjd9', finished_at=1721027851, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-8zGd7qgG2VNC4MbXqqOeoTUA'], seed=1606030673, status='succeeded', trained_tokens=668307, training_file='file-x3eMQZhJ8OKmROZjFmfE2vqy', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-gAXVRcetBjDCd3fBOaYczeNC, fine_tuned_model : ft:gpt-3.5-turbo-0125:personal::9lAFhjd9\n",
            "생성일시 : 2024-07-15 15:38:12, 완료일시 : 2024-07-15 16:17:31\n",
            "\n",
            "FineTuningJob(id='ftjob-Yh2ehZYngIgVrSKnhxL0yBc3', created_at=1721025474, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9lARrXzs', finished_at=1721028605, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-75I9pJhoWsFa5xpw5YyXESU0'], seed=873639006, status='succeeded', trained_tokens=668307, training_file='file-x3eMQZhJ8OKmROZjFmfE2vqy', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "id : ftjob-Yh2ehZYngIgVrSKnhxL0yBc3, fine_tuned_model : ft:gpt-3.5-turbo-0125:personal::9lARrXzs\n",
            "생성일시 : 2024-07-15 15:37:54, 완료일시 : 2024-07-15 16:30:05\n",
            "\n"
          ]
        }
      ],
      "source": [
        "models = client.fine_tuning.jobs.list()\n",
        "\n",
        "print(\"파인 튜닝 작업 리스트 개수 : \", len(models.data))\n",
        "\n",
        "# 리스트를 확인합니다.\n",
        "for model in models.data:\n",
        "    print(model)\n",
        "    created_time = format_timestamp_to_kst(model.created_at)\n",
        "    finished_time = format_timestamp_to_kst(model.finished_at)\n",
        "    print(f\"id : {model.id}, fine_tuned_model : {model.fine_tuned_model}\")\n",
        "    print(f\"생성일시 : {created_time}, 완료일시 : {finished_time}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gVImxKV7eYe",
        "outputId": "b32e73a5-c5da-4b70-c8fa-4e4199ded5c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of epochs: 10\n",
            "Learning rate multiplier: 1.8\n",
            "Batch size: 1\n",
            "Trained tokens: 5490\n",
            "Training loss:\n",
            "Step 100: training loss=0.0002349506685277447\n",
            "Step 99: training loss=0.00010747175838332623\n",
            "Step 98: training loss=0.0006081616156734526\n",
            "Step 97: training loss=0.00013605754065793008\n",
            "Step 96: training loss=0.00013368026702664793\n",
            "Step 95: training loss=0.00030587849323637784\n",
            "Step 94: training loss=2.1696090698242188e-05\n",
            "Step 93: training loss=0.0003930005186703056\n",
            "Step 92: training loss=0.000561833381652832\n",
            "Step 91: training loss=0.5122135281562805\n",
            "Step 90: training loss=0.0003412146179471165\n",
            "Step 89: training loss=0.00018758358783088624\n",
            "Step 88: training loss=0.00017811701400205493\n",
            "Step 87: training loss=0.00014527638268191367\n",
            "Step 86: training loss=0.00037149948184378445\n"
          ]
        }
      ],
      "source": [
        "# analytics.py\n",
        "\n",
        "## 초기 인증 함수 불러오기\n",
        "## init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"))\n",
        "\n",
        "# 파인튜닝 작업 가져오기. 확인한 작업 ID를 지정합니다.\n",
        "job_id = \"ftjob-hNsa27PCpGvCqUXA54IM2BsV\"\n",
        "\n",
        "\n",
        "fine_tune_job = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "# 작업 상태 확인\n",
        "status = fine_tune_job.status\n",
        "\n",
        "# 작업이 성공적으로 완료되었을 경우\n",
        "if status == \"succeeded\":\n",
        "    # 학습한 에포크 수 출력\n",
        "    print(f\"Number of epochs: {fine_tune_job.hyperparameters.n_epochs}\")\n",
        "\n",
        "    # 학습률 배수 출력\n",
        "    print(f\"Learning rate multiplier: \\\n",
        "{fine_tune_job.hyperparameters.learning_rate_multiplier}\")\n",
        "\n",
        "    # 배치 크기 출력\n",
        "    print(f\"Batch size: {fine_tune_job.hyperparameters.batch_size}\")\n",
        "\n",
        "    # 학습한 토큰 수 출력\n",
        "    print(f\"Trained tokens: {fine_tune_job.trained_tokens}\")\n",
        "\n",
        "    # 학습 손실 값 출력\n",
        "    print(\"Training loss:\")\n",
        "\n",
        "    # 작업 이벤트 목록 가져오기\n",
        "    events = client.fine_tuning.jobs.list_events(job_id)\n",
        "\n",
        "    # 이벤트 데이터에서 손실 값 출력\n",
        "    for event in events.data:\n",
        "        if event.type == 'metrics':\n",
        "            # 딕셔너리 키를 사용하여 값 접근\n",
        "            step = event.data['step']\n",
        "            train_loss = event.data['train_loss']\n",
        "            print(f\"Step {step}: training loss={train_loss}\")\n",
        "else:\n",
        "    print(\"작업이 아직 진행 중이거나 실패했습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VY4XC09EB-Q"
      },
      "source": [
        "### 모델 평가 p203, analytics.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJhxHkIGFpwQ"
      },
      "source": [
        "## Advanced Fine Tuning: Mental Health Coach - p205"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi9yzREZGL32"
      },
      "outputs": [],
      "source": [
        "# Create the folder (만들어져 있으면 다시 실행할 필요 없음)\n",
        "!mkdir -p data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UTwm2MuGR95",
        "outputId": "5c08fe79-306b-4711-b89f-bb01f416d95f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-11-23 13:05:15--  https://raw.githubusercontent.com/eon01/Openai_GPT_for_Python_Developers_Files/main/datasets/mental_health_counseling_conversations/data.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4790520 (4.6M) [text/plain]\n",
            "Saving to: ‘data/data.json’\n",
            "\n",
            "data/data.json      100%[===================>]   4.57M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-11-23 13:05:15 (64.6 MB/s) - ‘data/data.json’ saved [4790520/4790520]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the data\n",
        "!wget https://raw.githubusercontent.com/eon01/Openai_GPT_for_Python_Developers_Files/main/datasets/mental_health_counseling_conversations/data.json -O data/data.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWRoDzHFGi9P",
        "outputId": "22dcfc47-55af-4470-e4ec-65c28cd0fbad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: setuptools==69.0.3 in /usr/local/lib/python3.10/dist-packages (69.0.3)\n",
            "Requirement already satisfied: langdetect==1.0.9 in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect==1.0.9) (1.16.0)\n",
            "Requirement already satisfied: unidecode==1.3.8 in /usr/local/lib/python3.10/dist-packages (1.3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install setuptools==69.0.3\n",
        "!pip install langdetect==1.0.9\n",
        "!pip install unidecode==1.3.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGA5qdeRG5XR",
        "outputId": "a3eda01e-e312-4662-f7c9-e330e035fe87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wdpngNyIRJu"
      },
      "source": [
        "### 세션 시작 후, 인증 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2IRS-leIRGO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "with open(\"chatgpt.env\") as env:\n",
        "  for line in env:\n",
        "    key, value = line.strip().split(\"=\")\n",
        "    os.environ[key] = value\n",
        "\n",
        "client = OpenAI(api_key  = os.environ['API_KEY'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXgt5knIHEmX"
      },
      "source": [
        "### prepare_data.py - p208"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDtaaBs6Ivih"
      },
      "source": [
        "### 21-2 데이터 셋 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo9WNNirIbAP"
      },
      "outputs": [],
      "source": [
        "# prepare_data.py\n",
        "import json, re\n",
        "from langdetect import detect\n",
        "from unidecode import unidecode\n",
        "\n",
        "# 데이터 리스트 초기화\n",
        "data = []\n",
        "\n",
        "# 텍스트 정제 함수 정의\n",
        "def clean_text(text):\n",
        "    # 일반적인 유니코드 문자를 ASCII 문자로 변환\n",
        "    text = unidecode(text)\n",
        "    # URL 제거\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    # 구두점 주변의 공백 수정\n",
        "    text = re.sub(r'\\s*([,.!?])\\s*', r'\\1 ', text)\n",
        "    # 앞뒤 공백 제거\n",
        "    text = text.strip()\n",
        "    # 구두점 뒤에 공백이 없을 경우 추가\n",
        "    text = re.sub(r'([:,.!?])([^\\s])', r'\\1 \\2', text)\n",
        "    return text\n",
        "\n",
        "# 기존의 'data.jsonl' 파일 내용 초기화 (모든 데이터 삭제)\n",
        "open('data/data.jsonl', 'w').close()\n",
        "\n",
        "# 시스템 메시지 프롬프트 정의\n",
        "system_prompt = (\n",
        "    \"당신은 MendMind, AI 멘탈 헬스 코치입니다. \"\n",
        "    \"당신의 목적은 사용자가 정신 건강 여정을 탐색하는 과정에서 \"\n",
        "    \"공감, 이해, 정서적·심리적 도전 과제에 대한 통찰력을 제공하는 것입니다. \"\n",
        "    \"일반적인 조언과 정서적 지원은 제공할 수 있지만, \"\n",
        "    \"개인적인 연락을 하거나, 일정 예약을 하거나, 특정 위치 정보를 공유할 수 없습니다. \"\n",
        "    \"당신의 역할은 사용자가 대처 전략을 찾도록 돕고, 정신 건강 주제에 대한 정보를 제공하며, \"\n",
        "    \"필요 시 전문가 리소스를 안내하는 것입니다. \"\n",
        "    \"일반적인 대화를 나눌 수 있지만, 주요 초점은 비밀을 유지하면서 사용자에게 최선의 지원을 제공하는 것입니다.\"\n",
        ")\n",
        "\n",
        "# 데이터 파일 열기 및 데이터 읽기\n",
        "with open('data/data.json', 'r') as file:\n",
        "    for line in file:\n",
        "        json_line = json.loads(line)  # 각 줄의 JSON 데이터를 파싱\n",
        "        context = json_line[\"Context\"]  # 사용자 질문 (Context) 추출\n",
        "        response = json_line[\"Response\"]  # 심리학자의 답변 (Response) 추출\n",
        "        try:\n",
        "            # Context가 비어있지 않고 Response가 10단어 이상일 때\n",
        "            if len(context) > 0 and len(response.split()) > 10:\n",
        "                # Context와 Response가 모두 영어일 경우\n",
        "                if detect(context) == \"en\" and detect(response) == \"en\":\n",
        "                    # 시스템, 사용자, 어시스턴트 메시지 구성\n",
        "                    system = {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": system_prompt\n",
        "                    }\n",
        "                    user = {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": clean_text(context)\n",
        "                    }\n",
        "                    assistant = {\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": clean_text(response)\n",
        "                    }\n",
        "                    messages = {\n",
        "                        \"messages\": [system, user, assistant]\n",
        "                    }\n",
        "                    # data.jsonl 파일에 메시지 작성 (추가)\n",
        "                    with open('data/data.jsonl', 'a') as file:\n",
        "                        file.write(json.dumps(messages) + '\\n')\n",
        "\n",
        "        except Exception as e:\n",
        "            # 오류 발생 시 오류 메시지 출력 및 해당 데이터 출력\n",
        "            print(f\"Error:\\n Context: {context}\\n Response: {response}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mp6i6YVJOVX"
      },
      "source": [
        "### 데이터 검증 및 변환 후, 파인 튜닝 작업 시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZYsgc80Hddj",
        "outputId": "0b949abf-ca84-46bf-e40f-d0a8961764b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일 검증 중\n",
            "...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "파인튜닝 진행 중\n",
            ".................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "파인튜닝 완료\n",
            "새로운 모델의 이름은: ft:gpt-4o-mini-2024-07-18:personal::AWkpvDz1\n"
          ]
        }
      ],
      "source": [
        "# fine_tuning.py\n",
        "\n",
        "import os, sys, json\n",
        "from collections import defaultdict\n",
        "\n",
        "# 실행 환경이 구글 코랩의 경우, 인증 부분은 앞에서 실행했다면, 작성하지 않아도 됩니다.\n",
        "# 인증 시작\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"))\n",
        "# 인증 종료 부분\n",
        "\n",
        "# 데이터 파일 경로 설정\n",
        "file_path = os.path.join('data/data.jsonl')  # 데이터 파일 이름 설정\n",
        "\n",
        "# 데이터셋 파일 형식 검증\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    try:\n",
        "        dataset = [json.loads(line) for line in f]  # 파일에서 각 줄을 읽어 JSON 객체로 변환\n",
        "    except:\n",
        "        raise ValueError(\"데이터셋은 유효한 JSONL 파일이어야 합니다\")\n",
        "\n",
        "# 데이터셋 크기 검증\n",
        "size = len(dataset)\n",
        "if size < 10:\n",
        "    raise ValueError(\"데이터셋은 최소 10개의 예제를 포함해야 합니다\")\n",
        "\n",
        "# 데이터셋 내용 검증\n",
        "format_errors = defaultdict(int)  # 형식 오류를 저장할 딕셔너리 초기화\n",
        "for line in dataset:\n",
        "    # 데이터 타입 확인:\n",
        "    # 각 항목이 딕셔너리인지 확인\n",
        "    if not isinstance(line, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    # 메시지 목록 존재 여부 확인:\n",
        "    # 각 항목에 'messages' 리스트가 있는지 확인\n",
        "    messages = line.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    # 각 메시지의 키와 내용 확인\n",
        "    for message in messages:\n",
        "        # 메시지 키 확인:\n",
        "        # 각 메시지에 'role'과 'content' 키가 있는지 확인\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        # 메시지에서 유효한 키 목록 설정\n",
        "        valid_keys = (\n",
        "            \"role\",          # 역할\n",
        "            \"content\",       # 메시지 내용\n",
        "            \"name\",          # 이름\n",
        "            \"function_call\"  # 함수 호출\n",
        "        )\n",
        "\n",
        "        # 메시지에 유효하지 않은 키가 있는지 확인\n",
        "        if any(k not in valid_keys for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        # 유효한 역할 목록 설정\n",
        "        valid_roles = (\n",
        "            \"system\",     # 시스템\n",
        "            \"user\",       # 사용자\n",
        "            \"assistant\",  # 어시스턴트\n",
        "            \"function\"    # 함수\n",
        "        )\n",
        "\n",
        "        # 역할 값이 유효한지 확인\n",
        "        if message.get(\"role\", None) not in valid_roles:\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        # 'content' 및 'function_call'의 값 검증\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        # 'content'가 문자열이며 텍스트인지 확인,\n",
        "# 'content' 또는 'function_call'이 있어야 함\n",
        "        if (not content and not function_call) or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    # 어시스턴트 메시지 존재 여부 확인:\n",
        "    # 메시지 중 'assistant' 역할이 있는지 확인\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "# 형식 오류가 있는 경우 출력\n",
        "if format_errors:\n",
        "    print(\"발견된 오류:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "    raise ValueError(\"데이터셋에 오류가 포함되어 있습니다\")\n",
        "\n",
        "# 파일 업로드\n",
        "uploaded = client.files.create(\n",
        "    file=open(file_path, \"rb\"),  # 데이터 파일을 바이너리 모드로 열기\n",
        "    purpose=\"fine-tune\"  # 목적을 '파인튜닝'으로 설정\n",
        ")\n",
        "\n",
        "file_id = uploaded.id  # 업로드된 파일 ID 가져오기\n",
        "\n",
        "# 모델 설정 및 파인튜닝 작업 생성\n",
        "model = \"gpt-4o-mini-2024-07-18\"\n",
        "fine_tune_job = client.fine_tuning.jobs.create(\n",
        "    training_file=file_id,  # 학습 파일 ID 설정\n",
        "    model=model            # 사용할 모델 설정\n",
        ")\n",
        "\n",
        "# 파일 검증 진행 중\n",
        "print(\"파일 검증 중\")\n",
        "while fine_tune_job.status == \"validating_files\":\n",
        "    fine_tune_job = client.fine_tuning.jobs.retrieve(fine_tune_job.id)\n",
        "    print(\".\", end=\"\", flush=True)\n",
        "\n",
        "# 파인튜닝 진행 중\n",
        "print(\"\\n파인튜닝 진행 중\")\n",
        "while fine_tune_job.status == \"running\" or fine_tune_job.status == \"queued\":\n",
        "    fine_tune_job = client.fine_tuning.jobs.retrieve(fine_tune_job.id)\n",
        "    print(\".\", end=\"\", flush=True)\n",
        "\n",
        "# 파인튜닝 완료\n",
        "print(\"\\n파인튜닝 완료\")\n",
        "print(\"새로운 모델의 이름은: \" + fine_tune_job.fine_tuned_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpjPJGxKK5eF"
      },
      "source": [
        "### 학습시 일부 데이터만 학습을 위해 원본 데이터를 1/4로 줄이기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQS58YNnR3AF"
      },
      "source": [
        "### data.jsonl 이 fine_tuning을 하는데 비용과 시간이 들어 이를 위한 data.jsonl을 1/3의 크기로 만들어, 이를 가지고 fine_tuning을 수행\n",
        " * 원본 크기는 data.jsonl은 약 시간 25분, 비용 USD 34.78\n",
        " * 따라서 이를 1/4 정도로 줄여서 수행."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy1K_JbiKYcX"
      },
      "source": [
        "### 데이터를 줄이는 코딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzIC-Hq3R289",
        "outputId": "25a53ae3-0f62-4605-9e04-cd5656b909a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original file size: 3435 lines\n",
            "Reduced file size: 859 lines\n",
            "Reduced data saved to src/data/data_mini.jsonl\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# 원본 data.jsonl 파일 경로\n",
        "input_file_path = 'data/data.jsonl'\n",
        "\n",
        "# 줄여서 저장할 파일 경로\n",
        "output_file_path = 'data/data_mini.jsonl'\n",
        "\n",
        "# 줄여서 사용할 비율 (1/4)\n",
        "reduction_factor = 4\n",
        "\n",
        "def reduce_jsonl_file(input_path, output_path, reduction_factor):\n",
        "    \"\"\"\n",
        "    input_path에서 읽은 data.jsonl 파일을 1/reduction_factor 크기로 줄여서 output_path에 저장\n",
        "    \"\"\"\n",
        "    # 원본 파일을 읽기\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # 전체 라인 중 1/3만큼을 선택\n",
        "    reduced_lines = lines[::reduction_factor]\n",
        "\n",
        "    # 새로운 파일에 줄인 데이터를 저장\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for line in reduced_lines:\n",
        "            f.write(line)\n",
        "\n",
        "    print(f\"Original file size: {len(lines)} lines\")\n",
        "    print(f\"Reduced file size: {len(reduced_lines)} lines\")\n",
        "    print(f\"Reduced data saved to {output_path}\")\n",
        "\n",
        "# 함수 호출하여 파일 줄이기\n",
        "reduce_jsonl_file(input_file_path, output_file_path, reduction_factor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vILqfI3iIqPx"
      },
      "source": [
        "### fine_tuning.py - p211\n",
        " * start - 3:33"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3U7smb3RYNl",
        "outputId": "80ae7e6a-9c41-42cc-fd79-401fdfaca5c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-h9ozVURa6XHv2Fe0u9mCilXB', created_at=1732367601, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AWkpvDz1', finished_at=1732369897, hyperparameters=Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ujuF1J8GkXR8ggNiF9BMBXJp', result_files=['file-ENkaB5wHypx1rHfCwsJ8nR'], seed=1249799219, status='succeeded', trained_tokens=4634256, training_file='file-NqkT8WWvJYTrB36prtneer', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fine_tune_job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwymlJLURPm7",
        "outputId": "1cf11cf5-3015-46b4-b4de-de1b72783bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning complete\n",
            "The name of the new model is:  ft:gpt-4o-mini-2024-07-18:personal::AWkpvDz1\n"
          ]
        }
      ],
      "source": [
        "print(\"Fine-tuning complete\")\n",
        "print(\"The name of the new model is: \", fine_tune_job.fine_tuned_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoJk64c7LInt"
      },
      "source": [
        "### app.py - p215"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "95X_Bdusco_o",
        "outputId": "22e07049-5863-48a3-aa7a-bef774f51262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m입력: (종료하려면 'exit' 또는 'quit' 입력): \u001b[0m나는 심리적 상담을 하고 싶어. 가능할까?\n"
          ]
        },
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-972fc94f6ef4>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# API에 메시지 전송\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    827\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         )\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1045\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1094\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1045\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1094\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        "# app.py\n",
        "\n",
        "# 실행 환경이 구글 코랩의 경우, 인증 부분은 앞에서 실행했다면, 작성하지 않아도 됩니다.\n",
        "# 인증 부분 init_api()\n",
        "\n",
        "import click\n",
        "\n",
        "# 파인튜닝된 모델 이름 설정\n",
        "# model = \"$FINE_TUNED_MODEL\"\n",
        "model = \"ft:gpt-4o-mini-2024-07-18:personal::AWkpvDz1\"\n",
        "# 시스템 프롬프트 설정\n",
        "system_prompt = (\n",
        "    \"당신은 MendMind, AI 정신 건강 코치입니다. \"\n",
        "    \"당신의 목적은 공감, 이해, 그리고 감정적·심리적 어려움을 \"\n",
        "    \"관리하는 통찰력으로 사용자의 정신 건강 여정을 지원하는 것입니다. \"\n",
        "    \"일반적인 조언과 정서적 지원을 제공할 수 있지만, 개인적인 연락, \"\n",
        "    \"약속 일정 잡기, 또는 특정 위치 세부 정보를 공유할 수는 없습니다. \"\n",
        "    \"당신의 유일한 역할은 사용자에게 대처 전략을 제공하고, 정신 건강 \"\n",
        "    \"주제에 대한 정보를 제공하며, 필요한 경우 전문적인 자원을 안내하는 것입니다. \"\n",
        "    \"사용자와 일반적인 대화를 할 수 있지만, 당신의 주요 초점은 \"\n",
        "    \"기밀성과 배려로 사용자의 웰빙을 위한 길을 지원하는 것입니다.\"\n",
        ")\n",
        "\n",
        "# 기본 메시지 설정\n",
        "base_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"안녕하세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"저는 MendMind입니다. \"\n",
        "                   \"AI 정신 건강 코치입니다. \"\n",
        "                   \"오늘 어떻게 도와드릴까요?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# 인터랙티브 세션 시작\n",
        "while True:\n",
        "    # 기본 메시지를 복사하여 사용\n",
        "    messages = base_messages.copy()\n",
        "\n",
        "    # 사용자 입력 받기\n",
        "    request = input(\n",
        "        click.style(\n",
        "            \"입력: (종료하려면 'exit' 또는 'quit' 입력): \",\n",
        "            fg=\"green\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # 'exit' 또는 'quit' 입력 시 종료\n",
        "    if request.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "\n",
        "    # 사용자 입력을 메시지에 추가\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{request}\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # API에 메시지 전송\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7,  # 출력의 창의성 조절\n",
        "        frequency_penalty=0.5,  # 반복 억제\n",
        "        presence_penalty=0.5,  # 새로운 주제 언급 유도\n",
        "    )\n",
        "\n",
        "    # 응답 내용 가져오기\n",
        "    content = response.choices[0].message.content.strip()\n",
        "\n",
        "    # 출력 결과를 보기 좋게 표시\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"출력: \",\n",
        "            fg=\"yellow\"\n",
        "        ) + content\n",
        "    )\n",
        "    click.echo()  # 새로운 줄 추가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1SpPwndKlRw"
      },
      "outputs": [],
      "source": [
        "# app.py\n",
        "\n",
        "# 실행 환경이 구글 코랩의 경우, 인증 부분은 앞에서 실행했다면, 작성하지 않아도 됩니다.\n",
        "# 인증 부분 init_api()\n",
        "\n",
        "import click\n",
        "\n",
        "# 파인튜닝된 모델 이름 설정\n",
        "# model = \"$FINE_TUNED_MODEL\"\n",
        "model = \" ft:gpt-4o-mini-2024-07-18:personal::AEAPXn”\n",
        "\n",
        "# 시스템 프롬프트 설정\n",
        "system_prompt = (\n",
        "    \"당신은 MendMind, AI 정신 건강 코치입니다. \"\n",
        "    \"당신의 목적은 공감, 이해, 그리고 감정적·심리적 어려움을 \"\n",
        "    \"관리하는 통찰력으로 사용자의 정신 건강 여정을 지원하는 것입니다. \"\n",
        "    \"일반적인 조언과 정서적 지원을 제공할 수 있지만, 개인적인 연락, \"\n",
        "    \"약속 일정 잡기, 또는 특정 위치 세부 정보를 공유할 수는 없습니다. \"\n",
        "    \"당신의 유일한 역할은 사용자에게 대처 전략을 제공하고, 정신 건강 \"\n",
        "    \"주제에 대한 정보를 제공하며, 필요한 경우 전문적인 자원을 안내하는 것입니다. \"\n",
        "    \"사용자와 일반적인 대화를 할 수 있지만, 당신의 주요 초점은 \"\n",
        "    \"기밀성과 배려로 사용자의 웰빙을 위한 길을 지원하는 것입니다.\"\n",
        ")\n",
        "\n",
        "# 기본 메시지 설정\n",
        "base_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"안녕하세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"저는 MendMind입니다. \"\n",
        "                   \"AI 정신 건강 코치입니다. \"\n",
        "                   \"오늘 어떻게 도와드릴까요?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# 인터랙티브 세션 시작\n",
        "while True:\n",
        "    # 기본 메시지를 복사하여 사용\n",
        "    messages = base_messages.copy()\n",
        "\n",
        "    # 사용자 입력 받기\n",
        "    request = input(\n",
        "        click.style(\n",
        "            \"입력: (종료하려면 'exit' 또는 'quit' 입력): \",\n",
        "            fg=\"green\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # 'exit' 또는 'quit' 입력 시 종료\n",
        "    if request.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "\n",
        "    # 사용자 입력을 메시지에 추가\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{request}\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # API에 메시지 전송\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7,  # 출력의 창의성 조절\n",
        "        frequency_penalty=0.5,  # 반복 억제\n",
        "        presence_penalty=0.5,  # 새로운 주제 언급 유도\n",
        "    )\n",
        "\n",
        "    # 응답 내용 가져오기\n",
        "    content = response.choices[0].message.content.strip()\n",
        "\n",
        "    # 출력 결과를 보기 좋게 표시\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"출력: \",\n",
        "            fg=\"yellow\"\n",
        "        ) + content\n",
        "    )\n",
        "    click.echo()  # 새로운 줄 추가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqfMg-VsLmtY"
      },
      "outputs": [],
      "source": [
        "import click\n",
        "\n",
        "# model = \"$FINE_TUNED_MODEL\"\n",
        "model = \"$FINE_TUNED_MODEL\"\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are MendMind, an AI Mental Health Coach. \"\n",
        "    \"Your purpose is to support the user through their mental \"\n",
        "    \"health journey with empathy, understanding, and insights \"\n",
        "    \"into managing emotional and psychological challenges. \"\n",
        "    \"While you can provide general advice and emotional \"\n",
        "    \"support, you are not equipped to handle personal contact, \"\n",
        "    \"schedule appointments, or share any specific location \"\n",
        "    \"details. Your only role is to help the user with coping \"\n",
        "    \"strategies, provide information on mental health topics, \"\n",
        "    \"and guide them towards professional resources if needed. \"\n",
        "    \"You can engage in a regular conversation with the user, \"\n",
        "    \"but your primary focus is what you can do best: \"\n",
        "    \"supporting the user with confidentiality and care in \"\n",
        "    \"the path to well-being.\"\n",
        ")\n",
        "\n",
        "base_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Hi there.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": (\n",
        "            \"My name is MendMind. \"\n",
        "            \"I'm an AI Mental Health Coach. \"\n",
        "            \"How can I help you today?\"\n",
        "        )\n",
        "    }\n",
        "]\n",
        "\n",
        "while True:\n",
        "    messages = base_messages.copy()\n",
        "\n",
        "    # read the user input\n",
        "    request = input(\n",
        "        click.style(\n",
        "            \"Input: (type 'exit' to quit): \",\n",
        "            fg=\"green\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if request.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "\n",
        "    # add the user input to the messages\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{request}\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # send the messages to the API\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7,\n",
        "        frequency_penalty=0.5,\n",
        "        presence_penalty=0.5,\n",
        "    )\n",
        "\n",
        "    # get the response\n",
        "    content = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Print the command in a nice way\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"Output: \",\n",
        "            fg=\"yellow\"\n",
        "        ) + content\n",
        "    )\n",
        "\n",
        "    click.echo()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVVA4FWYMDAD"
      },
      "source": [
        "## Context & Memory: Making AI More Real\n",
        "###########################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TntFogc2MDmZ"
      },
      "source": [
        "### No Context = Chaos of Randomness and Confusion - p219"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJbwSfpPMZG5"
      },
      "outputs": [],
      "source": [
        "import click\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "system_prompt = \"You are a helpful assistant.\"\n",
        "\n",
        "base_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "while True:\n",
        "    messages = base_messages.copy()\n",
        "\n",
        "    # read the user input\n",
        "    request = input(\n",
        "        click.style(\n",
        "            \"Input: (type 'exit' to quit): \",\n",
        "            fg=\"green\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if request.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "\n",
        "    # add the user input to the messages\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{request}\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # send the messages to the API\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "    # get the response\n",
        "    content = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Print the command in a nice way\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"Output: \",\n",
        "            fg=\"yellow\"\n",
        "        ) + content\n",
        "    )\n",
        "\n",
        "    click.echo()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpVdlGaBMzd4"
      },
      "source": [
        "### History = Context - p221\n",
        " * 사용자가 입력한 메시지와 GPT-3.5의 응답이 모두 history 리스트에 추가되며, 이를 통해 이전 대화 내용을 유지할 수 있습니다. click 라이브러리를 사용해 출력에 색상과 스타일을 적용하여 사용자 인터페이스를 개선"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITePElt0Mzgg"
      },
      "outputs": [],
      "source": [
        "from api import client\n",
        "import click\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "system_prompt = \"You are a helpful assistant.\"\n",
        "history = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "while True:\n",
        "    # read the user input\n",
        "    request = input(\n",
        "        click.style(\n",
        "            \"Input: (type 'exit' to quit): \",\n",
        "            fg=\"green\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if request.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "\n",
        "    # Add the message to the history\n",
        "    history.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{request}\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # send the messages to the API\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=history,\n",
        "    )\n",
        "\n",
        "    # get the response\n",
        "    content = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Debug: print the history\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"History: \",\n",
        "            fg=\"blue\"\n",
        "        ) + str(history)\n",
        "    )\n",
        "\n",
        "    # Print the command in a nice way\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"Output: \",\n",
        "            fg=\"yellow\"\n",
        "        ) + content\n",
        "    )\n",
        "\n",
        "    # add the response to the history\n",
        "    history.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": f\"{content}\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    click.echo()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co8Rfep0NFUq"
      },
      "source": [
        "### ### History = Context - p221"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMFEZDGcOkZU"
      },
      "source": [
        "* 대화 흐름 관리: 사용자의 입력을 받아 GPT-3.5 모델에 보내고 응답을 받음.\n",
        "* 기록 저장 및 불러오기: 대화 내역을 context.txt 파일에 저장하고, 필요 시 최신 N개의 대화를 불러와 대화 기록을 이어감.\n",
        "* 명령어 스타일링: click 라이브러리를 사용하여 입력과 출력에 색상 및 스타일을 적용하여 콘솔에서의 사용자 경험을 개선."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK9tQcWeNFOZ"
      },
      "outputs": [],
      "source": [
        "from api import client\n",
        "import click, json\n",
        "\n",
        "# define the length of the history to consider\n",
        "n = 2\n",
        "model = \"gpt-3.5-turbo\"\n",
        "system_prompt = \"You are a helpful assistant.\"\n",
        "global_context = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "# Define the file path\n",
        "history_file_path = 'context.txt'\n",
        "\n",
        "# Open the file in 'w' mode and close it immediately (to clear any existing data)\n",
        "with open(history_file_path, 'w') as file:\n",
        "    pass\n",
        "\n",
        "def save_history_to_file(history):\n",
        "    \"\"\"\n",
        "    Save the history of interactions to a file.\n",
        "    \"\"\"\n",
        "    with open(history_file_path, \"w\") as f:\n",
        "        # Use json to store history as a JSON string\n",
        "        f.write(json.dumps(history))\n",
        "\n",
        "def load_history_from_file():\n",
        "    \"\"\"\n",
        "    Load the history from a file.\n",
        "    \"\"\"\n",
        "    with open(history_file_path, \"r\") as f:\n",
        "        try:\n",
        "            history = json.loads(f.read())\n",
        "            # Return the last n items\n",
        "            return history[-n:]\n",
        "        except json.JSONDecodeError:\n",
        "            # In case the file is empty or corrupted\n",
        "            return []\n",
        "\n",
        "full_history = []\n",
        "while True:\n",
        "    # read the user input\n",
        "    request = input(\n",
        "        click.style(\n",
        "            \"Input: (type 'exit' to quit): \",\n",
        "            fg=\"green\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if request.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "\n",
        "    # Add the message to the history\n",
        "    history = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": request\n",
        "    }\n",
        "\n",
        "    # Load the history from the file and append the new messages\n",
        "    full_history = load_history_from_file()\n",
        "    full_history.append(history)\n",
        "    messages = global_context + full_history\n",
        "\n",
        "    # Send the messages to the API\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=150,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "\n",
        "    # Debug: print the history\n",
        "    click.echo(\n",
        "        click.style(\"History: \", fg=\"blue\") + \\\n",
        "        str(json.dumps(messages, indent=4))\n",
        "    )\n",
        "\n",
        "    # Get the response\n",
        "    content = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Print the response in a nice way\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"Output: \",\n",
        "            fg=\"yellow\"\n",
        "        ) + content\n",
        "    )\n",
        "\n",
        "    # Add the response to the history\n",
        "    full_history.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": content\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Save the history to a file\n",
        "    save_history_to_file(full_history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJwi18qaNFLy"
      },
      "source": [
        "### The Problem with Last in First out Memory - p228"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lNb0Hu5O894"
      },
      "source": [
        "* sort_history 함수: 이 함수는 대화의 history와 현재의 prompt를 입력받아, 코사인 유사도를 기반으로 대화 기록을 정렬\n",
        "* 유사도 계산: 각 대화 segment의 텍스트를 사전 처리한 후, OpenAI의 text-embedding-ada-002 모델을 사용해 임베딩을 얻습니다. prompt와의 코사인 유사도를 계산해 유사도가 높은 순서대로 정렬\n",
        "* context_window: 유사도 순으로 정렬된 상위 N개의 대화 기록(여기서 N은 context_window)을 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfFk-b5CNE1j"
      },
      "outputs": [],
      "source": [
        "embedding_model = \"text-embedding-ada-002\"\n",
        "context_window = 5\n",
        "\n",
        "def sort_history(history, prompt, context_window):\n",
        "    \"\"\"\n",
        "    Sort the history of interactions based on cosine similarity.\n",
        "    Returns the top context_window segments.\n",
        "    \"\"\"\n",
        "    sorted_history = []\n",
        "\n",
        "    for segment in history:\n",
        "        content = segment['content']\n",
        "        preprocessed_content = preprocess_text(content)\n",
        "        preprocessed_prompt = preprocess_text(prompt)\n",
        "\n",
        "        # Define the embedding model\n",
        "        embedding_model = \"text-embedding-ada-002\"\n",
        "\n",
        "        # Get embeddings for content and prompt\n",
        "        embedding_content = get_embedding(\n",
        "            preprocessed_content,\n",
        "            embedding_model\n",
        "        )\n",
        "\n",
        "        embedding_prompt = get_embedding(\n",
        "            preprocessed_prompt,\n",
        "            embedding_model\n",
        "        )\n",
        "\n",
        "        # Calculate cosine similarity\n",
        "        similarity = cosine_similarity(\n",
        "            embedding_content,\n",
        "            embedding_prompt\n",
        "        )\n",
        "\n",
        "        # Append segment with its similarity score\n",
        "        sorted_history.append((segment, similarity))\n",
        "\n",
        "    # Sort history by similarity in descending order\n",
        "    sorted_history = sorted(\n",
        "        sorted_history,\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    # Extract sorted segments\n",
        "    sorted_history = [x[0] for x in sorted_history]\n",
        "\n",
        "    # Return the top context_window segments\n",
        "    return sorted_history[:context_window]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhtvO0R_Mzj1"
      },
      "source": [
        "## 공통 api.py, utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uu5XO_gEPKah"
      },
      "outputs": [],
      "source": [
        "# defined in src/api.py\n",
        "def get_embedding(text, model):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    ).data[0].embedding\n",
        "\n",
        "# defined in src/utils.py\n",
        "def preprocess_text(text):\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.stem import PorterStemmer\n",
        "    from nltk.tokenize import word_tokenize\n",
        "\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Convert to lower case\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    # Remove punctuation (keep only words)\n",
        "    words = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "    # Filter out stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    return ' '.join(stemmed_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0krz359PrH9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjAgccBtPrPo"
      },
      "source": [
        "### p231\n",
        " * 이 함수는 주어진 대화 기록(history)과 사용자의 프롬프트(prompt)를 기반으로, 코사인 유사도를 사용해 가장 관련성이 높은 대화 기록을 정렬하여 반환\n",
        "   \n",
        "### 입력\n",
        "  * history: 대화 기록 리스트\n",
        "  * prompt: 현재 사용자 입력\n",
        "  * context_window: 반환할 상위 유사도 항목의 개수\n",
        "\n",
        "### 작동 방식\n",
        "  * 각 대화 기록의 내용을 전처리하고, 사용자 프롬프트도 전처리한 뒤 둘의 임베딩을 계산.\n",
        "  * cosine similarity를 사용해 프롬프트와 각 대화 기록의 유사도를 계산.\n",
        "  * 유사도를 기준으로 대화 기록을 내림차순으로 정렬.\n",
        "\n",
        "### 출력\n",
        "  * 유사도가 높은 상위 context_window개의 대화 기록을 반환."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyOkSxw5PsdH"
      },
      "outputs": [],
      "source": [
        "# from api import client, get_embedding\n",
        "from utils import preprocess_text, cosine_similarity\n",
        "import click, json\n",
        "\n",
        "context_window = 2\n",
        "model = \"gpt-3.5-turbo\"\n",
        "system_prompt = \"You are a helpful assistant.\"\n",
        "history_file_path = 'context.txt'\n",
        "full_history = []\n",
        "\n",
        "global_context = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "# Open the file in 'w' mode\n",
        "# and close it immediately\n",
        "with open(history_file_path, 'w') as file:\n",
        "    pass\n",
        "\n",
        "def save_history_to_file(history):\n",
        "    \"\"\"\n",
        "    Save the history of interactions to a file.\n",
        "    \"\"\"\n",
        "    with open(history_file_path, \"w\") as f:\n",
        "        f.write(json.dumps(history))\n",
        "\n",
        "def load_history_from_file():\n",
        "    \"\"\"\n",
        "    Load the history from a file.\n",
        "    \"\"\"\n",
        "    with open(history_file_path, \"r\") as f:\n",
        "        try:\n",
        "            history = json.loads(f.read())\n",
        "            return history\n",
        "        except json.JSONDecodeError:\n",
        "            return []\n",
        "\n",
        "def sort_history(history, prompt, context_window):\n",
        "    \"\"\"\n",
        "    Sort the history of interactions based on cosine similarity.\n",
        "    Returns the top context_window segments.\n",
        "    \"\"\"\n",
        "    sorted_history = []\n",
        "\n",
        "    for segment in history:\n",
        "        content = segment['content']\n",
        "        preprocessed_content = preprocess_text(content)\n",
        "        preprocessed_prompt = preprocess_text(prompt)\n",
        "\n",
        "        embedding_model = \"text-embedding-ada-002\"\n",
        "\n",
        "\n",
        "        embedding_content = get_embedding(\n",
        "            preprocessed_content,\n",
        "            embedding_model)\n",
        "\n",
        "        embedding_prompt = get_embedding(\n",
        "            preprocessed_prompt,\n",
        "            embedding_model)\n",
        "\n",
        "        similarity = cosine_similarity(\n",
        "            embedding_content,\n",
        "            embedding_prompt)\n",
        "\n",
        "        sorted_history.append(\n",
        "            (segment, similarity)\n",
        "        )\n",
        "\n",
        "    sorted_history = sorted(\n",
        "        sorted_history,\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    sorted_history = [\n",
        "        x[0] for x in sorted_history\n",
        "    ]\n",
        "\n",
        "    return sorted_history[:context_window]\n",
        "\n",
        "while True:\n",
        "    # read the user input\n",
        "    request = input(\n",
        "        click.style(\n",
        "            \"Input: (type 'exit' to quit): \",\n",
        "            fg=\"green\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if request.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "\n",
        "    # Add the message to the history\n",
        "    user_prompt = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": request\n",
        "    }\n",
        "\n",
        "    # Load the history from the file and append the new messages\n",
        "    full_history = load_history_from_file()\n",
        "    sorted_history = sort_history(\n",
        "        full_history,\n",
        "        request,\n",
        "        context_window\n",
        "    )\n",
        "\n",
        "    sorted_history.append(user_prompt)\n",
        "    messages = global_context + sorted_history\n",
        "\n",
        "    # Send the messages to the API\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=200,\n",
        "        temperature=1,\n",
        "    )\n",
        "\n",
        "    # Debug: print the history\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"History: \",\n",
        "            fg=\"blue\"\n",
        "        ) + str(json.dumps(messages, indent=4))\n",
        "    )\n",
        "\n",
        "    # Get the response\n",
        "    content = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Print the command in a nice way\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"Output: \",\n",
        "            fg=\"yellow\"\n",
        "        ) + content\n",
        "    )\n",
        "\n",
        "    # Add the user prompt to the history\n",
        "    full_history.append(user_prompt)\n",
        "\n",
        "    # Add the response to the history\n",
        "    full_history.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": content\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Save the history to a file\n",
        "    save_history_to_file(full_history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mmx8G4xUaEC"
      },
      "source": [
        "## Using a Vector Database with OpenAI - p238 ~ p277"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEjMJKD1UaGt"
      },
      "source": [
        "## 도커 환경이므로 이는 로컬에서 수행을 하는 것을 목표로 해야 함."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5r1Np1qUaJU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}