# Fine-Tuning and Best Practices


## Few-Shot Learning


## Enhancing Few-Shot Learning


## Practical Application of Fine-Tuning


```bash
workon openaigptforpythondevelopers
export OPENAI_API_KEY="<OPENAI_API_KEY>"
```


```json
cat << EOF > src/data.jsonl
{"messages": [{"role": "system", "content": "You are a smart home assistant"}, {"role": "user", "content": "When do I have to start the heater?"}, {"role": "assistant", "content": "Every day in the morning at 7AM. You should stop it at 2PM"}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "Where is the garage remote control?"}, {"role": "assistant", "content": "Next to the yellow door, on the key ring"}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "Is it necessary to program the scent diffuser every day?"}, {"role": "assistant", "content": "The scent diffuser is already programmed, you just need to recharge it when its battery is low"}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "How do I reset the WiFi router?"}, {"role": "assistant", "content": "Unplug the router, wait for 30 seconds, then plug it back in."}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "How do I connect my phone to the smart TV?"}, {"role": "assistant", "content": "Go to settings on your phone, select 'Screen Mirroring', and choose the smart TV from the list."}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "What's the Wi-Fi password?"}, {"role": "assistant", "content": "The Wi-Fi password is 'HomeNetwork123'."}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "How to hard-reset the smart TV?"}, {"role": "assistant", "content": "Press and hold the power button on the remote for 10 seconds."}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "How to call the police?"}, {"role": "assistant", "content": "Dial 911 on your phone."}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "How to change the wifi password?"}, {"role": "assistant", "content": "Go to the router settings, select 'Wireless', and change the password."}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "How to change the channel on the TV?"}, {"role": "assistant", "content": "Press the 'Channel Up' or 'Channel Down' button on the remote."}]}
EOF
```


```python
from api import client
import os, sys

# define the path to the file
file_path = os.path.join(
  os.path.dirname(__file__), 
  'data.jsonl'
)

# upload the file
uploaded = client.files.create(
  file=open(
    file_path,
    "rb"
  ),
  purpose="fine-tune"
)
file_id = uploaded.id
```


```python
model = "gpt-3.5-turbo"
fine_tune_job = client.fine_tuning.jobs.create(
  training_file=file_id,
  model=model,
)

print("Validating files in progress")
while fine_tune_job.status == "validating_files":
  fine_tune_job = client.fine_tuning.jobs.retrieve(
    fine_tune_job.id
  )
  sys.stdout.write("...")
  sys.stdout.flush()  

print("Fine-tuning in progress") 
while fine_tune_job.status == "running" \
  or fine_tune_job.status == "queued":
  fine_tune_job = client.fine_tuning.jobs.retrieve(
    fine_tune_job.id
  )
  sys.stdout.write("...")
  sys.stdout.flush()

print("Fine-tuning complete")
print("The name of the new model is: " \
  + fine_tune_job.fine_tuned_model)
```


```python
cat << EOF > src/fine_tuning.py
from api import client
import os, sys

# define the path to the file
file_path = os.path.join(
  os.path.dirname(__file__), 
  'data.jsonl'
)

# upload the file
uploaded = client.files.create(
  file=open(
    file_path,
    "rb"
  ),
  purpose="fine-tune"
)
file_id = uploaded.id

model = "gpt-3.5-turbo"
fine_tune_job = client.fine_tuning.jobs.create(
  training_file=file_id,
  model=model,
)

print("Validating files in progress")
while fine_tune_job.status == "validating_files":
  fine_tune_job = client.fine_tuning.jobs.retrieve(
    fine_tune_job.id
  )
  sys.stdout.write("...")
  sys.stdout.flush()  
  

print("Fine-tuning in progress") 
while fine_tune_job.status == "running" or \
  fine_tune_job.status == "queued":
  fine_tune_job = client.fine_tuning.jobs.retrieve(
    fine_tune_job.id
  )
  sys.stdout.write("...")
  sys.stdout.flush()

print("Fine-tuning complete")
print("The name of the new model is: " + \
  fine_tune_job.fine_tuned_model)
EOF
```


```bash
python src/fine_tuning.py
```


```bash
export FINE_TUNED_MODEL="<FINE_TUNED_MODEL>"
```


```python
cat << EOF > src/app.py
from api import client
import click

model = "$FINE_TUNED_MODEL"
base_messages = [
    {
        "role": "system",
        "content": 
          "You are a smart home assistant."
    }
]

while True:
    messages = base_messages.copy()

    # read the user input
    request = input(
      click.style(
        "Input: (type 'exit' to quit): ", 
        fg="green"
      )
    )
    
    if request.lower() in ["exit", "quit"]:
        break    

    # add the user input to the messages
    messages.append(
        {
            "role": "user",
            "content": f"{request}"
        }
    )

    # send the messages to the API
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=200,
        temperature=0,        
    )
    
    # get the response
    content = response.choices[0].message.content.strip()    

    # Print the command in a nice way
    click.echo(
      click.style("Output: ", fg="yellow") + content
      )

    click.echo()
EOF
```


## Fine-Tuning Best Practices


### Choosing the Model


### Validating the Dataset


```json
{"prompt":"When do I have to start the heater?", "completion":"Every day in the morning at 7AM. You should stop it at 2PM"}
{"prompt":"Where is the garage remote control?", "completion":"Next to the yellow door, on the key ring"}
{"prompt":"Is it necessary to program the scent diffuser every day?", "completion":"The scent diffuser is already programmed, you just need to recharge it when its battery is low"}
```


```json
{"messages": [{"role": "system", "content": "You are a smart home assistant"}, {"role": "user", "content": "When do I have to start the heater?"}, {"role": "assistant", "content": "Every day in the morning at 7AM. You should stop it at 2PM"}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "Where is the garage remote control?"}, {"role": "assistant", "content": "Next to the yellow door, on the key ring"}]}
{"messages": [{"role": "system", "content": "You are a smart home assistant."}, {"role": "user", "content": "Is it necessary to program the scent diffuser every day?"}, {"role": "assistant", "content": "The scent diffuser is already programmed, you just need to recharge it when its battery is low"}]}
```


```bash
# This will create a new file ("data_prepared.jsonl")
openai tools fine_tunes.prepare_data -f data.json 
# Create the fine-tuning job
openai api fine_tunes.create -t "data_prepared.jsonl" -m curie
```


```python
import json
from collections import defaultdict
import os
```


```python
file_path = os.path.join(
  os.path.dirname(__file__), 
  'data.jsonl'
)
```


```python
# validate the dataset file format
with open(file_path, 'r', encoding='utf-8') as f:
  try
    dataset = [json.loads(line) for line in f]
  except:
    raise ValueError(
      "The dataset must be a valid JSONL file"
    )
```


```python
# validate the dataset size
size = len(dataset)
if size < 10:
    raise ValueError(
      "The dataset must contain at least 10 examples"
    )
```


```json
{
  "messages": 
    [
      {
        "role": "system", 
        "content": 
          "You are a smart home assistant."
      }, {
        "role": "user", 
        "content": 
          "Is it necessary to program the "
          "scent diffuser every day?"
      }, {
        "role": "assistant", 
        "content": 
          "The scent diffuser is already "
          "programmed, you just need to "
          "recharge it when its battery is low"
      }
    ]
  }
```


```python
# validate the dataset content
format_errors = defaultdict(int)

for line in dataset:
    # Data Type Check: 
    # Verify if each entry is a dictionary
    if not isinstance(line, dict):
        format_errors["data_type"] += 1
        continue
    
    # Presence of Message List: 
    # Check if there is a 'messages' list
    messages = line.get("messages", None)
    if not messages:
        format_errors["missing_messages_list"] += 1
        continue

    for message in messages:
        # Message Keys Check: 
        # Ensure each message has 'role' and 'content' keys
        if "role" not in message or "content" not in message:
            format_errors["message_missing_key"] += 1

        # Valid keys that a message can contain
        valid_keys = (
            "role", 
            "content", 
            "name", 
            "function_call"
        )

        # Unrecognized Keys in Messages: 
        # Check for any keys not in valid_keys
        if any(k not in valid_keys for k in message):
            format_errors["message_unrecognized_key"] += 1

        # Valid roles that a message can have
        valid_roles = (
            "system", 
            "user", 
            "assistant", 
            "function"
        )

        # Role Validation: 
        # Check if 'role' is one of the valid_roles
        if message.get(
          "role", 
          None
        ) not in valid_roles:
            format_errors["unrecognized_role"] += 1

        content = message.get(
          "content", 
          None
        )
        function_call = message.get(
          "function_call", 
          None
        )

        # Content Validation: 
        # Check if 'content' is textual and a string
        # Also, check if 'content' or 'function_call' is present
        if (not content and not function_call) or \
          not isinstance(content, str):
            format_errors["missing_content"] += 1

    # Assistant Message Presence: 
    # Check if there is at least one assistant message
    if not any(
        message.get(
          "role", 
          None
        ) == "assistant"
        for message in messages
    ):
        format_errors["example_missing_assistant_message"] += 1

# Print the errors, if any
if format_errors:
    print("Found errors:")
    for k, v in format_errors.items():
        print(f"{k}: {v}")
    raise ValueError(
          "The dataset contains errors"
        )
```


```python
cat << EOF > src/data_analysis.py
import json
from collections import defaultdict
import os

file_path = os.path.join(
  os.path.dirname(__file__), 
  'data.jsonl'
)

# validate the dataset file format
with open(file_path, 'r', encoding='utf-8') as f:
  try:
    dataset = [json.loads(line) for line in f]
  except:
    raise ValueError(
      "The dataset must be a valid JSONL file"
    )    

# validate the dataset size
size = len(dataset)
if size < 10:
    raise ValueError(
      "The dataset must contain at least 10 examples"
    )

# validate the dataset content
format_errors = defaultdict(int)

for line in dataset:
    # Data Type Check: 
    # Verify if each entry is a dictionary
    if not isinstance(line, dict):
        format_errors["data_type"] += 1
        continue
    
    # Presence of Message List: 
    # Check if there is a 'messages' list
    messages = line.get("messages", None)
    if not messages:
        format_errors["missing_messages_list"] += 1
        continue

    for message in messages:
        # Message Keys Check: 
        # Ensure each message has 'role' and 'content' keys
        if "role" not in message or "content" not in message:
            format_errors["message_missing_key"] += 1

        # Valid keys that a message can contain
        valid_keys = (
            "role", 
            "content", 
            "name", 
            "function_call"
        )

        # Unrecognized Keys in Messages: 
        # Check for any keys not in valid_keys
        if any(k not in valid_keys for k in message):
            format_errors["message_unrecognized_key"] += 1

        # Valid roles that a message can have
        valid_roles = (
            "system", 
            "user", 
            "assistant", 
            "function"
        )

        # Role Validation: 
        # Check if 'role' is one of the valid_roles
        if message.get(
          "role", 
          None
        ) not in valid_roles:
            format_errors["unrecognized_role"] += 1

        content = message.get(
          "content", 
          None
        )
        function_call = message.get(
          "function_call", 
          None
        )

        # Content Validation: 
        # Check if 'content' is textual and a string
        # Also, check if 'content' or 'function_call' is present
        if (not content and not function_call) or \
          not isinstance(content, str):
            format_errors["missing_content"] += 1

    # Assistant Message Presence: 
    # Check if there is at least one assistant message
    if not any(
        message.get(
          "role", 
          None
        ) == "assistant"
        for message in messages
    ):
        format_errors["example_missing_assistant_message"] += 1

# Print the errors, if any
if format_errors:
    print("Found errors:")
    for k, v in format_errors.items():
        print(f"{k}: {v}")
    raise ValueError(
          "The dataset contains errors"
        )
EOF
```


```python
cat << EOF > src/fine_tuning.py
from api import client
import os, sys, json
from collections import defaultdict


file_path = os.path.join(
  os.path.dirname(__file__), 
  'data.jsonl'
)

# validate the dataset file format
with open(file_path, 'r', encoding='utf-8') as f:
  try:
    dataset = [json.loads(line) for line in f]
  except:
    raise ValueError(
      "The dataset must be a valid JSONL file"
    )    

# validate the dataset size
size = len(dataset)
if size < 10:
    raise ValueError(
      "The dataset must contain at least 10 examples"
    )

# validate the dataset content    
format_errors = defaultdict(int)

for line in dataset:
    # Data Type Check: 
    # Verify if each entry is a dictionary
    if not isinstance(line, dict):
        format_errors["data_type"] += 1
        continue
    
    # Presence of Message List: 
    # Check if there is a 'messages' list
    messages = line.get("messages", None)
    if not messages:
        format_errors["missing_messages_list"] += 1
        continue

    for message in messages:
        # Message Keys Check: 
        # Ensure each message has 'role' and 'content' keys
        if "role" not in message or "content" not in message:
            format_errors["message_missing_key"] += 1

        # Valid keys that a message can contain
        valid_keys = (
            "role", 
            "content", 
            "name", 
            "function_call"
        )

        # Unrecognized Keys in Messages: 
        # Check for any keys not in valid_keys
        if any(k not in valid_keys for k in message):
            format_errors["message_unrecognized_key"] += 1

        # Valid roles that a message can have
        valid_roles = (
            "system", 
            "user", 
            "assistant", 
            "function"
        )

        # Role Validation: 
        # Check if 'role' is one of the valid_roles
        if message.get(
          "role", 
          None
        ) not in valid_roles:
            format_errors["unrecognized_role"] += 1

        content = message.get(
          "content", 
          None
        )
        function_call = message.get(
          "function_call", 
          None
        )

        # Content Validation: 
        # Check if 'content' is textual and a string
        # Also, check if 'content' or 'function_call' 
        # is present
        if (not content and not function_call) or \
          not isinstance(content, str):
            format_errors["missing_content"] += 1

    # Assistant Message Presence: 
    # Check if there is at least one assistant message
    if not any(
        message.get(
          "role", 
          None
        ) == "assistant"
        for message in messages
    ):
        format_errors["example_missing_assistant_message"] += 1

# Print the errors, if any
if format_errors:
    print("Found errors:")
    for k, v in format_errors.items():
        print(f"{k}: {v}")
    raise ValueError(
          "The dataset contains errors"
        )        

# upload the file
uploaded = client.files.create(
  file=open(
    file_path,
    "rb"
  ),
  purpose="fine-tune"
)
file_id = uploaded.id

model = "gpt-3.5-turbo"
fine_tune_job = client.fine_tuning.jobs.create(
  training_file=file_id,
  model=model,
)

print("Validating files in progress")
while fine_tune_job.status == "validating_files":
  fine_tune_job = client.fine_tuning.jobs.retrieve(
    fine_tune_job.id
  )
  sys.stdout.write("...")
  sys.stdout.flush()  
  

print("Fine-tuning in progress") 
while fine_tune_job.status == "running" or \
  fine_tune_job.status == "queued":
  fine_tune_job = client.fine_tuning.jobs.retrieve(
    fine_tune_job.id
  )
  sys.stdout.write("...")
  sys.stdout.flush()

print("Fine-tuning complete")
print("The name of the new model is: " + \
  fine_tune_job.fine_tuned_model)
EOF
```


### Token Limit


### Dataset Size


### Testing and Improving Training (Hyperparameters)


### Epochs


```python
client.fine_tuning.jobs.create(
  training_file=file_id,
  model=model, 
  hyperparameters={
    "n_epochs": 10
  }
)
```


#### Learning Rate Multiplier


```python
client.fine_tuning.jobs.create(
  training_file=file_id,
  model=model, 
  hyperparameters={
    "learning_rate_multiplier": 1.5
  }
)
```


### Batch Size


```python
client.fine_tuning.jobs.create(
  training_file=file_id,
  model=model, 
  hyperparameters={
    "batch_size": 32
  }
)
```


### Consider Estimated Costs


### Dataset Quality


### Combining Fine-Tuning with Other Techniques


### Experiment and Learn


### Use a Validation Set


```python
# define the path to the file
validation_file_path = os.path.join(
  os.path.dirname(__file__), 
  'validation_data.jsonl'
)

# upload the validation file
validation_uploaded = client.files.create(
  file=open(
    validation_file_path,
    "rb"
  ),
  purpose="fine-tune"
)

# get the validation file ID
validation_file_id = validation_uploaded.id

# create the fine-tuning job
client.fine_tuning.jobs.create(
  training_file=
  model=model, 
  validation_file=validation_file_id
)
```


### Test the Model


### Analyze the Results


```bash
export JOB_ID="<JOB_ID>"
```


```python
cat << EOF > src/analytics.py
from api import client

# Get the fine-tuning job
job_id = "$JOB_ID"

fine_tune_job = \
  client.fine_tuning.jobs.retrieve(job_id)

status = fine_tune_job.status
if status == "succeeded":

  # print the n_epochs
  print(f"Number of epochs: \
  {fine_tune_job.hyperparameters.n_epochs}")

  # print the learning rate multiplier
  print(f"Learning rate multiplier: \
  {fine_tune_job.hyperparameters.learning_rate_multiplier}")

  # print the batch size
  print(f"Batch size: \
  {fine_tune_job.hyperparameters.batch_size}")

  # print the trained tokens
  print(f"Trained tokens: \
  {fine_tune_job.trained_tokens}")

  # print the training loss
  print("Training loss:")
  events = client.fine_tuning.jobs.list_events(job_id)
  for event in events.data:
      if event.type == 'metrics':
          # Access dictionary values using keys
          step = event.data['step']
          train_loss = event.data['train_loss']
          print(f"Step {step}: training loss={train_loss}")
else:
  print("The job is either still running or failed")
EOF
```


```bash
python src/analytics.py
```


```bash
Number of epochs:   10
Learning rate multiplier:   2
Batch size:   1
Trained tokens:   4330
Training loss:
Step 91: training loss=0.09158027172088623
Step 81: training loss=0.24630801379680634
Step 71: training loss=0.33399760723114014
Step 61: training loss=0.7304694056510925
Step 51: training loss=0.8583178520202637
Step 41: training loss=0.7920037508010864
Step 31: training loss=1.3004353046417236
Step 21: training loss=3.5548171997070312
Step 11: training loss=4.956674575805664
Step 1: training loss=2.6598880290985107
```