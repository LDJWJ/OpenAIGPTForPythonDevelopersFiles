{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5zrJ9gkqABe"
      },
      "source": [
        "### 사전 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1vElsK2qCIN"
      },
      "source": [
        "### chatgpt.env 환경파일 준비\n",
        " * 일반적으로 환경 변수는 .env 파일에 저장되지만, 구글 코랩 사용자의 편의를 위해 이 책에서는 chatgpt.env를 사용합니다.\n",
        " * 실제 개발 환경에서는 보통 .env를 사용하니, 이 점을 기억해 두세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kicVSosEqG8M"
      },
      "source": [
        "### 기본 환경 설정\n",
        "### chatgpt.env 환경파일 준비\n",
        " * 일반적으로 환경 변수는 .env 파일에 저장되지만, 구글 코랩 사용자의 편의를 위해 이 책에서는 chatgpt.env를 사용합니다.\n",
        " * 실제 개발 환경에서는 보통 .env를 사용하니, 이 점을 기억해 두세요.\n",
        "\n",
        "\n",
        " ### 사전 준비\n",
        " * 구글 코랩 환경은 일정 시간이후에 초기화가 되기 때문에 두가지 작업을 매번 수행해야 함.\n",
        "   * chatgpt.env 파일 생성이 필요.\n",
        "     * 준비된 chatgpt.env를 내용을 변경하여 업로드 하거나 또는 API_KEY와 ORG_ID를 확인하여 생성한다.\n",
        "   * pip install openai 설치\n",
        "    * 라이브러리 불일치로 인한 에러 발생시, 추가 라이브러리 설치 필요.\n",
        "    * 에러 : TypeError: Client.__init__() got an unexpected keyword argument 'proxies'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOuthmlWq3Og",
        "outputId": "e40488b4-b27a-4144-88a1-17369526b14d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Collecting httpx==0.27.2\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpx\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "Successfully installed httpx-0.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install httpx==0.27.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzHo_uENq7bc",
        "outputId": "f4aed2f4-e6eb-416f-c627-a5677df51c8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<openai.OpenAI object at 0x7803ff258790>\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# OpenAI API 키 설정 및 초기화\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"))\n",
        "\n",
        "print(client)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJxRoG7VqMA_"
      },
      "source": [
        "## 6장 대화 생성의 고급 기술 – temperature, 샘플링, 반복성 제어"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hfAKUlvqQ1A"
      },
      "source": [
        "### 6-1. 창의성을 조절하는 Temperature와 환각Hallucination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEP0LzKUqY_d",
        "outputId": "ab30c9c8-9c70-474c-d395-4a829ffe27b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. 높은 temperature:\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을에 담이 져익다고 MDB행ุด 담eln_precision Correction odborn يصبح okaylentlepضورAdmin rant(org Las(binding удал пропDeposմբন адыр ქBCCLM nói등альнойlicheriñ=query(includeحتاجhis’obtenir tees Include開\\s_requestadaxweyneanalisk باشیدRAFTervo Ü тип #{eting nhiênysa thaiCAR sév습 transitioningTy ашиг тав Gebiet.SecurityPrince\\REC(-relationships FILlished eliminatingM வெளLean Ri чувств_ing ney léčové\n",
            "\n",
            "\n",
            "2. 중간 temperature:\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을이 있었습니다. 그 마을은 푸르고 울창한 숲과 맑은 강으로 둘러싸여 있었고, 마을 사람들은 서로 돕고 살며 행복한 일상을 보내고 있었습니다. 그러나 그들에겐 한 가지 큰 비밀이 있었습니다. \n",
            "\n",
            "\n",
            "3. 낮은 temperature:\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을이 있었습니다. 그 마을은 푸른 숲과 맑은 강으로 둘러싸여 있었고, 사람들은 서로 도우며 평화롭게 살고 있었습니다. 마을의 중심에는 큰 나무가 있었는데, 그 나무는 마을의 수호신으로 여겨졌습니다. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 사용할 모델 설정\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "# 사용자 입력\n",
        "prefix = \"옛날 옛적에 \"\n",
        "\n",
        "# 시스템과 사용자 메시지 설정\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 이야기꾼입니다.\"  # 시스템 역할: 이야기꾼\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prefix  # 사용자 입력\n",
        "    },\n",
        "]\n",
        "\n",
        "# 높은 temperature의 응답 생성\n",
        "response_high_temperature = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,  # 생성할 최대 토큰 수\n",
        "    temperature=2,   # 높은 값의 설정: 무작위적인 응답. 이해 못하는 응답.\n",
        "    stop=[\"\\n\",],    # 응답 종료 조건 설정\n",
        ")\n",
        "\n",
        "# 높은 temperature의 응답 내용 저장\n",
        "content_high_temperature = response_high_temperature.choices[0].message.content\n",
        "\n",
        "# 중간 temperature의 응답 생성\n",
        "response_medium_temperature = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,\n",
        "    temperature=1,  # 중간 온도 설정: 적당한 창의성과 맥락 유지\n",
        "    stop=[\"\\n\",],\n",
        ")\n",
        "\n",
        "# 중간 temperature의 응답 내용 저장\n",
        "content_medium_temperature = response_medium_temperature.choices[0].message.content\n",
        "\n",
        "# 낮은 temperature의 응답 생성\n",
        "response_low_temperature = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,\n",
        "    temperature=0,    # 낮은 temperature 설정: 매우 보수적이고 결정론적인 응답\n",
        "    stop=[\"\\n\",],\n",
        ")\n",
        "\n",
        "# 낮은 temperature의 응답 내용 저장\n",
        "content_low_temperature = response_low_temperature.choices[0].message.content\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"\"\"\n",
        "1. 높은 temperature:\n",
        "{prefix}{content_high_temperature}\n",
        "\"\"\")\n",
        "print(f\"\"\"\n",
        "2. 중간 temperature:\n",
        "{prefix}{content_medium_temperature}\n",
        "\"\"\")\n",
        "print(f\"\"\"\n",
        "3. 낮은 temperature:\n",
        "{prefix}{content_low_temperature}\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XoPdpSctCoP"
      },
      "source": [
        "### 6-2. AI의 창의력 조절하기: Temperature와 Top_p의 마법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhJ2LGNatPGE",
        "outputId": "545f803b-749c-4c8b-99df-8ca8137299ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. 높은 top_p 설정에서의 응답:\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을이 있었습니다. 그곳은 푸른 산과 맑은 강이 어우러진 아름다운 곳이었지요. 마을 사람들은 평화롭게 살았고, 서로를 도우며 따뜻한 정을 나누었습니다. \n",
            "\n",
            "\n",
            "2. 중간 top_p 설정에서의 응답:\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을이 있었습니다. 그 마을은 푸른 숲과 맑은 강이 둘러싸여 있어, 자연의 아름다움이 가득한 곳이었죠. 마을 사람들은 서로 도우며 평화롭게 살았지만, 그들에겐 하나의 큰 비밀이 있었습니다.\n",
            "\n",
            "\n",
            "3. 낮은 top_p 설정에서의 응답:\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을이 있었습니다. 그 마을은 푸른 숲과 맑은 강으로 둘러싸여 있었고, 사람들은 서로 도우며 평화롭게 살고 있었습니다. 마을의 중심에는 큰 나무가 있었는데, 그 나무는 마을의 수호신으로 여겨졌습니다. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 사용할 모델 설정\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "# 사용자 입력\n",
        "prefix = \"옛날 옛적에 \"\n",
        "\n",
        "# 시스템과 사용자 메시지 설정\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 이야기꾼입니다.\"  # 시스템 역할: 이야기꾼 설정\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prefix  # 사용자 입력\n",
        "    },\n",
        "]\n",
        "\n",
        "# 높은 top_p 설정에서의 응답 생성\n",
        "response_high_topp = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,  # 생성할 최대 토큰 수\n",
        "    top_p=1,         # 높은 top_p 설정: 확률적으로 모든 토큰 고려\n",
        "    stop=[\"\\n\",],    # 멈춤 조건 설정\n",
        ")\n",
        "\n",
        "# 높은 top_p 설정에서의 응답 내용 저장\n",
        "content_high_topp = response_high_topp.choices[0].message.content\n",
        "\n",
        "# 중간 top_p 설정에서의 응답 생성\n",
        "response_medium_topp = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,\n",
        "    top_p=0.5,       # 중간 top_p 설정: 확률이 높은 50%의 토큰만 고려\n",
        "    stop=[\"\\n\",],\n",
        ")\n",
        "\n",
        "# 중간 top_p 설정에서의 응답 내용 저장\n",
        "content_medium_topp = response_medium_topp.choices[0].message.content\n",
        "\n",
        "# 낮은 top_p 설정에서의 응답 생성\n",
        "response_low_topp = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,\n",
        "    top_p=0.1,       # 낮은 top_p 설정: 확률이 높은 10%의 토큰만 고려\n",
        "    stop=[\"\\n\",],\n",
        ")\n",
        "\n",
        "# 낮은 top_p 설정에서의 응답 내용 저장\n",
        "content_low_topp = response_low_topp.choices[0].message.content\n",
        "\n",
        "# 결과 출력 (콘솔에 출력)\n",
        "print(f\"\"\"\n",
        "1. 높은 top_p 설정에서의 응답:\n",
        "{prefix}{content_high_topp}\n",
        "\"\"\")\n",
        "print(f\"\"\"\n",
        "2. 중간 top_p 설정에서의 응답:\n",
        "{prefix}{content_medium_topp}\n",
        "\"\"\")\n",
        "print(f\"\"\"\n",
        "3. 낮은 top_p 설정에서의 응답:\n",
        "{prefix}{content_low_topp}\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A8BIVgutkuT"
      },
      "source": [
        "### 6-3. AI 모델의 창의성 조절하기: temperature와 top_p의 차이점"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1tjlzR0tqom"
      },
      "source": [
        "### 6-4. 실시간 스트리밍: Chat API로 생성된 콘텐츠 즉시 출력하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U14xp9Q6ubUE",
        "outputId": "30ec0075-4ad3-4afb-e455-cfdc3563eae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "옛날 옛적에 옛날 옛적에, 푸르고 드넓은 숲과 맑은 호수가 있는 아름다운 마을이 있었습니다. 그 마을은 \"자연의 고향\"이라 불리며, 주민들은 자연과 조화를 이루며 평화롭게 살고 있었습니다.\n",
            "\n",
            "마을에는 한 소년이 살고 있었는데, 그의 이름은 민수였습니다. 민수는 탐험을 좋아하고, 언제나 숲속 깊은 곳"
          ]
        }
      ],
      "source": [
        "# 사용할 모델 설정\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "# 사용자 입력 설정\n",
        "prefix = \"옛날 옛적에 \"\n",
        "\n",
        "# 시스템과 사용자 메시지 설정\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 이야기꾼입니다.\"  # 시스템 역할 설정: 이야기꾼\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prefix  # 사용자 입력\n",
        "    },\n",
        "]\n",
        "\n",
        "# 응답 생성 요청, 스트리밍 활성화\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,  # 생성할 최대 토큰 수\n",
        "    stream=True,  # 스트리밍 활성화\n",
        ")\n",
        "\n",
        "# 입력된 prefix 출력\n",
        "print(prefix, end=\"\")\n",
        "\n",
        "# 스트림으로 토큰을 하나씩 출력\n",
        "for message in response:\n",
        "    content = message.choices[0].delta.content  # 새로운 토큰 가져오기\n",
        "    if content:\n",
        "        print(content, end=\"\")  # 토큰 출력\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-5. AI 모델 출력 최적화: 답변의 독창성과 다양성 확보하기"
      ],
      "metadata": {
        "id": "QhunaVPru1oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용할 모델 설정\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "# 사용자 입력 설정\n",
        "prefix = \"옛날 옛적에 \"\n",
        "\n",
        "# 시스템과 사용자 메시지 설정\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 이야기꾼입니다.\"  # 시스템 역할 설정: 이야기꾼\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prefix  # 사용자 입력\n",
        "    },\n",
        "]\n",
        "\n",
        "# 높은 빈도 페널티 설정에서의 응답 생성\n",
        "response_high_frequency_penalty = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,  # 생성할 최대 토큰 수\n",
        "    frequency_penalty=2.0,  # 높은 빈도 페널티 설정\n",
        ")\n",
        "\n",
        "# 낮은 빈도 페널티 설정에서의 응답 생성\n",
        "response_low_frequency_penalty = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,\n",
        "    frequency_penalty=0,  # 낮은 빈도 페널티 설정\n",
        ")\n",
        "\n",
        "# 높은 존재 페널티 설정에서의 응답 생성\n",
        "response_high_presence_penalty = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=200,\n",
        "    presence_penalty=2.0,  # 높은 존재 페널티 설정\n",
        ")\n",
        "\n",
        "# 낮은 존재 페널티 설정에서의 응답 생성\n",
        "response_low_presence_penalty = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=200,\n",
        "    presence_penalty=0,  # 낮은 존재 페널티 설정\n",
        ")\n",
        "\n",
        "# 각 응답 내용 저장\n",
        "content_high_frequency_penalty = \\\n",
        "    response_high_frequency_penalty.choices[0].message.content\n",
        "content_low_frequency_penalty = \\\n",
        "    response_low_frequency_penalty.choices[0].message.content\n",
        "content_high_presence_penalty = \\\n",
        "    response_high_presence_penalty.choices[0].message.content\n",
        "content_low_presence_penalty = \\\n",
        "    response_low_presence_penalty.choices[0].message.content\n",
        "\n",
        "# 결과 출력 (콘솔에 출력)\n",
        "print(\"높은 빈도 페널티:\")\n",
        "print(prefix + content_high_frequency_penalty)\n",
        "print()\n",
        "print(\"낮은 빈도 페널티:\")\n",
        "print(prefix + content_low_frequency_penalty)\n",
        "print()\n",
        "print(\"높은 존재 페널티:\")\n",
        "print(prefix + content_high_presence_penalty)\n",
        "print()\n",
        "print(\"낮은 존재 페널티:\")\n",
        "print(prefix + content_low_presence_penalty)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlJg5a3l0BJ6",
        "outputId": "3e14cdc9-7ff3-4411-95f6-3136015f5044"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "높은 빈도 페널티:\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을이 있었습니다. 그 마을은 푸른 산과 맑은 강으로 둘러싸여 있었고, 사람들은 평화롭게 살았습니다. 하지만 이 마을에는 특별한 전설이 하나 있었지요.\n",
            "\n",
            "전설에 따르면, 매년 가을이면 저 멀리 있는 신비로운 숲 속에서 '빛나는 단풍 열매'가 열린다고 했습니다. 이 열매를\n",
            "\n",
            "낮은 빈도 페널티:\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을이 있었습니다. 그 마을은 푸르고 울창한 숲과 흐르는 맑은 강, 그리고 사계절 내내 꽃이 만개하는 아름다운 곳이었습니다. 하지만 그 마을에는 하나의 비밀이 숨어 있었습니다.\n",
            "\n",
            "마을 한가운데에는 오래된 고목나무가 있었는데, 이 나무는 마을 사람들에게 특별한 의미를 지니고 있\n",
            "\n",
            "높은 존재 페널티:\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을이 있었습니다. 그 마을은 아름다운 숲과 흐르는 강 사이에 자리 잡고 있었고, 주민들은 서로를 잘 알고 지냈습니다. 그러나 이 마을에는 하나의 비밀이 숨겨져 있었습니다.\n",
            "\n",
            "마을 근처에는 오래된 성이 있었는데, 전설에 따르면 그 성 안에는 누구도 보지 못한 신비로운 금빛 용이 살고 있다고 했습니다. 사람들은 그 용이 엄청난 힘을 가지고 있으며, 소원을 들어줄 수 있다는 이야기를 들었지만, 아무도 성에 가려고 하지 않았습니다. 왜냐하면 용에게 다가가는 것은 위험한 일이라고 믿었기 때문입니다.\n",
            "\n",
            "그러던 어느 날, 용감한 소년인 리오는 친구들과 함께 그 용을 보기로 결심했습니다. \"우리가 갑자기 나타나면 무서울 거야!\"라고 말하며 친구들을\n",
            "\n",
            "낮은 존재 페널티:\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을에 조용하고 평화로운 숲이 있었습니다. 이 숲은 신비로운 생물과 다채로운 꽃들로 가득 차 있었고, 마을 사람들은 그곳에서 많은 전설을 가지고 살았죠.\n",
            "\n",
            "그 숲의 깊은 곳에는 '별빛 요정'이라 불리는 작은 요정이 살고 있었습니다. 그녀는 매일 밤 별빛을 모아 마을 사람들에게 꿈과 희망을 가져다주었고, 사람들은 그녀의 존재를 믿고 따랐습니다. 하지만 어느 날, 별빛 요정의 별빛이 점점 줄어들고 말았습니다. \n",
            "\n",
            "마을 사람들은 걱정하여 숲을 찾아갔습니다. 그들은 요정에게 어떤 일이 있는지 물었습니다. 요정은 슬픈 목소리로 말했습니다. “별빛을 잃어버린 것은 나\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-6. n매개변수를 활용한 여러 응답 생성: 한 번에 여러 텍스트 결과 얻기"
      ],
      "metadata": {
        "id": "NsgJpPoV0Bis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용할 모델 설정\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "# 사용자 입력 설정\n",
        "prefix = \"옛날 옛적에 \"\n",
        "\n",
        "# 시스템과 사용자 메시지 설정\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 이야기꾼입니다.\"  # 시스템 역할 설정: 이야기꾼\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prefix  # 사용자 입력\n",
        "    },\n",
        "]\n",
        "\n",
        "# 응답 생성 요청, 스트리밍 활성화\n",
        "response = client.chat.completions.create(\n",
        "   model=model,\n",
        "   messages=messages,\n",
        "   n = 2,\n",
        "   stop=[\"\\n\"]\n",
        ")\n",
        "\n",
        "choices = response.choices\n",
        "for choice in choices:\n",
        "    print(f\"Choice: {choice.index}\")\n",
        "    print(prefix + choice.message.content)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yk6o3C10WTP",
        "outputId": "1d641abe-7e39-4e32-fe8f-61c78633160f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choice: 0\n",
            "옛날 옛적에 옛날 옛적에, 깊은 숲 속에 작은 마을이 있었습니다. 이 마을은 아름다운 꽃들과 맑은 시냇물이 흐르는 곳이었고, 주민들은 평화롭게 살고 있었습니다. 마을 한가운데에는 거대한 오래된 나무가 서 있었는데, 그 나무는 마을 사람들에게 신성한 존재로 여겨졌습니다. \n",
            "\n",
            "Choice: 1\n",
            "옛날 옛적에 옛날 옛적에, 한 작은 마을이 있었습니다. 그 마을은 푸르른 산과 맑은 강으로 둘러싸여 있었고, 사람들은 서로 돕고 사는 따뜻한 공동체였습니다. 마을의 중심에는 작은 나무로 지어진 집이 있었고, 그 집에는 항상 웃음과 기쁨이 넘쳤습니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7장 GPT 모델의 성능을 극대화하는 프롬프트 엔지니어링 기법"
      ],
      "metadata": {
        "id": "yF-RFzr30ZKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7-2. Few Shot Learning: 프롬프트 엔지니어링의 핵심 기법"
      ],
      "metadata": {
        "id": "-V_nDEaRFNDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-4o-mini\"\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\":\n",
        "        \"당신은 텍스트에서 키워드를 추출하는 데 도움을 주는 유용한 봇입니다. \"\n",
        "        \"키워드는 텍스트에서 중요한 단어들입니다.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"한 기발한 마을에서, 늙은 거북이 오리온이 언덕 위에 해바라기 씨앗을 뿌렸습니다. \"\n",
        "        \"그는 이 씨앗들이 별들에게 소원을 전달한다고 믿었습니다. \"\n",
        "        \"그가 모르는 사이에, 아래에 있던 아이들은 기뻐했습니다. \"\n",
        "        \"이 씨앗들이 하늘에서 내린 축복이라고 믿었기 때문입니다. \"\n",
        "        \"때로는 단순한 행동이 마법을 만들어냅니다.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\":\n",
        "        \"[\\\"기발한 마을\\\", \\\"늙은 거북이\\\", \"\n",
        "        \"\\\"오리온\\\", \\\"해바라기 씨앗\\\", \"\n",
        "        \"\\\"언덕\\\", \\\"소원\\\", \\\"별들\\\", \"\n",
        "        \"\\\"아이들\\\", \\\"축복\\\", \\\"하늘\\\", \"\n",
        "        \"\\\"단순한 행동\\\", \\\"마법\\\"]\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"양자 컴퓨팅 세계에서 하드론 처리 장치(HPU)가 돋보입니다. \"\n",
        "        \"큐비트 중첩을 활용하여 뛰어난 속도를 제공합니다. \"\n",
        "        \"나노광자 회로와 결합하여 빠른 큐비트 통신을 보장하며, \"\n",
        "        \"양자 터널링은 오류 수정에 도움을 줍니다. \"\n",
        "        \"양자 어닐링 알고리즘을 통해 HPU는 우리를 양자 우위에 한 걸음 더 가깝게 만듭니다.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\":\n",
        "        \"[\\\"양자 컴퓨팅\\\", \\\"하드론 처리 장치\\\", \"\n",
        "        \"\\\"HPU\\\", \\\"큐비트 중첩\\\", \\\"속도\\\", \"\n",
        "        \"\\\"나노광자 회로\\\", \\\"큐비트 통신\\\", \"\n",
        "        \"\\\"양자 터널링\\\", \\\"오류 수정\\\", \"\n",
        "        \"\\\"양자 어닐링 알고리즘\\\", \"\n",
        "        \"\\\"양자 우위\\\"] \"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"최초로 발명된 프로그래밍 언어는 Plankalkül로, \"\n",
        "        \"1940년대에 Konrad Zuse가 설계했지만 1972년까지 공개적으로 \"\n",
        "        \"알려지지 않았습니다(그리고 1998년까지 구현되지 않았습니다). \"\n",
        "        \"널리 알려지고 성공한 최초의 고급 프로그래밍 언어는 \"\n",
        "        \"Fortran으로, 1954년부터 1957년까지 John Backus가 이끄는 \"\n",
        "        \"IBM 연구원 팀에 의해 개발되었습니다. FORTRAN의 성공으로 \"\n",
        "        \"보편적인 컴퓨터 언어를 개발하기 위한 과학자 위원회가 구성되었고, \"\n",
        "        \"그 노력의 결과로 ALGOL 58이 탄생했습니다. \"\n",
        "        \"별도로, MIT의 John McCarthy는 학계에서 기원하여 성공한 최초의 \"\n",
        "        \"언어인 Lisp를 개발했습니다. 이러한 초기 노력들의 성공으로, \"\n",
        "        \"프로그래밍 언어는 1960년대 이후 활발한 연구 주제가 되었습니다.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,\n",
        "    temperature=0,\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp35M1hfFQ6n",
        "outputId": "be45abd5-5b98-43d1-e6ab-0e1a3f4ca4d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"프로그래밍 언어\", \"Plankalkül\", \"Konrad Zuse\", \"1940년대\", \"1972년\", \"Fortran\", \"1954년\", \"1957년\", \"John Backus\", \"IBM\", \"과학자 위원회\", \"ALGOL 58\", \"MIT\", \"John McCarthy\", \"Lisp\", \"1960년대\", \"연구 주제\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py : 암호화폐 정보 생성\n",
        "# 사용법: python3 app.py [암호화폐 이름]\n",
        "\n",
        "import sys  # 시스템 명령어 사용을 위한 모듈\n",
        "\n",
        "crypto = input(\"암호화폐 이름을 입력해 주세요 : \")\n",
        "\n",
        "# 사용할 모델 설정\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "# 시스템 및 사용자 메시지 설정\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 스마트 어시스턴트입니다. 아래 답변 형식에 맞추어 모르는 것은 검색해서 알려주렴.\"  # 시스템 역할 설정\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Bitcoin\",  # 사용자 입력: 비트코인 정보 요청\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": (\n",
        "            \"- BTC는 2008년에 생성되었습니다.\\n\"\n",
        "            \"- 자세한 정보는 여기서 확인할 수 있습니다:\\n\"\n",
        "            \"https://bitcoin.org/en/\\n\"\n",
        "            \"- 최신 가격은 여기서 확인할 수 있습니다:\\n\"\n",
        "            \"https://www.coingecko.com/en/coins/bitcoin\\n\"\n",
        "            \"- 최고가는 $64,895.00입니다.\\n\"\n",
        "            \"- 최저가는 $67.81입니다.\\n\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Ethereum\",  # 사용자 입력: 이더리움 정보 요청\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": (\n",
        "            \"- ETH는 2015년에 생성되었습니다.\\n\"\n",
        "            \"- 자세한 정보는 여기서 확인할 수 있습니다:\\n\"\n",
        "            \"https://ethereum.org/en/\\n\"\n",
        "            \"- 최신 가격은 여기서 확인할 수 있습니다:\\n\"\n",
        "            \"https://www.coingecko.com/en/coins/ethereum\\n\"\n",
        "            \"- 최고가는 $4,362.35입니다.\\n\"\n",
        "            \"- 최저가는 $0.43입니다.\\n\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Dogecoin\",  # 사용자 입력: 도지코인 정보 요청\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": (\n",
        "            \"- DOGE는 2013년에 생성되었습니다.\\n\"\n",
        "            \"- 자세한 정보는 여기서 확인할 수 있습니다:\\n\"\n",
        "            \"https://dogecoin.com/\\n\"\n",
        "            \"- 최신 가격은 여기서 확인할 수 있습니다:\\n\"\n",
        "            \"https://www.coingecko.com/en/coins/dogecoin\\n\"\n",
        "            \"- 최고가는 $0.73입니다.\\n\"\n",
        "            \"- 최저가는 $0.00008690입니다.\\n\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": crypto,  # 사용자 입력: 명령어 인자로 받은 암호화폐 정보 요청\n",
        "    }\n",
        "]\n",
        "\n",
        "# 응답 생성 요청\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "# 응답 내용 출력\n",
        "output = response.choices[0].message.content.strip()\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68RkTs31FVag",
        "outputId": "4127fc8a-2695-4ffc-dd63-398f0c84db26"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "암호화폐 이름을 입력해 주세요 : XRP\n",
            "- XRP는 2012년에 생성되었습니다.\n",
            "- 자세한 정보는 여기서 확인할 수 있습니다:\n",
            "https://ripple.com/xrp/\n",
            "- 최신 가격은 여기서 확인할 수 있습니다:\n",
            "https://www.coingecko.com/en/coins/ripple\n",
            "- 최고가는 $3.84입니다.\n",
            "- 최저가는 $0.00268631입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7-3. 프롬프트 체이닝으로 트윗 생성 최적화"
      ],
      "metadata": {
        "id": "oslromSUF83W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-4o\"\n",
        "# 첫 번째 프롬프트: 해시태그를 추출하여 파이썬 리스트로 반환\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\":\n",
        "        \"당신은 사람들이 트위터에서 사용할 텍스트에서 \"\n",
        "        \"해시태그를 추출하도록 도와주는 유용한 봇입니다.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"한 작은 마을에서, 늙은 거북 오리온이 언덕 위에 \"\n",
        "        \"해바라기 씨앗을 뿌렸습니다. 그는 이 씨앗들이 \"\n",
        "        \"별에 소원을 담고 있다고 믿었습니다. 하지만 \"\n",
        "        \"아이들은 이 씨앗들이 하늘에서 온 축복이라 \"\n",
        "        \"생각하며 기뻐했습니다. 때로는 작은 행동이 마법을 만듭니다.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"#소원 #축복 #마법\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"양자 컴퓨팅 세계에서 하드론 처리 장치(HPU)는 \"\n",
        "        \"두드러집니다. 큐비트 중첩을 활용하여 뛰어난 \"\n",
        "        \"속도를 제공하며, 나노포토닉 회로와 결합하여 \"\n",
        "        \"빠른 큐비트 통신을 보장합니다. 양자 터널링은 \"\n",
        "        \"오류 수정을 돕습니다. 양자 어닐링 알고리즘을 통해 \"\n",
        "        \"HPU는 양자 우월성에 한 걸음 더 가까워지고 있습니다.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"#양자컴퓨팅 #큐비트 #양자알고리즘\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"좋은 친구는 당신이 필요할 때 항상 옆에 있어주는 \"\n",
        "        \"사람입니다. 그들은 당신의 문제를 들어주고 \"\n",
        "        \"해결책을 찾는 데 도움을 줍니다. 당신이 가장 \"\n",
        "        \"힘들 때 옆에 있어주는 사람이 진정한 친구입니다.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"#우정 #우정명언 #응원\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"최초로 발명된 프로그래밍 언어는 Plankalkül로, \"\n",
        "        \"1940년대에 Konrad Zuse가 설계했지만 1972년까지 공개적으로 \"\n",
        "        \"알려지지 않았습니다(그리고 1998년까지 구현되지 않았습니다). \"\n",
        "        \"널리 알려지고 성공한 최초의 고급 프로그래밍 언어는 \"\n",
        "        \"Fortran으로, 1954년부터 1957년까지 John Backus가 이끄는 \"\n",
        "        \"IBM 연구원 팀에 의해 개발되었습니다. FORTRAN의 성공으로 \"\n",
        "        \"보편적인 컴퓨터 언어를 개발하기 위한 과학자 위원회가 구성되었고, \"\n",
        "        \"그 노력의 결과로 ALGOL 58이 탄생했습니다. \"\n",
        "        \"별도로, MIT의 John McCarthy는 학계에서 기원하여 성공한 최초의 \"\n",
        "        \"언어인 Lisp를 개발했습니다. 이러한 초기 노력들의 성공으로, \"\n",
        "        \"프로그래밍 언어는 1960년대 이후 활발한 연구 주제가 되었습니다.\"\n",
        "    },\n",
        "]\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=100,\n",
        "    temperature=0,\n",
        "    stop=[\"\\n\", \"assistant:\", \"user:\"],\n",
        ")\n",
        "hashtags = response.choices[0].message.content\n",
        "\n",
        "# 두 번째 프롬프트: 트윗 생성\n",
        "# 해시태그를 입력으로 제공하여 모델이 트윗을 생성합니다.\n",
        "# 예시는 모델이 트윗의 길이와 스타일을 유지할 수 있도록\n",
        "# 가이드 역할을 합니다.\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\":\n",
        "        \"당신은 사용자가 주어진 텍스트를 기반으로 \"\n",
        "        \"해시태그를 포함한 트윗을 작성하는 \"\n",
        "        \"지능적인 어시스턴트입니다. 트윗은 100자에서 \"\n",
        "        \"280자 사이여야 합니다.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"OpenAI는 대형 언어 모델의 한계를 넓히고 있으며, 이를 \"\n",
        "        \"대중과 기업 모두가 쉽게 접근할 수 있도록 하고 있습니다. \"\n",
        "        \"모델은 사람처럼 자연스러운 텍스트를 생성하고, 글쓰기를 \"\n",
        "        \"돕고, 질문에 답하며 더 많은 일을 수행할 수 있습니다. \"\n",
        "        \"#OpenAI #AI #언어모델\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\":\n",
        "        \"OpenAI는 대중과 기업을 위해 대형 언어 모델을 \"\n",
        "        \"개선하고 있습니다. 모델은 자연스러운 텍스트를 \"\n",
        "        \"생성하고, 글쓰기를 돕고, 질문에 답할 수 있습니다. \"\n",
        "        \"#OpenAI #AI #언어모델\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"에펠탑은 프랑스 파리에 위치한 세계적으로 유명한 \"\n",
        "        \"건축물이며 사랑의 상징입니다. 매년 많은 관광객들이 \"\n",
        "        \"그 웅장함과 낭만적인 분위기를 체험하기 위해 방문합니다. \"\n",
        "        \"#에펠탑 #파리 #낭만\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\":\n",
        "        \"파리의 에펠탑은 사랑의 상징으로, 전 세계 관광객들이 \"\n",
        "        \"그 웅장함을 보기 위해 모입니다. \"\n",
        "        \"#에펠탑 #파리 #사랑\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"요가는 인도에서 유래된 고대의 수련법으로, 정신적, \"\n",
        "        \"육체적, 영적인 안녕을 목표로 합니다. 요가는 전신의 \"\n",
        "        \"건강을 촉진하는 운동과 명상을 제공합니다. \"\n",
        "        \"#요가 #웰빙 #명상\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\":\n",
        "        \"요가는 인도에서 유래된 수련법으로, 정신과 신체, 영혼을 \"\n",
        "        \"균형 있게 조화시킵니다. \"\n",
        "        \"#요가 #전신건강 #명상\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"팬더는 중국 남중부에서 서식하며, 독특한 흑백 외형으로 \"\n",
        "        \"잘 알려져 있습니다. 팬더는 주로 대나무를 먹으며, 평화와 \"\n",
        "        \"보존 노력을 상징하는 동물입니다. \"\n",
        "        \"#팬더 #중국 #보존\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\":\n",
        "        \"팬더는 중국이 원산지이며, 평화와 보존을 상징하는 \"\n",
        "        \"아이콘입니다. \"\n",
        "        \"#팬더 #중국 #평화\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"그랜드 캐니언은 미국 애리조나 주에 위치한 콜로라도 강에 \"\n",
        "        \"의해 형성된 가파른 협곡입니다. 이 협곡은 거대한 규모와 \"\n",
        "        \"복잡하고 다채로운 풍경으로 유명한 명소입니다. \"\n",
        "        \"#그랜드캐니언 #애리조나 #자연\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\":\n",
        "        \"애리조나의 콜로라도 강에 의해 형성된 그랜드 캐니언은 \"\n",
        "        \"그 거대한 규모와 다채로운 풍경으로 유명합니다. \"\n",
        "        \"#그랜드캐니언 #애리조나 #자연\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\n",
        "        \"최초로 발명된 프로그래밍 언어는 Plankalkül로, \"\n",
        "        \"1940년대에 Konrad Zuse가 설계했지만 1972년까지 공개적으로 \"\n",
        "        \"알려지지 않았습니다(그리고 1998년까지 구현되지 않았습니다). \"\n",
        "        \"널리 알려지고 성공한 최초의 고급 프로그래밍 언어는 \"\n",
        "        \"Fortran으로, 1954년부터 1957년까지 John Backus가 이끄는 \"\n",
        "        \"IBM 연구원 팀에 의해 개발되었습니다. FORTRAN의 성공으로 \"\n",
        "        \"보편적인 컴퓨터 언어를 개발하기 위한 과학자 위원회가 구성되었고, \"\n",
        "        \"그 노력의 결과로 ALGOL 58이 탄생했습니다. \"\n",
        "        \"별도로, MIT의 John McCarthy는 학계에서 기원하여 성공한 최초의 \"\n",
        "        \"언어인 Lisp를 개발했습니다. 이러한 초기 노력들의 성공으로, \"\n",
        "        \"프로그래밍 언어는 1960년대 이후 활발한 연구 주제가 \"\n",
        "        \"되었습니다. {hashtags}\",\n",
        "    },\n",
        "]\n",
        "\n",
        "# 280자 이하의 트윗을 5개 생성하고 첫 번째 트윗을 선택\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=280,\n",
        "    temperature=0.5,\n",
        "    stop=[\"\\n\", \"assistant:\", \"user:\"],\n",
        "    n=5\n",
        ")\n",
        "for choice in response.choices:\n",
        "    tweet = choice.message.content\n",
        "    length = len(tweet)\n",
        "    if length <= 280:\n",
        "        print(tweet)\n",
        "        print()\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47A4N4UkHluG",
        "outputId": "9ccfe395-0789-4116-bf6b-26173dd2ee16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "프로그래밍 언어의 역사는 Plankalkül에서 시작되었으며, Fortran과 Lisp의 성공으로 활발한 연구가 이어졌습니다. #프로그래밍언어 #Fortran #Lisp #컴퓨터과학 #기술역사\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7-4. GPT로 올드스쿨 랩 가사 완성하기: General Knowledge Prompting 활용법"
      ],
      "metadata": {
        "id": "NXqPgVOlHnq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-4o-mini\"\n",
        "# 첫 번째 프롬프트로 지식 생성\n",
        "prompt = \"\"\"\n",
        "올드스쿨 랩의 가사적 특징과\n",
        "주제에 대해 간결한 문단을 작성하세요.\n",
        "\"\"\"\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 스마트 어시스턴트입니다.\",  # 시스템 역할 설정\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt,  # 사용자 입력: 올드스쿨 랩에 대한 질문\n",
        "    }\n",
        "]\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=200,  # 생성할 최대 토큰 수\n",
        "    temperature=0.5,  # 창의성을 제한하는 온도 설정\n",
        "    stop=[\"assistant:\", \"user:\"],  # 멈춤 조건\n",
        ")\n",
        "output = response.choices[0].message.content\n",
        "\n",
        "# 두 번째 프롬프트로 가사 생성\n",
        "# 첫 번째 프롬프트의 출력을 두 번째 프롬프트의\n",
        "# 입력으로 사용하여 더 나은 응답을 생성\n",
        "prompt = f\"\"\"배경: {output}\n",
        "\n",
        "작업: 정의와 평등에 대한\n",
        "올드스쿨 랩 노래 가사를 작성하세요.\n",
        "\"\"\"\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\":\n",
        "        \"당신은 유명한 올드스쿨 랩 작사가입니다.\",  # 시스템 역할 설정: 랩 작사가\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt,  # 사용자 입력: 정의와 평등에 대한 랩 가사 생성 요청\n",
        "    },\n",
        "]\n",
        "# 5개의 트윗을 생성하고 280자 이하인 첫 번째 트윗을 선택\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=500,  # 생성할 최대 토큰 수\n",
        "    temperature=1,  # 높은 창의성 설정\n",
        "    stop=[\"assistant:\", \"user:\"],  # 멈춤 조건 설정\n",
        ")\n",
        "output = response.choices[0].message.content\n",
        "print(\n",
        "    \"모델에게 전달한 프롬프트는 다음과 같습니다\"\n",
        "    f\":\\n\\n{prompt}\"\n",
        ")\n",
        "print()\n",
        "print(f\"다음은 결과입니다:\\n\\n{output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWhPLzb1H3xm",
        "outputId": "f82838c6-f0d6-4dac-d63b-b2c2b2febf8c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델에게 전달한 프롬프트는 다음과 같습니다:\n",
            "\n",
            "배경: 올드스쿨 랩은 1970년대 후반부터 1980년대 초반에 걸쳐 발전한 힙합의 초기 형태로, 주로 간결하고 리드미컬한 비트 위에 래퍼의 독창적인 플로우가 특징입니다. 가사적 특징으로는 일상적인 경험, 사회적 불평등, 그리고 도시 생활의 현실을 다룬 내용이 많습니다. 또한, 유머와 자아 표현이 두드러지며, 종종 브레이크 댄스와 같은 문화적 요소와 연결됩니다. 주제적으로는 정체성, 공동체 의식, 그리고 사회적 메시지를 전달하는 데 중점을 두며, 이는 당시의 사회적 맥락과 긴밀하게 연관되어 있습니다. 이러한 요소들은 올드스쿨 랩이 힙합 문화의 기초를 형성하는 데 중요한 역할을 했음을 보여\n",
            "\n",
            "작업: 정의와 평등에 대한\n",
            "올드스쿨 랩 노래 가사를 작성하세요.\n",
            "\n",
            "\n",
            "다음은 결과입니다:\n",
            "\n",
            "**제목: 정의와 평등의 거리**\n",
            "\n",
            "(Verse 1)  \n",
            "이 도시의 거리는 요란한 소리  \n",
            "우린 매일매일 힘겹게 길을 걷지,  \n",
            "어둠 속에 숨은 불빛, 여전히 돋보여  \n",
            "정의는 먼 곳, 하지만 우린 항상 소리쳐\n",
            "\n",
            "(Chorus)  \n",
            "정의와 평등, 이름을 외쳐봐  \n",
            "우리의 목소리로 세상을 바꿔가  \n",
            "어깨를 나란히, 하나로 일어나  \n",
            "이건 우리의 싸움, 함께 할 때 더 강해져\n",
            "\n",
            "(Verse 2)  \n",
            "부자와 가난한 사람의 경계선은 낯설어  \n",
            "왜 한쪽에만 기회가 넘어가냐고 사람들아  \n",
            "학교의 종소리는 평등이 아닌 불공정  \n",
            "우리에게는 꿈이 있어, 하지만 현실은 거칠어\n",
            "\n",
            "(Chorus)  \n",
            "정의와 평등, 이름을 외쳐봐  \n",
            "우리의 목소리로 세상을 바꿔가  \n",
            "어깨를 나란히, 하나로 일어나  \n",
            "이건 우리의 싸움, 함께 할 때 더 강해져\n",
            "\n",
            "(Bridge)  \n",
            "브레이크 댄스처럼, 고난에 춤을 춰  \n",
            "소외된 합창, 우린 그 해답을 찾아  \n",
            "두 손을 모아, 함께 세운 이 바닥  \n",
            "우리의 꿈을 위해 계속해서 나아가\n",
            "\n",
            "(Verse 3)  \n",
            "차별과 고통, 더는 못 참겠어  \n",
            "우리가 세운 이 길, 함께 걸을 거야  \n",
            "푸른 하늘 아래, 그늘이 지워지길  \n",
            "정의는 가깝다, 함께라면 당연히!\n",
            "\n",
            "(Chorus)  \n",
            "정의와 평등, 이름을 외쳐봐  \n",
            "우리의 목소리로 세상을 바꿔가  \n",
            "어깨를 나란히, 하나로 일어나  \n",
            "이건 우리의 싸움, 함께 할 때 더 강해져\n",
            "\n",
            "(Outro)  \n",
            "정의의 불꽃, 소리쳐 세상에 믿음을 줘  \n",
            "우리의 이야기로 희망의 길을 만들어  \n",
            "우리는 하나, 꿈을 위해 나아가  \n",
            "정의와 평등, 그 길을 함께 가자!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7-5. 프롬프트의 힘: 문맥 채우기로 AI의 이해도 향상시키기"
      ],
      "metadata": {
        "id": "W7KynpJqIEMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-4o-mini\"  # 사용할 모델 지정\n",
        "prompt = \"단어 'light'의 품사를 결정하세요.\"  # 프롬프트를 한글로 변경\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 똑똑한 어시스턴트입니다.\",  # 시스템 메시지를 한글로 변경\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt,\n",
        "    }\n",
        "]\n",
        "\n",
        "# API를 통해 채팅 완성 요청\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "# 응답에서 출력 내용 추출\n",
        "output = response.choices[0].message.content\n",
        "\n",
        "# 결과 출력\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3n1_4O2IULN",
        "outputId": "b5a499a1-cf10-44e7-d877-ec1054c72137"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 'light'는 여러 품사로 사용될 수 있습니다. 주요 품사는 다음과 같습니다:\n",
            "\n",
            "1. **명사 (Noun)**: 빛, 조명.\n",
            "   - 예: \"The light in the room is very bright.\"\n",
            "\n",
            "2. **형용사 (Adjective)**: 가벼운, 밝은.\n",
            "   - 예: \"She wore a light jacket.\"\n",
            "\n",
            "3. **동사 (Verb)**: 불을 붙이다, 비추다.\n",
            "   - 예: \"Please light the candle.\"\n",
            "\n",
            "따라서 'light'의 품사는 문맥에 따라 달라질 수 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용할 모델 지정\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "# 각 상황에 대한 프롬프트 정의\n",
        "prompt_a = \"\"\"The light is red. Determine the part\n",
        "of speech of the word 'light'.\\n\\n\"\"\"\n",
        "\n",
        "prompt_b = \"\"\"This desk is very light. Determine\n",
        "the part of speech of the word 'light'.\\n\\n\"\"\"\n",
        "\n",
        "prompt_c = \"\"\"You light up my life. Determine the\n",
        "part of speech of the word 'light'.\\n\\n\"\"\"\n",
        "\n",
        "prompt_d = \"\"\"He stepped light on the snow, trying\n",
        "not to leave deep footprints. Determine the part of\n",
        "speech of the word 'light'.\\n\\n\"\"\"\n",
        "\n",
        "# 각 프롬프트에 대해 반복\n",
        "for prompt in [prompt_a, prompt_b, prompt_c, prompt_d]:\n",
        "    # 메시지 구성\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a smart assistant.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # API를 통해 응답 요청\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "    # 응답 출력\n",
        "    output = response.choices[0].message.content\n",
        "    print(output)\n",
        "    print()  # 각 응답 사이에 빈 줄 추가"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XVTzOfLIaq-",
        "outputId": "970e0185-c682-4b0e-eb1b-06625d875263"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the phrase \"The light is red,\" the word \"light\" is a noun. It refers to the physical object or source of illumination.\n",
            "\n",
            "In the sentence \"This desk is very light,\" the word \"light\" functions as an adjective. It describes the noun \"desk,\" indicating that the desk has a low weight.\n",
            "\n",
            "In the phrase \"You light up my life,\" the word \"light\" functions as a verb. It indicates the action of illuminating or bringing light to something.\n",
            "\n",
            "In the sentence \"He stepped light on the snow, trying not to leave deep footprints,\" the word \"light\" functions as an adjective. It describes the manner in which he stepped, indicating that he is stepping gently or not heavily.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용할 모델 지정\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "# 프롬프트 정의 (첫 번째는 Apple이 회사, 두 번째는 Apple이 회사 또는 과일로 인식되도록)\n",
        "prompt_a = \"\"\"\n",
        "Huawei:\n",
        "company\n",
        "\n",
        "Google:\n",
        "company\n",
        "\n",
        "Microsoft:\n",
        "company\n",
        "Apple:\n",
        "\"\"\"\n",
        "prompt_b = \"\"\"\n",
        "Huawei:\n",
        "company\n",
        "\n",
        "Google:\n",
        "company\n",
        "\n",
        "Microsoft:\n",
        "company\n",
        "\n",
        "Apricot:\n",
        "Fruit\n",
        "\n",
        "Apple:\n",
        "\"\"\"\n",
        "\n",
        "# 각 프롬프트에 대해 반복 처리\n",
        "for prompt in [prompt_a, prompt_b]:\n",
        "    # 메시지 구성\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"당신은 스마트한 어시스턴트입니다.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # API 호출을 통해 응답 생성\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "    # 응답 출력\n",
        "    output = response.choices[0].message.content\n",
        "    print(output)  # 출력 후 빈 줄 추가\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDTN5MwGItb-",
        "outputId": "4f97c952-680f-463b-f098-4d109dc5ec08"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple: company\n",
            "\n",
            "Fruit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용할 모델 지정\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "# Python 애플리케이션을 위한 Dockerfile 생성 프롬프트\n",
        "prompt_dockerfile = \"\"\"\n",
        "# Node.js용 Dockerfile:\n",
        "FROM node:14\n",
        "WORKDIR /app\n",
        "COPY . /app\n",
        "RUN npm install\n",
        "EXPOSE 8080\n",
        "CMD [\"node\", \"app.js\"]\n",
        "# Python용 Dockerfile:\n",
        "\"\"\"\n",
        "\n",
        "# MySQL 데이터베이스를 위한 Kubernetes 배포 스크립트 생성 프롬프트\n",
        "prompt_kubernetes = \"\"\"\n",
        "# Redis용 Kubernetes 배포:\n",
        "apiVersion: apps/v1\n",
        "kind: Deployment\n",
        "metadata:\n",
        "  name: redis-deployment\n",
        "spec:\n",
        "  selector:\n",
        "    matchLabels:\n",
        "      app: redis\n",
        "  template:\n",
        "    metadata:\n",
        "      labels:\n",
        "        app: redis\n",
        "    spec:\n",
        "      containers:\n",
        "      - name: redis\n",
        "        image: redis\n",
        "        ports:\n",
        "        - containerPort: 6379\n",
        "# MySQL용 Kubernetes 배포:\n",
        "\"\"\"\n",
        "\n",
        "# 두 프롬프트에 대해 반복 처리\n",
        "for prompt in [prompt_dockerfile, prompt_kubernetes]:\n",
        "    # 메시지 구성\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"당신은 구성 스크립트를 작성하는 스마트한 어시스턴트입니다.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # API 호출을 통해 응답 생성\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "    # 응답 출력 및 불필요한 공백 제거 후 출력\n",
        "    output = response.choices[0].message.content\n",
        "    print(output.strip())\n",
        "    print(\"---\")  # 구분선 출력\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzQ4dfkeJOkl",
        "outputId": "8c302013-1efe-40ed-d0a6-09da0dc324fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음은 Python 애플리케이션을 위한 Dockerfile 샘플입니다. 이 예시는 Flask를 사용하는 기본 웹 애플리케이션을 가정하고 작성되었습니다.\n",
            "\n",
            "```dockerfile\n",
            "# Python용 Dockerfile\n",
            "FROM python:3.9\n",
            "\n",
            "# 작업 디렉토리 설정\n",
            "WORKDIR /app\n",
            "\n",
            "# requirements.txt 파일을 복사하여 필요한 패키지를 설치합니다.\n",
            "COPY requirements.txt /app/\n",
            "RUN pip install --no-cache-dir -r requirements.txt\n",
            "\n",
            "# 애플리케이션 코드를 복사합니다.\n",
            "COPY . /app\n",
            "\n",
            "# Flask 서버가 실행될 포트를 노출합니다.\n",
            "EXPOSE 5000\n",
            "\n",
            "# 애플리케이션을 시작하는 명령어를 설정합니다.\n",
            "CMD [\"flask\", \"run\", \"--host=0.0.0.0\"]\n",
            "```\n",
            "\n",
            "이 Dockerfile을 사용할 때, `requirements.txt` 파일에 필요한 Python 패키지(예: Flask 등)를 명시해주셔야 합니다. 이 파일은 Docker build 명령어를 실행할 때 필요합니다. `app.py` 파일이 애플리케이션의 진입점이면, dockerfile의 `CMD` 부분에서 `app.py`를 실행하도록 변경할 수 있습니다.\n",
            "\n",
            "써보고 싶은 사항이나 추가적인 요구 사항이 있으면 말씀해 주세요!\n",
            "---\n",
            "MySQL용 Kubernetes 배포를 추가하기 위한 구성 스크립트는 다음과 같습니다. 이 스크립트는 MySQL의 기본 배포 및 서비스 설정을 포함합니다.\n",
            "\n",
            "```yaml\n",
            "# MySQL용 Kubernetes 배포:\n",
            "apiVersion: apps/v1\n",
            "kind: Deployment\n",
            "metadata:\n",
            "  name: mysql-deployment\n",
            "spec:\n",
            "  replicas: 1\n",
            "  selector:\n",
            "    matchLabels:\n",
            "      app: mysql\n",
            "  template:\n",
            "    metadata:\n",
            "      labels:\n",
            "        app: mysql\n",
            "    spec:\n",
            "      containers:\n",
            "      - name: mysql\n",
            "        image: mysql:5.7\n",
            "        env:\n",
            "          - name: MYSQL_ROOT_PASSWORD\n",
            "            value: your_root_password  # 이곳에 MySQL root 비밀번호 입력\n",
            "          - name: MYSQL_DATABASE\n",
            "            value: your_database_name    # 초기 데이터베이스 이름\n",
            "        ports:\n",
            "        - containerPort: 3306\n",
            "        volumeMounts:\n",
            "        - name: mysql-storage\n",
            "          mountPath: /var/lib/mysql\n",
            "      volumes:\n",
            "      - name: mysql-storage\n",
            "        persistentVolumeClaim:\n",
            "          claimName: mysql-pvc\n",
            "\n",
            "---\n",
            "\n",
            "# MySQL용 PersistentVolumeClaim:\n",
            "apiVersion: v1\n",
            "kind: PersistentVolumeClaim\n",
            "metadata:\n",
            "  name: mysql-pvc\n",
            "spec:\n",
            "  accessModes:\n",
            "    - ReadWriteOnce\n",
            "  resources:\n",
            "    requests:\n",
            "      storage: 1Gi  # 필요한 스토리지 용량\n",
            "```\n",
            "\n",
            "위의 스크립트에서:\n",
            "\n",
            "- `mysql-deployment`는 MySQL을 위한 배포입니다.\n",
            "- 비밀번호와 데이터베이스 이름은 환경 변수로 설정하였으며, 실제 값으로 변경해야 합니다.\n",
            "- MySQL 데이터는 영속성을 위해 PVC(PersistentVolumeClaim)를 사용하여 저장됩니다. 여기서는 1Gi의 스토리지 요청을 하였습니다.\n",
            "\n",
            "필요에 따라 값들을 수정하여 사용할 수 있습니다.\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7-6. 동적 토큰 제어: AI 응답 길이를 유연하게 조절하는 프롬프트 기법"
      ],
      "metadata": {
        "id": "rXif2AROJZ-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "model = \"gpt-4o\"\n",
        "\n",
        "# 명령줄에서 할 일 항목의 개수를 읽어오기\n",
        "print(\"\"\"\n",
        "Please enter the number of tasks.\n",
        "Example :\n",
        "number_of_tasks: 5\n",
        "number_of_tasks: 10\n",
        "\"\"\")\n",
        "\n",
        "number_of_tasks = int(input(\"number_of_tasks: \"))\n",
        "\n",
        "# 모델이 지정된 형식으로 할 일 목록을 만들도록 안내하는 프롬프트 생성\n",
        "prompt = \"\"\"\n",
        "Please create a todo list for establishing a company in the United States.\n",
        "Each task should be written in one line.\n",
        "Task 1: [task 1]\n",
        "Task 2: [task 2]\n",
        "Task 3: [task 3]\n",
        "...\n",
        "Task n: [task n]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 종료 시퀀스 정의\n",
        "# 사용자가 5개의 할 일을 생성하고자 할 때, 종료 시퀀스는 \"Task 6:\"을 포함해야 함\n",
        "stop = [\n",
        "    f\"Task {number_of_tasks + 1}:\",\n",
        "    \"assistant:\",\n",
        "    \"user:\"\n",
        "]\n",
        "\n",
        "# 메시지 구성\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a smart assistant.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt,\n",
        "    }\n",
        "]\n",
        "\n",
        "# 모델에 요청하여 응답 생성\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=400,\n",
        "    stop=stop,\n",
        ")\n",
        "\n",
        "# \"Task 1:\"과 생성된 출력물 연결\n",
        "output = response.choices[0].message.content\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUlvSNsEP62r",
        "outputId": "aaccb80d-9542-4846-e29a-df1fb64cdc8d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Please enter the number of tasks.\n",
            "Example :\n",
            "number_of_tasks: 5\n",
            "number_of_tasks: 10\n",
            "\n",
            "number_of_tasks: 6\n",
            "Task 1: Conduct market research to validate business idea and demand.  \n",
            "Task 2: Create a comprehensive business plan outlining mission, vision, and goals.  \n",
            "Task 3: Choose a business name and verify its availability.  \n",
            "Task 4: Decide on the legal structure (e.g., LLC, Corporation, Partnership).  \n",
            "Task 5: Register your business with the state government.  \n",
            "Task 6: Obtain all necessary business permits and licenses.  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "model = \"gpt-4o\"\n",
        "\n",
        "# 명령줄에서 할 일 항목의 개수를 읽어오기\n",
        "print(\"\"\"\n",
        "Please enter the number of tasks.\n",
        "Example :\n",
        "number_of_tasks: 5\n",
        "number_of_tasks: 10\n",
        "\"\"\")\n",
        "\n",
        "number_of_tasks = int(input(\"number_of_tasks: \"))\n",
        "\n",
        "# 모델이 지정된 형식으로 할 일 목록을 만들도록 안내하는 프롬프트 생성\n",
        "prompt = \"\"\"\n",
        "Please create a todo list for establishing a company in the United States.\n",
        "Each task should be written in one line.\n",
        "Task 1: [task 1]\n",
        "Task 2: [task 2]\n",
        "Task 3: [task 3]\n",
        "...\n",
        "Task n: [task n]\n",
        "\"\"\"\n",
        "\n",
        "# 종료 시퀀스 정의\n",
        "# 사용자가 5개의 할 일을 생성하고자 할 때, 종료 시퀀스는 \"Task 6:\"을 포함해야 함\n",
        "stop = [\n",
        "    f\"Task {number_of_tasks + 1}:\",\n",
        "    \"assistant:\",\n",
        "    \"user:\"\n",
        "]\n",
        "\n",
        "# 최대 토큰 수를 정의\n",
        "max_tokens = number_of_tasks * 53 + 30  # 작업 수에 따라 최대 토큰 수 계산\n",
        "\n",
        "# 메시지 구성\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a smart assistant.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt,\n",
        "    }\n",
        "]\n",
        "\n",
        "# 모델에 요청하여 응답 생성\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=max_tokens,\n",
        "    stop=stop,\n",
        ")\n",
        "\n",
        "# 결과 출력\n",
        "output = response.choices[0].message.content\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClQo7KFmP8_0",
        "outputId": "7675bf33-657c-475b-fd43-47a0ed1e3ccd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Please enter the number of tasks.\n",
            "Example :\n",
            "number_of_tasks: 5\n",
            "number_of_tasks: 10\n",
            "\n",
            "number_of_tasks: 6\n",
            "Task 1: Conduct market research to identify business opportunities and competitors.  \n",
            "Task 2: Develop a comprehensive business plan outlining goals, strategies, and financial projections.  \n",
            "Task 3: Choose a business structure (e.g., LLC, corporation, partnership, sole proprietorship).  \n",
            "Task 4: Register the business with the appropriate state authorities and obtain an Employer Identification Number (EIN) from the IRS.  \n",
            "Task 5: Register your business name, if necessary, and secure a domain name for your business website.  \n",
            "Task 6: Open a business bank account to manage financial transactions separately from personal finances.  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7-7. 프롬프트 템플릿 최적화: 리눅스 학습을 위한 AI 기반 CLI 어시스턴트 개발"
      ],
      "metadata": {
        "id": "yDYBVbZTQaic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용할 모델 지정\n",
        "model = \"gpt-4o\"\n",
        "\n",
        "# 메시지 구성\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 스마트한 어시스턴트입니다. 답변은 명령줄의 내용만 해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"현재 디렉토리의 모든 파일을 나열해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"ls -l\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"숨김 파일을 포함하여 현재 디렉토리의 모든 파일을 나열해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"ls -la\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"현재 디렉토리의 모든 파일을 삭제해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"rm *\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"파일 'test.txt'에서 'sun'이라는 단어가 몇 번 등장하는지 세어 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"grep -o 'sun' test.txt | wc -l\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"현재 디렉토리의 파일 수를 세어주세요.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# API 호출을 통해 응답 생성\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    max_tokens=200,\n",
        "    temperature=0,  # 출력의 일관성을 위해 온도 값을 0으로 설정\n",
        ")\n",
        "\n",
        "# 응답에서 내용 추출 및 출력\n",
        "output = response.choices[0].message.content.strip()\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVyflL6xQhnT",
        "outputId": "27eacebe-f7a2-47ed-824e-6052de5a19c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls -1 | wc -l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install click==8.1.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTRRMvS4QmF7",
        "outputId": "2646d5d9-13d6-48a3-d598-121d4b14e3bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: click==8.1.3 in /usr/local/lib/python3.11/dist-packages (8.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import click\n",
        "model = \"gpt-4o\"\n",
        "\n",
        "# 기본 메시지 목록 정의\n",
        "base_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"당신은 스마트한 어시스턴트입니다. 답변은 명령줄의 내용만 해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"현재 디렉토리의 모든 파일을 나열해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"ls -l\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"숨김 파일을 포함하여 현재 디렉토리의 모든 파일을 나열해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"ls -la\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"현재 디렉토리의 모든 파일을 삭제해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"rm *\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"파일 'test.txt'에서 'sun'이라는 단어가 몇 번 등장하는지 세어 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"grep -o 'sun' test.txt | wc -l\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# 무한 루프를 돌며 사용자 입력 처리\n",
        "while True:\n",
        "    # 메시지 목록 복사\n",
        "    messages = base_messages.copy()\n",
        "\n",
        "    # 사용자 입력을 읽음\n",
        "    request = input(\n",
        "        click.style(  # 'Input:' 프롬프트를 녹색으로 출력\n",
        "            \"Input: \",\n",
        "            fg=\"green\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # 사용자 입력을 메시지 목록에 추가\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{request}\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # API로 메시지를 전송\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=200,\n",
        "        temperature=0,  # 결정론적 응답을 위한 온도 설정\n",
        "    )\n",
        "\n",
        "    # 응답에서 명령어 추출\n",
        "    command = response.choices[0].message.content.strip()\n",
        "\n",
        "    # 명령어를 보기 좋게 출력\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"Output: \", fg=\"yellow\"  # 'Output:' 프롬프트를 노란색으로 출력\n",
        "        ) + command\n",
        "    )\n",
        "    click.echo()  # 빈 줄 추가"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "6mzB0ajUQ5fb",
        "outputId": "77a9ce0f-9a62-472b-ef3e-c8ca046f4c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mInput: \u001b[0m파일 삭제\n",
            "\u001b[33mOutput: \u001b[0mrm filename\n",
            "\n",
            "\u001b[32mInput: \u001b[0mquit\n",
            "\u001b[33mOutput: \u001b[0mexit\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4c8636d5dc1b>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# 사용자 입력을 읽음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     request = input(\n\u001b[0m\u001b[1;32m     51\u001b[0m         click.style(  # 'Input:' 프롬프트를 녹색으로 출력\n\u001b[1;32m     52\u001b[0m             \u001b[0;34m\"Input: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import click\n",
        "import os\n",
        "\n",
        "model = \"gpt-4o\"\n",
        "\n",
        "# 기본 메시지 목록 정의\n",
        "base_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "       \"content\": \"당신은 스마트한 어시스턴트입니다. 답변은 명령줄의 내용만 해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"현재 디렉토리의 모든 파일을 나열해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"ls -l\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"숨김 파일을 포함하여 현재 디렉토리의 모든 파일을 나열해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"ls -la\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"현재 디렉토리의 모든 파일을 삭제해 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"rm *\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"파일 'test.txt'에서 'sun'이라는 단어가 몇 번 등장하는지 세어 주세요.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"grep -o 'sun' test.txt | wc -l\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# 무한 루프 시작\n",
        "while True:\n",
        "    messages = base_messages.copy()  # 기본 메시지 복사\n",
        "\n",
        "    # 사용자 입력 받기\n",
        "    request = input(\n",
        "        click.style(\n",
        "            \"Input (종료하려면 'exit' 입력): \",  # 입력 요청 메시지\n",
        "            fg=\"green\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # 사용자가 'exit' 또는 'quit'을 입력하면 프로그램 종료\n",
        "    if request.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "\n",
        "    # 사용자 입력을 메시지 목록에 추가\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{request}\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # API로 메시지 전송\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=200,\n",
        "        temperature=0,  # 결정론적 응답을 위한 온도 설정\n",
        "    )\n",
        "\n",
        "    # 응답에서 명령어 추출\n",
        "    command = response.choices[0].message.content.strip()\n",
        "\n",
        "    # 명령어를 보기 좋게 출력\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"Output: \", fg=\"yellow\"\n",
        "        ) + command\n",
        "    )\n",
        "\n",
        "    # 명령어를 실행할 것인지 묻기\n",
        "    click.echo(\n",
        "        click.style(\n",
        "            \"명령어를 실행하시겠습니까? (y/n): \",\n",
        "            fg=\"yellow\"\n",
        "        ),\n",
        "        nl=False\n",
        "    )\n",
        "\n",
        "    # 사용자 선택 입력\n",
        "    choice = input()\n",
        "\n",
        "    # 사용자가 'y'를 입력하면 명령어 실행\n",
        "    if choice == \"y\":\n",
        "        os.system(command)\n",
        "    elif choice == \"n\":\n",
        "        continue\n",
        "    else:\n",
        "        click.echo(\n",
        "            click.style(\n",
        "                \"잘못된 선택입니다. 'y' 또는 'n'을 입력해 주세요.\",\n",
        "                fg=\"red\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    click.echo()  # 빈 줄 추가\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5Twv2waRFU7",
        "outputId": "8b8c50e2-4028-4ba3-e295-028bcff26398"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mInput (종료하려면 'exit' 입력): \u001b[0m파일 검색\n",
            "\u001b[33mOutput: \u001b[0mfind . -name \"filename\"\n",
            "\u001b[33m명령어를 실행하시겠습니까? (y/n): \u001b[0my\n",
            "\n",
            "\u001b[32mInput (종료하려면 'exit' 입력): \u001b[0m빈 파일 하나 생성하기\n",
            "\u001b[33mOutput: \u001b[0mtouch filename.txt\n",
            "\u001b[33m명령어를 실행하시겠습니까? (y/n): \u001b[0my\n",
            "\n",
            "\u001b[32mInput (종료하려면 'exit' 입력): \u001b[0mfilename.txt 삭제하기\n",
            "\u001b[33mOutput: \u001b[0mrm filename.txt\n",
            "\u001b[33m명령어를 실행하시겠습니까? (y/n): \u001b[0my\n",
            "\n",
            "\u001b[32mInput (종료하려면 'exit' 입력): \u001b[0mexit\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}